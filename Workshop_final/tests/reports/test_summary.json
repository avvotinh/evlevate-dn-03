{
  "timestamp": "2025-08-23 13:12:20",
  "total_duration": 105.00396752357483,
  "total_tests": 11,
  "passed_tests": 0,
  "failed_tests": 11,
  "success_rate": 0.0,
  "test_results": {
    "unit_configuration_module": {
      "status": "FAILED",
      "duration": 7.191471099853516,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.13.6, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\MinhTC\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\ncachedir: .pytest_cache\nrootdir: C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, langsmith-0.4.13, asyncio-1.1.0, cov-6.2.1, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 14 items\n\ntests/unit/test_config.py::TestConfig::test_config_initialization PASSED [  7%]\ntests/unit/test_config.py::TestConfig::test_default_values PASSED        [ 14%]\ntests/unit/test_config.py::TestConfig::test_environment_variable_loading PASSED [ 21%]\ntests/unit/test_config.py::TestConfig::test_config_validation_success PASSED [ 28%]\ntests/unit/test_config.py::TestConfig::test_config_validation_failure FAILED [ 35%]\ntests/unit/test_config.py::TestConfig::test_get_openai_config FAILED     [ 42%]\ntests/unit/test_config.py::TestConfig::test_config_immutability PASSED   [ 50%]\ntests/unit/test_config.py::TestConfig::test_search_settings PASSED       [ 57%]\ntests/unit/test_config.py::TestConfig::test_llm_settings PASSED          [ 64%]\ntests/unit/test_config.py::TestConfig::test_ui_settings PASSED           [ 71%]\ntests/unit/test_config.py::TestConfig::test_empty_environment_variables FAILED [ 78%]\ntests/unit/test_config.py::TestConfig::test_model_names PASSED           [ 85%]\ntests/unit/test_config.py::TestConfig::test_numeric_constraints PASSED   [ 92%]\ntests/unit/test_config.py::TestConfig::test_custom_endpoint_detection PASSED [100%]\n\n================================== FAILURES ===================================\n__________________ TestConfig.test_config_validation_failure __________________\ntests\\unit\\test_config.py:82: in test_config_validation_failure\n    with pytest.raises(ValueError, match=\"Missing required environment variables\"):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   Failed: DID NOT RAISE <class 'ValueError'>\n______________________ TestConfig.test_get_openai_config ______________________\ntests\\unit\\test_config.py:99: in test_get_openai_config\n    assert openai_config[\"api_key\"] == 'test_embedding_key'\nE   AssertionError: assert 'sk-9-fFflHflOhQR-Y9VZcMCg' == 'test_embedding_key'\nE     \nE     - test_embedding_key\nE     + sk-9-fFflHflOhQR-Y9VZcMCg\n---------------------------- Captured stdout call -----------------------------\n\\u2705 Configuration loaded successfully\n_________________ TestConfig.test_empty_environment_variables _________________\ntests\\unit\\test_config.py:150: in test_empty_environment_variables\n    assert config.Config.PINECONE_API_KEY == \"\"\nE   AssertionError: assert 'pcsk_3fZQv8_...4pr6UWVvMpED3' == ''\nE     \nE     + pcsk_3fZQv8_As1xDMbGK8G5gVQMzL243ZtkwFe4eUzKP4rQaC2NFfAkw3Bj454pr6UWVvMpED3\n---------------------------- Captured stdout call -----------------------------\n\\u2705 Configuration loaded successfully\n=========================== short test summary info ===========================\nFAILED tests/unit/test_config.py::TestConfig::test_config_validation_failure\nFAILED tests/unit/test_config.py::TestConfig::test_get_openai_config - Assert...\nFAILED tests/unit/test_config.py::TestConfig::test_empty_environment_variables\n======================== 3 failed, 11 passed in 3.96s =========================\n",
      "stderr": "",
      "returncode": 1
    },
    "unit_llm_service": {
      "status": "FAILED",
      "duration": 5.194109201431274,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.13.6, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\MinhTC\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\ncachedir: .pytest_cache\nrootdir: C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, langsmith-0.4.13, asyncio-1.1.0, cov-6.2.1, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 16 items\n\ntests/unit/test_llm_service.py::TestLLMService::test_llm_service_initialization FAILED [  6%]\ntests/unit/test_llm_service.py::TestLLMService::test_custom_endpoint_initialization FAILED [ 12%]\ntests/unit/test_llm_service.py::TestLLMService::test_get_langchain_llm_azure FAILED [ 18%]\ntests/unit/test_llm_service.py::TestLLMService::test_get_langchain_llm_custom FAILED [ 25%]\ntests/unit/test_llm_service.py::TestLLMService::test_classify_intent_success FAILED [ 31%]\ntests/unit/test_llm_service.py::TestLLMService::test_classify_intent_failure FAILED [ 37%]\ntests/unit/test_llm_service.py::TestLLMService::test_generate_response_success FAILED [ 43%]\ntests/unit/test_llm_service.py::TestLLMService::test_generate_response_failure FAILED [ 50%]\ntests/unit/test_llm_service.py::TestLLMService::test_extract_parameters_success FAILED [ 56%]\ntests/unit/test_llm_service.py::TestLLMService::test_extract_parameters_invalid_json FAILED [ 62%]\ntests/unit/test_llm_service.py::TestLLMService::test_health_check_success FAILED [ 68%]\ntests/unit/test_llm_service.py::TestLLMService::test_health_check_failure FAILED [ 75%]\ntests/unit/test_llm_service.py::TestLLMService::test_response_format_enum PASSED [ 81%]\ntests/unit/test_llm_service.py::TestLLMService::test_singleton_instance PASSED [ 87%]\ntests/unit/test_llm_service.py::TestLLMService::test_format_prompt_for_intent FAILED [ 93%]\ntests/unit/test_llm_service.py::TestLLMService::test_format_prompt_for_generation FAILED [100%]\n\n================================== FAILURES ===================================\n_______________ TestLLMService.test_llm_service_initialization ________________\ntests\\unit\\test_llm_service.py:56: in test_llm_service_initialization\n    assert service.max_tokens == 1000\nE   assert 5000 == 1000\nE    +  where 5000 = <src.services.llm_service.LLMService object at 0x000001EFD8A96D50>.max_tokens\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:01 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:11:01 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n_____________ TestLLMService.test_custom_endpoint_initialization ______________\ntests\\unit\\test_llm_service.py:70: in test_custom_endpoint_initialization\n    with patch('src.services.llm_service.OpenAI') as mock_openai:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <module 'src.services.llm_service' from 'C:\\\\Users\\\\MinhTC\\\\Desktop\\\\Hackaton\\\\evlevate-dn-03\\\\Workshop_final\\\\src\\\\services\\\\llm_service.py'> does not have the attribute 'OpenAI'\n_________________ TestLLMService.test_get_langchain_llm_azure _________________\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1423: in patched\n    with self.decoration_helper(patched,\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1405: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <module 'src.services.llm_service' from 'C:\\\\Users\\\\MinhTC\\\\Desktop\\\\Hackaton\\\\evlevate-dn-03\\\\Workshop_final\\\\src\\\\services\\\\llm_service.py'> does not have the attribute 'AzureChatOpenAI'\n________________ TestLLMService.test_get_langchain_llm_custom _________________\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1423: in patched\n    with self.decoration_helper(patched,\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1405: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <module 'src.services.llm_service' from 'C:\\\\Users\\\\MinhTC\\\\Desktop\\\\Hackaton\\\\evlevate-dn-03\\\\Workshop_final\\\\src\\\\services\\\\llm_service.py'> does not have the attribute 'ChatOpenAI'\n_________________ TestLLMService.test_classify_intent_success _________________\ntests\\unit\\test_llm_service.py:120: in test_classify_intent_success\n    result = service.classify_intent(\"Tìm laptop Dell\")\n             ^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMService' object has no attribute 'classify_intent'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n_________________ TestLLMService.test_classify_intent_failure _________________\ntests\\unit\\test_llm_service.py:136: in test_classify_intent_failure\n    result = service.classify_intent(\"Tìm laptop Dell\")\n             ^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMService' object has no attribute 'classify_intent'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n________________ TestLLMService.test_generate_response_success ________________\ntests\\unit\\test_llm_service.py:153: in test_generate_response_success\n    result = service.generate_response(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMService' object has no attribute 'generate_response'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n________________ TestLLMService.test_generate_response_failure ________________\ntests\\unit\\test_llm_service.py:172: in test_generate_response_failure\n    result = service.generate_response(\"Test prompt\")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMService' object has no attribute 'generate_response'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n_______________ TestLLMService.test_extract_parameters_success ________________\ntests\\unit\\test_llm_service.py:189: in test_extract_parameters_success\n    result = service.extract_parameters(\"T\\xecm laptop Dell d\\u01b0\\u1edbi 20 tri\\u1ec7u\")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMService' object has no attribute 'extract_parameters'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n_____________ TestLLMService.test_extract_parameters_invalid_json _____________\ntests\\unit\\test_llm_service.py:207: in test_extract_parameters_invalid_json\n    result = service.extract_parameters(\"Tìm laptop Dell\")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMService' object has no attribute 'extract_parameters'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n__________________ TestLLMService.test_health_check_success ___________________\ntests\\unit\\test_llm_service.py:224: in test_health_check_success\n    result = service.health_check()\n             ^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMService' object has no attribute 'health_check'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n__________________ TestLLMService.test_health_check_failure ___________________\ntests\\unit\\test_llm_service.py:240: in test_health_check_failure\n    result = service.health_check()\n             ^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMService' object has no attribute 'health_check'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n________________ TestLLMService.test_format_prompt_for_intent _________________\ntests\\unit\\test_llm_service.py:268: in test_format_prompt_for_intent\n    formatted_prompt = service._format_prompt_for_intent(user_input)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMService' object has no attribute '_format_prompt_for_intent'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n______________ TestLLMService.test_format_prompt_for_generation _______________\ntests\\unit\\test_llm_service.py:282: in test_format_prompt_for_generation\n    formatted_prompt = service._format_prompt_for_generation(query, context)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMService' object has no attribute '_format_prompt_for_generation'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:11:02 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n=========================== short test summary info ===========================\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_llm_service_initialization\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_custom_endpoint_initialization\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_get_langchain_llm_azure\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_get_langchain_llm_custom\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_classify_intent_success\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_classify_intent_failure\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_generate_response_success\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_generate_response_failure\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_extract_parameters_success\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_extract_parameters_invalid_json\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_health_check_success\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_health_check_failure\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_format_prompt_for_intent\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_format_prompt_for_generation\n======================== 14 failed, 2 passed in 3.47s =========================\n",
      "stderr": "",
      "returncode": 1
    },
    "unit_pinecone_service": {
      "status": "FAILED",
      "duration": 5.172495365142822,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.13.6, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\MinhTC\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\ncachedir: .pytest_cache\nrootdir: C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, langsmith-0.4.13, asyncio-1.1.0, cov-6.2.1, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 16 items\n\ntests/unit/test_pinecone_service.py::TestPineconeService::test_pinecone_service_initialization PASSED [  6%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_create_embedding_success PASSED [ 12%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_create_embedding_failure FAILED [ 18%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_upsert_products_success FAILED [ 25%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_upsert_products_failure FAILED [ 31%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_search_products_success PASSED [ 37%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_search_products_with_filters PASSED [ 43%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_search_products_failure FAILED [ 50%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_get_index_stats_success PASSED [ 56%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_get_index_stats_failure FAILED [ 62%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_delete_all_vectors_success PASSED [ 68%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_delete_all_vectors_failure PASSED [ 75%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_health_check_success FAILED [ 81%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_health_check_failure FAILED [ 87%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_prepare_product_for_indexing FAILED [ 93%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_singleton_instance PASSED [100%]\n\n================================== FAILURES ===================================\n______________ TestPineconeService.test_create_embedding_failure ______________\ntests\\unit\\test_pinecone_service.py:87: in test_create_embedding_failure\n    assert result is None\nE   assert [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...] is None\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Failed to create embedding: API Error\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Failed to create embedding: API Error\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Failed to create embedding: API Error\n______________ TestPineconeService.test_upsert_products_success _______________\ntests\\unit\\test_pinecone_service.py:101: in test_upsert_products_success\n    result = service.upsert_products(sample_products)\n             ^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PineconeService' object has no attribute 'upsert_products'. Did you mean: 'search_products'?\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\n______________ TestPineconeService.test_upsert_products_failure _______________\ntests\\unit\\test_pinecone_service.py:119: in test_upsert_products_failure\n    result = service.upsert_products(sample_products)\n             ^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PineconeService' object has no attribute 'upsert_products'. Did you mean: 'search_products'?\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\n______________ TestPineconeService.test_search_products_failure _______________\ntests\\unit\\test_pinecone_service.py:200: in test_search_products_failure\n    results = service.search_products(\"laptop Dell\")\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsrc\\services\\pinecone_service.py:246: in search_products\n    raise e\nsrc\\services\\pinecone_service.py:199: in search_products\n    results = self.index.query(\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1169: in __call__\n    return self._mock_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1173: in _mock_call\n    return self._execute_mock_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1228: in _execute_mock_call\n    raise effect\nE   Exception: Search Error\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\U0001f50d Searching for: 'laptop Dell' with filters: {'type': 'product'}\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\U0001f50d Searching for: 'laptop Dell' with filters: {'type': 'product'}\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - Metadata filter applied:\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - Metadata filter applied:\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO -   type: product\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO -   type: product\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: Search Error\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: Search Error\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\U0001f50d Searching for: 'laptop Dell' with filters: {'type': 'product'}\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 Metadata filter applied:\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79   type: product\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: Search Error\n______________ TestPineconeService.test_get_index_stats_failure _______________\ntests\\unit\\test_pinecone_service.py:245: in test_get_index_stats_failure\n    assert stats is None\nE   assert {} is None\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Failed to get index stats: Stats Error\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Failed to get index stats: Stats Error\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Failed to get index stats: Stats Error\n________________ TestPineconeService.test_health_check_success ________________\ntests\\unit\\test_pinecone_service.py:293: in test_health_check_success\n    result = service.health_check()\n             ^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PineconeService' object has no attribute 'health_check'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\n________________ TestPineconeService.test_health_check_failure ________________\ntests\\unit\\test_pinecone_service.py:311: in test_health_check_failure\n    result = service.health_check()\n             ^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PineconeService' object has no attribute 'health_check'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\n____________ TestPineconeService.test_prepare_product_for_indexing ____________\ntests\\unit\\test_pinecone_service.py:324: in test_prepare_product_for_indexing\n    prepared = service._prepare_product_for_indexing(product)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PineconeService' object has no attribute '_prepare_product_for_indexing'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:11:07 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\n=========================== short test summary info ===========================\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_create_embedding_failure\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_upsert_products_success\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_upsert_products_failure\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_search_products_failure\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_get_index_stats_failure\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_health_check_success\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_health_check_failure\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_prepare_product_for_indexing\n========================= 8 failed, 8 passed in 3.45s =========================\n",
      "stderr": "",
      "returncode": 1
    },
    "unit_tools": {
      "status": "FAILED",
      "duration": 7.274729251861572,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.13.6, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\MinhTC\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\ncachedir: .pytest_cache\nrootdir: C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, langsmith-0.4.13, asyncio-1.1.0, cov-6.2.1, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 30 items\n\ntests/unit/test_tools.py::TestToolManager::test_tool_manager_initialization PASSED [  3%]\ntests/unit/test_tools.py::TestToolManager::test_get_all_tools PASSED     [  6%]\ntests/unit/test_tools.py::TestToolManager::test_get_tool_by_name PASSED  [ 10%]\ntests/unit/test_tools.py::TestToolManager::test_get_tool_names PASSED    [ 13%]\ntests/unit/test_tools.py::TestToolManager::test_describe_tools PASSED    [ 16%]\ntests/unit/test_tools.py::TestSearchTool::test_search_tool_initialization FAILED [ 20%]\ntests/unit/test_tools.py::TestSearchTool::test_search_tool_success PASSED [ 23%]\ntests/unit/test_tools.py::TestSearchTool::test_search_tool_empty_query PASSED [ 26%]\ntests/unit/test_tools.py::TestSearchTool::test_search_tool_pinecone_error PASSED [ 30%]\ntests/unit/test_tools.py::TestSearchTool::test_search_tool_singleton PASSED [ 33%]\ntests/unit/test_tools.py::TestCompareTool::test_compare_tool_initialization FAILED [ 36%]\ntests/unit/test_tools.py::TestCompareTool::test_compare_tool_success PASSED [ 40%]\ntests/unit/test_tools.py::TestCompareTool::test_compare_tool_no_products_found PASSED [ 43%]\ntests/unit/test_tools.py::TestCompareTool::test_compare_tool_singleton PASSED [ 46%]\ntests/unit/test_tools.py::TestRecommendTool::test_recommend_tool_initialization FAILED [ 50%]\ntests/unit/test_tools.py::TestRecommendTool::test_recommend_tool_success PASSED [ 53%]\ntests/unit/test_tools.py::TestRecommendTool::test_recommend_tool_no_products PASSED [ 56%]\ntests/unit/test_tools.py::TestRecommendTool::test_recommend_tool_singleton PASSED [ 60%]\ntests/unit/test_tools.py::TestReviewTool::test_review_tool_initialization FAILED [ 63%]\ntests/unit/test_tools.py::TestReviewTool::test_review_tool_success PASSED [ 66%]\ntests/unit/test_tools.py::TestReviewTool::test_review_tool_product_not_found PASSED [ 70%]\ntests/unit/test_tools.py::TestReviewTool::test_review_tool_singleton PASSED [ 73%]\ntests/unit/test_tools.py::TestGenerationTool::test_generation_tool_initialization FAILED [ 76%]\ntests/unit/test_tools.py::TestGenerationTool::test_generation_tool_success FAILED [ 80%]\ntests/unit/test_tools.py::TestGenerationTool::test_generation_tool_llm_failure FAILED [ 83%]\ntests/unit/test_tools.py::TestGenerationTool::test_generation_tool_singleton PASSED [ 86%]\ntests/unit/test_tools.py::TestToolIntegration::test_all_tools_have_required_attributes PASSED [ 90%]\ntests/unit/test_tools.py::TestToolIntegration::test_tool_names_are_unique PASSED [ 93%]\ntests/unit/test_tools.py::TestToolIntegration::test_tools_return_json_strings FAILED [ 96%]\ntests/unit/test_tools.py::TestToolIntegration::test_tool_manager_contains_all_tools FAILED [100%]\n\n================================== FAILURES ===================================\n_______________ TestSearchTool.test_search_tool_initialization ________________\ntests\\unit\\test_tools.py:99: in test_search_tool_initialization\n    assert \"search\" in tool.description.lower()\nE   assert 'search' in '\\U0001f50d t\\xecm ki\\u1ebfm s\\u1ea3n ph\\u1ea9m theo ti\\xeau ch\\xed c\\u1ee5 th\\u1ec3.\\\\n    \\\\n    m\\u1ee5c \\u0111\\xedch: t\\xecm s\\u1ea3n ph\\u1ea9m d\\u1ef1a tr\\xean c\\xe1c b\\u1ed9 l\\u1ecdc v\\xe0 ti\\xeau ch\\xed nh\\u1ea5t \\u0111\\u1ecbnh\\\\n    \\\\n    s\\u1eed d\\u1ee5ng khi:\\\\n    - kh\\xe1ch h\\xe0ng t\\xecm s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3: \"t\\xecm laptop dell\", \"iphone 15 pro max\"\\\\n    - l\\u1ecdc theo th\\u01b0\\u01a1ng hi\\u1ec7u: \"laptop hp\", \"smartphone samsung\"  \\\\n    - l\\u1ecdc theo gi\\xe1: \"laptop d\\u01b0\\u1edbi 25 tri\\u1ec7u\", \"\\u0111i\\u1ec7n tho\\u1ea1i t\\u1eeb 10-20 tri\\u1ec7u\"\\\\n    - l\\u1ecdc theo t\\xednh n\\u0103ng: \"laptop c\\xf3 ssd\", \"smartphone camera 48mp\"\\\\n    - t\\xecm theo m\\u1ee5c \\u0111\\xedch s\\u1eed d\\u1ee5ng: \"laptop gaming\", \"smartphone ch\\u1ee5p \\u1ea3nh\"\\\\n    \\\\n    kh\\xf4ng d\\xf9ng cho: g\\u1ee3i \\xfd ho\\u1eb7c t\\u01b0 v\\u1ea5n s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p\\\\n    \\\\n    output: danh s\\xe1ch s\\u1ea3n ph\\u1ea9m kh\\u1edbp v\\u1edbi filters, kh\\xf4ng c\\xf3 ranking'\nE    +  where '\\U0001f50d t\\xecm ki\\u1ebfm s\\u1ea3n ph\\u1ea9m theo ti\\xeau ch\\xed c\\u1ee5 th\\u1ec3.\\\\n    \\\\n    m\\u1ee5c \\u0111\\xedch: t\\xecm s\\u1ea3n ph\\u1ea9m d\\u1ef1a tr\\xean c\\xe1c b\\u1ed9 l\\u1ecdc v\\xe0 ti\\xeau ch\\xed nh\\u1ea5t \\u0111\\u1ecbnh\\\\n    \\\\n    s\\u1eed d\\u1ee5ng khi:\\\\n    - kh\\xe1ch h\\xe0ng t\\xecm s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3: \"t\\xecm laptop dell\", \"iphone 15 pro max\"\\\\n    - l\\u1ecdc theo th\\u01b0\\u01a1ng hi\\u1ec7u: \"laptop hp\", \"smartphone samsung\"  \\\\n    - l\\u1ecdc theo gi\\xe1: \"laptop d\\u01b0\\u1edbi 25 tri\\u1ec7u\", \"\\u0111i\\u1ec7n tho\\u1ea1i t\\u1eeb 10-20 tri\\u1ec7u\"\\\\n    - l\\u1ecdc theo t\\xednh n\\u0103ng: \"laptop c\\xf3 ssd\", \"smartphone camera 48mp\"\\\\n    - t\\xecm theo m\\u1ee5c \\u0111\\xedch s\\u1eed d\\u1ee5ng: \"laptop gaming\", \"smartphone ch\\u1ee5p \\u1ea3nh\"\\\\n    \\\\n    kh\\xf4ng d\\xf9ng cho: g\\u1ee3i \\xfd ho\\u1eb7c t\\u01b0 v\\u1ea5n s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p\\\\n    \\\\n    output: danh s\\xe1ch s\\u1ea3n ph\\u1ea9m kh\\u1edbp v\\u1edbi filters, kh\\xf4ng c\\xf3 ranking' = <built-in method lower of str object at 0x0000024FDBC78040>()\nE    +    where <built-in method lower of str object at 0x0000024FDBC78040> = '\\U0001f50d T\\xccM KI\\u1ebeM s\\u1ea3n ph\\u1ea9m theo ti\\xeau ch\\xed c\\u1ee5 th\\u1ec3.\\\\n    \\\\n    M\\u1ee4C \\u0110\\xcdCH: T\\xecm s\\u1ea3n ph\\u1ea9m d\\u1ef1a tr\\xean c\\xe1c b\\u1ed9 l\\u1ecdc v\\xe0 ti\\xeau ch\\xed nh\\u1ea5t \\u0111\\u1ecbnh\\\\n    \\\\n    S\\u1eec D\\u1ee4NG KHI:\\\\n    - Kh\\xe1ch h\\xe0ng T\\xccM s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3: \"t\\xecm laptop Dell\", \"iPhone 15 Pro Max\"\\\\n    - L\\u1ecdc theo th\\u01b0\\u01a1ng hi\\u1ec7u: \"laptop HP\", \"smartphone Samsung\"  \\\\n    - L\\u1ecdc theo gi\\xe1: \"laptop d\\u01b0\\u1edbi 25 tri\\u1ec7u\", \"\\u0111i\\u1ec7n tho\\u1ea1i t\\u1eeb 10-20 tri\\u1ec7u\"\\\\n    - L\\u1ecdc theo t\\xednh n\\u0103ng: \"laptop c\\xf3 SSD\", \"smartphone camera 48MP\"\\\\n    - T\\xecm theo m\\u1ee5c \\u0111\\xedch s\\u1eed d\\u1ee5ng: \"laptop gaming\", \"smartphone ch\\u1ee5p \\u1ea3nh\"\\\\n    \\\\n    KH\\xd4NG d\\xf9ng cho: G\\u1ee3i \\xfd ho\\u1eb7c t\\u01b0 v\\u1ea5n s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p\\\\n    \\\\n    OUTPUT: Danh s\\xe1ch s\\u1ea3n ph\\u1ea9m kh\\u1edbp v\\u1edbi filters, kh\\xf4ng c\\xf3 ranking'.lower\nE    +      where '\\U0001f50d T\\xccM KI\\u1ebeM s\\u1ea3n ph\\u1ea9m theo ti\\xeau ch\\xed c\\u1ee5 th\\u1ec3.\\\\n    \\\\n    M\\u1ee4C \\u0110\\xcdCH: T\\xecm s\\u1ea3n ph\\u1ea9m d\\u1ef1a tr\\xean c\\xe1c b\\u1ed9 l\\u1ecdc v\\xe0 ti\\xeau ch\\xed nh\\u1ea5t \\u0111\\u1ecbnh\\\\n    \\\\n    S\\u1eec D\\u1ee4NG KHI:\\\\n    - Kh\\xe1ch h\\xe0ng T\\xccM s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3: \"t\\xecm laptop Dell\", \"iPhone 15 Pro Max\"\\\\n    - L\\u1ecdc theo th\\u01b0\\u01a1ng hi\\u1ec7u: \"laptop HP\", \"smartphone Samsung\"  \\\\n    - L\\u1ecdc theo gi\\xe1: \"laptop d\\u01b0\\u1edbi 25 tri\\u1ec7u\", \"\\u0111i\\u1ec7n tho\\u1ea1i t\\u1eeb 10-20 tri\\u1ec7u\"\\\\n    - L\\u1ecdc theo t\\xednh n\\u0103ng: \"laptop c\\xf3 SSD\", \"smartphone camera 48MP\"\\\\n    - T\\xecm theo m\\u1ee5c \\u0111\\xedch s\\u1eed d\\u1ee5ng: \"laptop gaming\", \"smartphone ch\\u1ee5p \\u1ea3nh\"\\\\n    \\\\n    KH\\xd4NG d\\xf9ng cho: G\\u1ee3i \\xfd ho\\u1eb7c t\\u01b0 v\\u1ea5n s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p\\\\n    \\\\n    OUTPUT: Danh s\\xe1ch s\\u1ea3n ph\\u1ea9m kh\\u1edbp v\\u1edbi filters, kh\\xf4ng c\\xf3 ranking' = SearchTool().description\n______________ TestCompareTool.test_compare_tool_initialization _______________\ntests\\unit\\test_tools.py:166: in test_compare_tool_initialization\n    assert \"compare\" in tool.description.lower()\nE   assert 'compare' in 'so s\\xe1nh chi ti\\u1ebft nhi\\u1ec1u s\\u1ea3n ph\\u1ea9m c\\u1ea1nh nhau.\\\\n    \\\\n    s\\u1eed d\\u1ee5ng tool n\\xe0y khi:\\\\n    - kh\\xe1ch h\\xe0ng mu\\u1ed1n so s\\xe1nh 2-3 s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3\\\\n    - c\\u1ea7n ph\\xe2n t\\xedch \\u01b0u nh\\u01b0\\u1ee3c \\u0111i\\u1ec3m t\\u1eebng s\\u1ea3n ph\\u1ea9m\\\\n    - mu\\u1ed1n \\u0111\\u01b0a ra k\\u1ebft lu\\u1eadn v\\u1ec1 s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p nh\\u1ea5t\\\\n    - so s\\xe1nh theo kh\\xeda c\\u1ea1nh c\\u1ee5 th\\u1ec3 (gi\\xe1, hi\\u1ec7u n\\u0103ng, camera, v.v.)\\\\n    \\\\n    input format:\\\\n    {\\\\n        \"product_ids\": [\"t\\xean ho\\u1eb7c id s\\u1ea3n ph\\u1ea9m 1\", \"t\\xean ho\\u1eb7c id s\\u1ea3n ph\\u1ea9m 2\"],\\\\n        \"comparison_aspects\": [\"kh\\xeda c\\u1ea1nh 1\", \"kh\\xeda c\\u1ea1nh 2\"],\\\\n        \"include_reviews\": true/false\\\\n    }\\\\n    \\\\n    v\\xed d\\u1ee5 s\\u1eed d\\u1ee5ng:\\\\n    - {\"product_ids\": [\"iphone 15\", \"iphone 15 pro max\"], \"comparison_aspects\": [\"gi\\xe1\", \"camera\", \"hi\\u1ec7u n\\u0103ng\"]}\\\\n    - {\"product_ids\": [\"dell xps 15\", \"macbook air m2\"], \"comparison_aspects\": [\"hi\\u1ec7u n\\u0103ng\", \"gi\\xe1\", \"pin\"]}\\\\n    \\\\n    tool s\\u1ebd t\\u1ef1 \\u0111\\u1ed9ng t\\xecm s\\u1ea3n ph\\u1ea9m theo t\\xean v\\xe0 tr\\u1ea3 v\\u1ec1 b\\u1ea3ng so s\\xe1nh chi ti\\u1ebft.'\nE    +  where 'so s\\xe1nh chi ti\\u1ebft nhi\\u1ec1u s\\u1ea3n ph\\u1ea9m c\\u1ea1nh nhau.\\\\n    \\\\n    s\\u1eed d\\u1ee5ng tool n\\xe0y khi:\\\\n    - kh\\xe1ch h\\xe0ng mu\\u1ed1n so s\\xe1nh 2-3 s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3\\\\n    - c\\u1ea7n ph\\xe2n t\\xedch \\u01b0u nh\\u01b0\\u1ee3c \\u0111i\\u1ec3m t\\u1eebng s\\u1ea3n ph\\u1ea9m\\\\n    - mu\\u1ed1n \\u0111\\u01b0a ra k\\u1ebft lu\\u1eadn v\\u1ec1 s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p nh\\u1ea5t\\\\n    - so s\\xe1nh theo kh\\xeda c\\u1ea1nh c\\u1ee5 th\\u1ec3 (gi\\xe1, hi\\u1ec7u n\\u0103ng, camera, v.v.)\\\\n    \\\\n    input format:\\\\n    {\\\\n        \"product_ids\": [\"t\\xean ho\\u1eb7c id s\\u1ea3n ph\\u1ea9m 1\", \"t\\xean ho\\u1eb7c id s\\u1ea3n ph\\u1ea9m 2\"],\\\\n        \"comparison_aspects\": [\"kh\\xeda c\\u1ea1nh 1\", \"kh\\xeda c\\u1ea1nh 2\"],\\\\n        \"include_reviews\": true/false\\\\n    }\\\\n    \\\\n    v\\xed d\\u1ee5 s\\u1eed d\\u1ee5ng:\\\\n    - {\"product_ids\": [\"iphone 15\", \"iphone 15 pro max\"], \"comparison_aspects\": [\"gi\\xe1\", \"camera\", \"hi\\u1ec7u n\\u0103ng\"]}\\\\n    - {\"product_ids\": [\"dell xps 15\", \"macbook air m2\"], \"comparison_aspects\": [\"hi\\u1ec7u n\\u0103ng\", \"gi\\xe1\", \"pin\"]}\\\\n    \\\\n    tool s\\u1ebd t\\u1ef1 \\u0111\\u1ed9ng t\\xecm s\\u1ea3n ph\\u1ea9m theo t\\xean v\\xe0 tr\\u1ea3 v\\u1ec1 b\\u1ea3ng so s\\xe1nh chi ti\\u1ebft.' = <built-in method lower of str object at 0x0000024FDBC7D6B0>()\nE    +    where <built-in method lower of str object at 0x0000024FDBC7D6B0> = 'So s\\xe1nh chi ti\\u1ebft nhi\\u1ec1u s\\u1ea3n ph\\u1ea9m c\\u1ea1nh nhau.\\\\n    \\\\n    S\\u1eed d\\u1ee5ng tool n\\xe0y khi:\\\\n    - Kh\\xe1ch h\\xe0ng mu\\u1ed1n so s\\xe1nh 2-3 s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3\\\\n    - C\\u1ea7n ph\\xe2n t\\xedch \\u01b0u nh\\u01b0\\u1ee3c \\u0111i\\u1ec3m t\\u1eebng s\\u1ea3n ph\\u1ea9m\\\\n    - Mu\\u1ed1n \\u0111\\u01b0a ra k\\u1ebft lu\\u1eadn v\\u1ec1 s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p nh\\u1ea5t\\\\n    - So s\\xe1nh theo kh\\xeda c\\u1ea1nh c\\u1ee5 th\\u1ec3 (gi\\xe1, hi\\u1ec7u n\\u0103ng, camera, v.v.)\\\\n    \\\\n    INPUT FORMAT:\\\\n    {\\\\n        \"product_ids\": [\"t\\xean ho\\u1eb7c ID s\\u1ea3n ph\\u1ea9m 1\", \"t\\xean ho\\u1eb7c ID s\\u1ea3n ph\\u1ea9m 2\"],\\\\n        \"comparison_aspects\": [\"kh\\xeda c\\u1ea1nh 1\", \"kh\\xeda c\\u1ea1nh 2\"],\\\\n        \"include_reviews\": true/false\\\\n    }\\\\n    \\\\n    V\\xcd D\\u1ee4 S\\u1eec D\\u1ee4NG:\\\\n    - {\"product_ids\": [\"iPhone 15\", \"iPhone 15 Pro Max\"], \"comparison_aspects\": [\"gi\\xe1\", \"camera\", \"hi\\u1ec7u n\\u0103ng\"]}\\\\n    - {\"product_ids\": [\"Dell XPS 15\", \"MacBook Air M2\"], \"comparison_aspects\": [\"hi\\u1ec7u n\\u0103ng\", \"gi\\xe1\", \"pin\"]}\\\\n    \\\\n    Tool s\\u1ebd t\\u1ef1 \\u0111\\u1ed9ng t\\xecm s\\u1ea3n ph\\u1ea9m theo t\\xean v\\xe0 tr\\u1ea3 v\\u1ec1 b\\u1ea3ng so s\\xe1nh chi ti\\u1ebft.'.lower\nE    +      where 'So s\\xe1nh chi ti\\u1ebft nhi\\u1ec1u s\\u1ea3n ph\\u1ea9m c\\u1ea1nh nhau.\\\\n    \\\\n    S\\u1eed d\\u1ee5ng tool n\\xe0y khi:\\\\n    - Kh\\xe1ch h\\xe0ng mu\\u1ed1n so s\\xe1nh 2-3 s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3\\\\n    - C\\u1ea7n ph\\xe2n t\\xedch \\u01b0u nh\\u01b0\\u1ee3c \\u0111i\\u1ec3m t\\u1eebng s\\u1ea3n ph\\u1ea9m\\\\n    - Mu\\u1ed1n \\u0111\\u01b0a ra k\\u1ebft lu\\u1eadn v\\u1ec1 s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p nh\\u1ea5t\\\\n    - So s\\xe1nh theo kh\\xeda c\\u1ea1nh c\\u1ee5 th\\u1ec3 (gi\\xe1, hi\\u1ec7u n\\u0103ng, camera, v.v.)\\\\n    \\\\n    INPUT FORMAT:\\\\n    {\\\\n        \"product_ids\": [\"t\\xean ho\\u1eb7c ID s\\u1ea3n ph\\u1ea9m 1\", \"t\\xean ho\\u1eb7c ID s\\u1ea3n ph\\u1ea9m 2\"],\\\\n        \"comparison_aspects\": [\"kh\\xeda c\\u1ea1nh 1\", \"kh\\xeda c\\u1ea1nh 2\"],\\\\n        \"include_reviews\": true/false\\\\n    }\\\\n    \\\\n    V\\xcd D\\u1ee4 S\\u1eec D\\u1ee4NG:\\\\n    - {\"product_ids\": [\"iPhone 15\", \"iPhone 15 Pro Max\"], \"comparison_aspects\": [\"gi\\xe1\", \"camera\", \"hi\\u1ec7u n\\u0103ng\"]}\\\\n    - {\"product_ids\": [\"Dell XPS 15\", \"MacBook Air M2\"], \"comparison_aspects\": [\"hi\\u1ec7u n\\u0103ng\", \"gi\\xe1\", \"pin\"]}\\\\n    \\\\n    Tool s\\u1ebd t\\u1ef1 \\u0111\\u1ed9ng t\\xecm s\\u1ea3n ph\\u1ea9m theo t\\xean v\\xe0 tr\\u1ea3 v\\u1ec1 b\\u1ea3ng so s\\xe1nh chi ti\\u1ebft.' = CompareTool().description\n____________ TestRecommendTool.test_recommend_tool_initialization _____________\ntests\\unit\\test_tools.py:228: in test_recommend_tool_initialization\n    assert \"recommend\" in tool.description.lower()\nE   assert 'recommend' in '\\U0001f4a1 t\\u01b0 v\\u1ea5n v\\xe0 g\\u1ee3i \\xfd s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p v\\u1edbi nhu c\\u1ea7u c\\xe1 nh\\xe2n.\\\\n    \\\\n    m\\u1ee5c \\u0111\\xedch: \\u0111\\u01b0a ra g\\u1ee3i \\xfd s\\u1ea3n ph\\u1ea9m t\\u1ed1i \\u01b0u d\\u1ef1a tr\\xean ph\\xe2n t\\xedch nhu c\\u1ea7u ng\\u01b0\\u1eddi d\\xf9ng\\\\n    \\\\n    s\\u1eed d\\u1ee5ng khi:\\\\n    - kh\\xe1ch h\\xe0ng c\\u1ea7n t\\u01b0 v\\u1ea5n: \"g\\u1ee3i \\xfd laptop cho sinh vi\\xean\", \"n\\xean mua smartphone n\\xe0o\"\\\\n    - m\\xf4 t\\u1ea3 nhu c\\u1ea7u s\\u1eed d\\u1ee5ng: \"c\\u1ea7n laptop l\\u1eadp tr\\xecnh\", \"smartphone ch\\u1ee5p \\u1ea3nh \\u0111\\u1eb9p\"\\\\n    - c\\xf3 ng\\xe2n s\\xe1ch v\\xe0 y\\xeau c\\u1ea7u: \"laptop gaming d\\u01b0\\u1edbi 30 tri\\u1ec7u\", \"iphone hay samsung t\\u1ed1t h\\u01a1n\"\\\\n    - kh\\xf4ng bi\\u1ebft ch\\u1ecdn g\\xec: \"t\\u01b0 v\\u1ea5n laptop ph\\xf9 h\\u1ee3p\", \"\\u0111i\\u1ec7n tho\\u1ea1i n\\xe0o \\u0111\\xe1ng mua\"\\\\n    - so s\\xe1nh l\\u1ef1a ch\\u1ecdn: \"dell hay hp t\\u1ed1t h\\u01a1n cho v\\u0103n ph\\xf2ng\"\\\\n    \\\\n    kh\\xf4ng d\\xf9ng cho: t\\xecm ki\\u1ebfm s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3 \\u0111\\xe3 bi\\u1ebft t\\xean\\\\n    \\\\n    output: top g\\u1ee3i \\xfd c\\xf3 ranking + l\\xfd do chi ti\\u1ebft t\\u1ea1i sao ph\\xf9 h\\u1ee3p'\nE    +  where '\\U0001f4a1 t\\u01b0 v\\u1ea5n v\\xe0 g\\u1ee3i \\xfd s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p v\\u1edbi nhu c\\u1ea7u c\\xe1 nh\\xe2n.\\\\n    \\\\n    m\\u1ee5c \\u0111\\xedch: \\u0111\\u01b0a ra g\\u1ee3i \\xfd s\\u1ea3n ph\\u1ea9m t\\u1ed1i \\u01b0u d\\u1ef1a tr\\xean ph\\xe2n t\\xedch nhu c\\u1ea7u ng\\u01b0\\u1eddi d\\xf9ng\\\\n    \\\\n    s\\u1eed d\\u1ee5ng khi:\\\\n    - kh\\xe1ch h\\xe0ng c\\u1ea7n t\\u01b0 v\\u1ea5n: \"g\\u1ee3i \\xfd laptop cho sinh vi\\xean\", \"n\\xean mua smartphone n\\xe0o\"\\\\n    - m\\xf4 t\\u1ea3 nhu c\\u1ea7u s\\u1eed d\\u1ee5ng: \"c\\u1ea7n laptop l\\u1eadp tr\\xecnh\", \"smartphone ch\\u1ee5p \\u1ea3nh \\u0111\\u1eb9p\"\\\\n    - c\\xf3 ng\\xe2n s\\xe1ch v\\xe0 y\\xeau c\\u1ea7u: \"laptop gaming d\\u01b0\\u1edbi 30 tri\\u1ec7u\", \"iphone hay samsung t\\u1ed1t h\\u01a1n\"\\\\n    - kh\\xf4ng bi\\u1ebft ch\\u1ecdn g\\xec: \"t\\u01b0 v\\u1ea5n laptop ph\\xf9 h\\u1ee3p\", \"\\u0111i\\u1ec7n tho\\u1ea1i n\\xe0o \\u0111\\xe1ng mua\"\\\\n    - so s\\xe1nh l\\u1ef1a ch\\u1ecdn: \"dell hay hp t\\u1ed1t h\\u01a1n cho v\\u0103n ph\\xf2ng\"\\\\n    \\\\n    kh\\xf4ng d\\xf9ng cho: t\\xecm ki\\u1ebfm s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3 \\u0111\\xe3 bi\\u1ebft t\\xean\\\\n    \\\\n    output: top g\\u1ee3i \\xfd c\\xf3 ranking + l\\xfd do chi ti\\u1ebft t\\u1ea1i sao ph\\xf9 h\\u1ee3p' = <built-in method lower of str object at 0x0000024FDBD28D80>()\nE    +    where <built-in method lower of str object at 0x0000024FDBD28D80> = '\\U0001f4a1 T\\u01af V\\u1ea4N v\\xe0 G\\u1ee2I \\xdd s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p v\\u1edbi nhu c\\u1ea7u c\\xe1 nh\\xe2n.\\\\n    \\\\n    M\\u1ee4C \\u0110\\xcdCH: \\u0110\\u01b0a ra g\\u1ee3i \\xfd s\\u1ea3n ph\\u1ea9m t\\u1ed1i \\u01b0u d\\u1ef1a tr\\xean ph\\xe2n t\\xedch nhu c\\u1ea7u ng\\u01b0\\u1eddi d\\xf9ng\\\\n    \\\\n    S\\u1eec D\\u1ee4NG KHI:\\\\n    - Kh\\xe1ch h\\xe0ng C\\u1ea6N T\\u01af V\\u1ea4N: \"g\\u1ee3i \\xfd laptop cho sinh vi\\xean\", \"n\\xean mua smartphone n\\xe0o\"\\\\n    - M\\xf4 t\\u1ea3 nhu c\\u1ea7u s\\u1eed d\\u1ee5ng: \"c\\u1ea7n laptop l\\u1eadp tr\\xecnh\", \"smartphone ch\\u1ee5p \\u1ea3nh \\u0111\\u1eb9p\"\\\\n    - C\\xf3 ng\\xe2n s\\xe1ch v\\xe0 y\\xeau c\\u1ea7u: \"laptop gaming d\\u01b0\\u1edbi 30 tri\\u1ec7u\", \"iPhone hay Samsung t\\u1ed1t h\\u01a1n\"\\\\n    - Kh\\xf4ng bi\\u1ebft ch\\u1ecdn g\\xec: \"t\\u01b0 v\\u1ea5n laptop ph\\xf9 h\\u1ee3p\", \"\\u0111i\\u1ec7n tho\\u1ea1i n\\xe0o \\u0111\\xe1ng mua\"\\\\n    - So s\\xe1nh l\\u1ef1a ch\\u1ecdn: \"Dell hay HP t\\u1ed1t h\\u01a1n cho v\\u0103n ph\\xf2ng\"\\\\n    \\\\n    KH\\xd4NG d\\xf9ng cho: T\\xecm ki\\u1ebfm s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3 \\u0111\\xe3 bi\\u1ebft t\\xean\\\\n    \\\\n    OUTPUT: Top g\\u1ee3i \\xfd c\\xf3 ranking + l\\xfd do chi ti\\u1ebft t\\u1ea1i sao ph\\xf9 h\\u1ee3p'.lower\nE    +      where '\\U0001f4a1 T\\u01af V\\u1ea4N v\\xe0 G\\u1ee2I \\xdd s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p v\\u1edbi nhu c\\u1ea7u c\\xe1 nh\\xe2n.\\\\n    \\\\n    M\\u1ee4C \\u0110\\xcdCH: \\u0110\\u01b0a ra g\\u1ee3i \\xfd s\\u1ea3n ph\\u1ea9m t\\u1ed1i \\u01b0u d\\u1ef1a tr\\xean ph\\xe2n t\\xedch nhu c\\u1ea7u ng\\u01b0\\u1eddi d\\xf9ng\\\\n    \\\\n    S\\u1eec D\\u1ee4NG KHI:\\\\n    - Kh\\xe1ch h\\xe0ng C\\u1ea6N T\\u01af V\\u1ea4N: \"g\\u1ee3i \\xfd laptop cho sinh vi\\xean\", \"n\\xean mua smartphone n\\xe0o\"\\\\n    - M\\xf4 t\\u1ea3 nhu c\\u1ea7u s\\u1eed d\\u1ee5ng: \"c\\u1ea7n laptop l\\u1eadp tr\\xecnh\", \"smartphone ch\\u1ee5p \\u1ea3nh \\u0111\\u1eb9p\"\\\\n    - C\\xf3 ng\\xe2n s\\xe1ch v\\xe0 y\\xeau c\\u1ea7u: \"laptop gaming d\\u01b0\\u1edbi 30 tri\\u1ec7u\", \"iPhone hay Samsung t\\u1ed1t h\\u01a1n\"\\\\n    - Kh\\xf4ng bi\\u1ebft ch\\u1ecdn g\\xec: \"t\\u01b0 v\\u1ea5n laptop ph\\xf9 h\\u1ee3p\", \"\\u0111i\\u1ec7n tho\\u1ea1i n\\xe0o \\u0111\\xe1ng mua\"\\\\n    - So s\\xe1nh l\\u1ef1a ch\\u1ecdn: \"Dell hay HP t\\u1ed1t h\\u01a1n cho v\\u0103n ph\\xf2ng\"\\\\n    \\\\n    KH\\xd4NG d\\xf9ng cho: T\\xecm ki\\u1ebfm s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3 \\u0111\\xe3 bi\\u1ebft t\\xean\\\\n    \\\\n    OUTPUT: Top g\\u1ee3i \\xfd c\\xf3 ranking + l\\xfd do chi ti\\u1ebft t\\u1ea1i sao ph\\xf9 h\\u1ee3p' = RecommendTool().description\n_______________ TestReviewTool.test_review_tool_initialization ________________\ntests\\unit\\test_tools.py:292: in test_review_tool_initialization\n    assert tool.name == \"get_reviews\"\nE   AssertionError: assert 'get_product_reviews' == 'get_reviews'\nE     \nE     - get_reviews\nE     + get_product_reviews\n___________ TestGenerationTool.test_generation_tool_initialization ____________\ntests\\unit\\test_tools.py:358: in test_generation_tool_initialization\n    assert tool.name == \"generate_response\"\nE   AssertionError: assert 'answer_with_context' == 'generate_response'\nE     \nE     - generate_response\nE     + answer_with_context\n_______________ TestGenerationTool.test_generation_tool_success _______________\ntests\\unit\\test_tools.py:377: in test_generation_tool_success\n    result = tool.run(json.dumps(generation_input))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:888: in run\n    raise error_to_raise\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:850: in run\n    tool_args, tool_kwargs = self._to_args_and_kwargs(\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:765: in _to_args_and_kwargs\n    tool_input = self._parse_input(tool_input, tool_call_id)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:646: in _parse_input\n    input_args.model_validate({key_: tool_input})\nE   pydantic_core._pydantic_core.ValidationError: 1 validation error for GenerationInput\nE   intent\nE     Field required [type=missing, input_value={'user_query': '{\"query\":...ersation_history\": []}'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\n_____________ TestGenerationTool.test_generation_tool_llm_failure _____________\ntests\\unit\\test_tools.py:399: in test_generation_tool_llm_failure\n    result = tool.run(json.dumps(generation_input))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:888: in run\n    raise error_to_raise\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:850: in run\n    tool_args, tool_kwargs = self._to_args_and_kwargs(\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:765: in _to_args_and_kwargs\n    tool_input = self._parse_input(tool_input, tool_call_id)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:646: in _parse_input\n    input_args.model_validate({key_: tool_input})\nE   pydantic_core._pydantic_core.ValidationError: 1 validation error for GenerationInput\nE   intent\nE     Field required [type=missing, input_value={'user_query': '{\"query\":...text\": \"Test context\"}'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\n_____________ TestToolIntegration.test_tools_return_json_strings ______________\ntests\\unit\\test_tools.py:451: in test_tools_return_json_strings\n    result = tool.run(test_input)\n             ^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:888: in run\n    raise error_to_raise\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:850: in run\n    tool_args, tool_kwargs = self._to_args_and_kwargs(\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:765: in _to_args_and_kwargs\n    tool_input = self._parse_input(tool_input, tool_call_id)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:646: in _parse_input\n    input_args.model_validate({key_: tool_input})\nE   pydantic_core._pydantic_core.ValidationError: 1 validation error for GenerationInput\nE   intent\nE     Field required [type=missing, input_value={'user_query': '{\"query\":...t\", \"context\": \"test\"}'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\n\nDuring handling of the above exception, another exception occurred:\ntests\\unit\\test_tools.py:455: in test_tools_return_json_strings\n    pytest.fail(f\"Tool {tool.name} failed to return valid JSON: {e}\")\nE   Failed: Tool answer_with_context failed to return valid JSON: 1 validation error for GenerationInput\nE   intent\nE     Field required [type=missing, input_value={'user_query': '{\"query\":...t\", \"context\": \"test\"}'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:12 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'test'}\\n2025-08-23 13:11:12 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'test'}\\n2025-08-23 13:11:12 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'test'\\n2025-08-23 13:11:12 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'test'\\n2025-08-23 13:11:12 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: None\\n2025-08-23 13:11:12 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: None\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'bc50670603898101cf074d8ee159455c', 'date': 'Sat, 23 Aug 2025 06:11:09 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'bc50670603898101cf074d8ee159455c', 'date': 'Sat, 23 Aug 2025 06:11:09 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Parsed JSON tool input: {'product_ids': ['test'], 'comparison_aspects': ['price']}\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Parsed JSON tool input: {'product_ids': ['test'], 'comparison_aspects': ['price']}\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Raw input - product_ids type: <class 'list'>, value: ['test']\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Raw input - product_ids type: <class 'list'>, value: ['test']\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Raw input - comparison_aspects: ['price']\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Raw input - comparison_aspects: ['price']\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Raw input - kwargs: {}\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Raw input - kwargs: {}\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Trying to parse JSON string: test\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Trying to parse JSON string: test\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - ERROR - \\U0001f527 JSON decode error: Expecting value: line 1 column 1 (char 0)\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - ERROR - \\U0001f527 JSON decode error: Expecting value: line 1 column 1 (char 0)\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f50d Comparing products: ['test']\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f50d Comparing products: ['test']\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f50d Comparison aspects: ['price']\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f50d Comparison aspects: ['price']\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f50d Product count: 1\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f50d Product count: 1\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f527 Parsed JSON tool input: {'user_needs': 'test', 'budget': 1000000}\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f527 Parsed JSON tool input: {'user_needs': 'test', 'budget': 1000000}\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f3af Generating recommendations for: 'test'\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f3af Generating recommendations for: 'test'\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f4ca Recommendation metadata: None\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f4ca Recommendation metadata: None\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f50d Search filters applied: {'rating': {'$gte': 3.5}}\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f50d Search filters applied: {'rating': {'$gte': 3.5}}\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'ac36d9bf64da1452cf074d8ee159430d', 'date': 'Sat, 23 Aug 2025 06:11:09 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'ac36d9bf64da1452cf074d8ee159430d', 'date': 'Sat, 23 Aug 2025 06:11:09 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.recommend_tool - ERROR - \\u274c Recommend tool error: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'ac36d9bf64da1452cf074d8ee159430d', 'date': 'Sat, 23 Aug 2025 06:11:09 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.recommend_tool - ERROR - \\u274c Recommend tool error: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'ac36d9bf64da1452cf074d8ee159430d', 'date': 'Sat, 23 Aug 2025 06:11:09 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.review_tool - INFO - \\U0001f4dd Getting reviews for product: '{\"product_id\": \"test\"}'\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.review_tool - INFO - \\U0001f4dd Getting reviews for product: '{\"product_id\": \"test\"}'\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'a625606aa862023fcf074d8ee1594031', 'date': 'Sat, 23 Aug 2025 06:11:10 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'a625606aa862023fcf074d8ee1594031', 'date': 'Sat, 23 Aug 2025 06:11:10 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.review_tool - ERROR - \\u274c Error finding product: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'a625606aa862023fcf074d8ee1594031', 'date': 'Sat, 23 Aug 2025 06:11:10 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.review_tool - ERROR - \\u274c Error finding product: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'a625606aa862023fcf074d8ee1594031', 'date': 'Sat, 23 Aug 2025 06:11:10 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f527 Parsed JSON tool input: {'query': 'test'}\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f50d Searching products with query: 'test'\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f3af Search metadata: None\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'bc50670603898101cf074d8ee159455c', 'date': 'Sat, 23 Aug 2025 06:11:09 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f527 Parsed JSON tool input: {'product_ids': ['test'], 'comparison_aspects': ['price']}\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f527 Raw input - product_ids type: <class 'list'>, value: ['test']\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f527 Raw input - comparison_aspects: ['price']\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f527 Raw input - kwargs: {}\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f527 Trying to parse JSON string: test\\nERROR    ecommerce_ai_advisor.compare_tool:logger.py:90 \\U0001f527 JSON decode error: Expecting value: line 1 column 1 (char 0)\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f50d Comparing products: ['test']\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f50d Comparison aspects: ['price']\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f50d Product count: 1\\nINFO     ecommerce_ai_advisor.recommend_tool:logger.py:79 \\U0001f527 Parsed JSON tool input: {'user_needs': 'test', 'budget': 1000000}\\nINFO     ecommerce_ai_advisor.recommend_tool:logger.py:79 \\U0001f3af Generating recommendations for: 'test'\\nINFO     ecommerce_ai_advisor.recommend_tool:logger.py:79 \\U0001f4ca Recommendation metadata: None\\nINFO     ecommerce_ai_advisor.recommend_tool:logger.py:79 \\U0001f50d Search filters applied: {'rating': {'$gte': 3.5}}\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'ac36d9bf64da1452cf074d8ee159430d', 'date': 'Sat, 23 Aug 2025 06:11:09 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\nERROR    ecommerce_ai_advisor.recommend_tool:logger.py:90 \\u274c Recommend tool error: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'ac36d9bf64da1452cf074d8ee159430d', 'date': 'Sat, 23 Aug 2025 06:11:09 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\nINFO     ecommerce_ai_advisor.review_tool:logger.py:79 \\U0001f4dd Getting reviews for product: '{\"product_id\": \"test\"}'\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'a625606aa862023fcf074d8ee1594031', 'date': 'Sat, 23 Aug 2025 06:11:10 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\nERROR    ecommerce_ai_advisor.review_tool:logger.py:90 \\u274c Error finding product: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'a625606aa862023fcf074d8ee1594031', 'date': 'Sat, 23 Aug 2025 06:11:10 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\n__________ TestToolIntegration.test_tool_manager_contains_all_tools ___________\ntests\\unit\\test_tools.py:475: in test_tool_manager_contains_all_tools\n    assert expected_name in manager_tool_names\nE   AssertionError: assert 'get_reviews' in ['search_products', 'compare_products', 'recommend_products', 'get_product_reviews']\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:14 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:11:14 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.tool_manager:logger.py:79 \\u2705 ToolManager initialized with 4 tools\n============================== warnings summary ===============================\ntests/unit/test_tools.py::TestToolManager::test_describe_tools\ntests/unit/test_tools.py::TestToolManager::test_describe_tools\ntests/unit/test_tools.py::TestToolManager::test_describe_tools\ntests/unit/test_tools.py::TestToolManager::test_describe_tools\n  C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\\src\\tools\\tool_manager.py:52: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n    \"schema\": tool.args_schema.schema() if tool.args_schema else None\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ===========================\nFAILED tests/unit/test_tools.py::TestSearchTool::test_search_tool_initialization\nFAILED tests/unit/test_tools.py::TestCompareTool::test_compare_tool_initialization\nFAILED tests/unit/test_tools.py::TestRecommendTool::test_recommend_tool_initialization\nFAILED tests/unit/test_tools.py::TestReviewTool::test_review_tool_initialization\nFAILED tests/unit/test_tools.py::TestGenerationTool::test_generation_tool_initialization\nFAILED tests/unit/test_tools.py::TestGenerationTool::test_generation_tool_success\nFAILED tests/unit/test_tools.py::TestGenerationTool::test_generation_tool_llm_failure\nFAILED tests/unit/test_tools.py::TestToolIntegration::test_tools_return_json_strings\nFAILED tests/unit/test_tools.py::TestToolIntegration::test_tool_manager_contains_all_tools\n================== 9 failed, 21 passed, 4 warnings in 5.58s ===================\n",
      "stderr": "",
      "returncode": 1
    },
    "unit_agents": {
      "status": "FAILED",
      "duration": 5.339763641357422,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.13.6, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\MinhTC\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\ncachedir: .pytest_cache\nrootdir: C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, langsmith-0.4.13, asyncio-1.1.0, cov-6.2.1, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 22 items\n\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_agent_initialization PASSED [  4%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_create_graph_structure FAILED [  9%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_classify_intent_with_llm_success FAILED [ 13%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_classify_intent_with_llm_failure PASSED [ 18%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_classify_intent_with_rules FAILED [ 22%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_analyze_intent_node PASSED [ 27%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_handle_greeting_node PASSED [ 31%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_search_products_node PASSED [ 36%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_compare_products_node PASSED [ 40%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_recommend_products_node PASSED [ 45%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_get_reviews_node FAILED [ 50%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_generate_response_node PASSED [ 54%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_handle_error_node PASSED [ 59%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_route_after_intent_analysis FAILED [ 63%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_route_to_response_or_error FAILED [ 68%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_extract_search_params FAILED [ 72%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_chat_method PASSED [ 77%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_chat_method_with_error PASSED [ 81%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_clear_memory PASSED [ 86%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_agent_state_structure PASSED [ 90%]\ntests/unit/test_agents.py::TestAgentManager::test_get_agent_manager PASSED [ 95%]\ntests/unit/test_agents.py::TestAgentManager::test_get_langgraph_agent_manager FAILED [100%]\n\n================================== FAILURES ===================================\n________ TestProductAdvisorLangGraphAgent.test_create_graph_structure _________\ntests\\unit\\test_agents.py:54: in test_create_graph_structure\n    graph_dict = agent.graph.get_graph().to_dict()\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'Graph' object has no attribute 'to_dict'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:19 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:19 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\n___ TestProductAdvisorLangGraphAgent.test_classify_intent_with_llm_success ____\ntests\\unit\\test_agents.py:81: in test_classify_intent_with_llm_success\n    assert intent == \"search\"\nE   AssertionError: assert None == 'search'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:19 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:19 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:19 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f LLM returned invalid intent: <MagicMock name='llm_service.get_llm().invoke().content.strip().lower()' id='1614900232272'>\\n2025-08-23 13:11:19 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f LLM returned invalid intent: <MagicMock name='llm_service.get_llm().invoke().content.strip().lower()' id='1614900232272'>\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\\nWARNING  ecommerce_ai_advisor.langgraph_agent:logger.py:83 \\u26a0\\ufe0f LLM returned invalid intent: <MagicMock name='llm_service.get_llm().invoke().content.strip().lower()' id='1614900232272'>\n______ TestProductAdvisorLangGraphAgent.test_classify_intent_with_rules _______\ntests\\unit\\test_agents.py:111: in test_classify_intent_with_rules\n    assert intent == expected_intent\nE   AssertionError: assert 'search' == 'review'\nE     \nE     - review\nE     + search\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:19 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:19 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\n___________ TestProductAdvisorLangGraphAgent.test_get_reviews_node ____________\ntests\\unit\\test_agents.py:235: in test_get_reviews_node\n    assert \"get_reviews\" in result_state[\"tools_used\"]\nE   AssertionError: assert 'get_reviews' in ['get_product_reviews']\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f3af Extracted review params: {'product_name': 'dell xps 13', 'limit': 5, 'sort_by': 'newest'}\\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f3af Extracted review params: {'product_name': 'dell xps 13', 'limit': 5, 'sort_by': 'newest'}\\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Reviews retrieved successfully\\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Reviews retrieved successfully\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f3af Extracted review params: {'product_name': 'dell xps 13', 'limit': 5, 'sort_by': 'newest'}\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Reviews retrieved successfully\n______ TestProductAdvisorLangGraphAgent.test_route_after_intent_analysis ______\ntests\\unit\\test_agents.py:283: in test_route_after_intent_analysis\n    route = agent._route_after_intent_analysis(state)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'ProductAdvisorLangGraphAgent' object has no attribute '_route_after_intent_analysis'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\n______ TestProductAdvisorLangGraphAgent.test_route_to_response_or_error _______\ntests\\unit\\test_agents.py:298: in test_route_to_response_or_error\n    route = agent._route_to_response_or_error(state)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'ProductAdvisorLangGraphAgent' object has no attribute '_route_to_response_or_error'\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\n_________ TestProductAdvisorLangGraphAgent.test_extract_search_params _________\ntests\\unit\\test_agents.py:317: in test_extract_search_params\n    assert params[key] == value\nE   AssertionError: assert 'laptop Dell d\\u01b0\\u1edbi 20 tri\\u1ec7u' == 'laptop Dell'\nE     \nE     - laptop Dell\nE     + laptop Dell d\\u01b0\\u1edbi 20 tri\\u1ec7u\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f Failed to extract search params: the JSON object must be str, bytes or bytearray, not MagicMock\\n2025-08-23 13:11:20 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f Failed to extract search params: the JSON object must be str, bytes or bytearray, not MagicMock\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\\nWARNING  ecommerce_ai_advisor.langgraph_agent:logger.py:83 \\u26a0\\ufe0f Failed to extract search params: the JSON object must be str, bytes or bytearray, not MagicMock\n______________ TestAgentManager.test_get_langgraph_agent_manager ______________\ntests\\unit\\test_agents.py:404: in test_get_langgraph_agent_manager\n    from src.agents.langgraph_agent import get_langgraph_agent_manager\nE   ImportError: cannot import name 'get_langgraph_agent_manager' from 'src.agents.langgraph_agent' (C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\\src\\agents\\langgraph_agent.py)\n=========================== short test summary info ===========================\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_create_graph_structure\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_classify_intent_with_llm_success\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_classify_intent_with_rules\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_get_reviews_node\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_route_after_intent_analysis\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_route_to_response_or_error\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_extract_search_params\nFAILED tests/unit/test_agents.py::TestAgentManager::test_get_langgraph_agent_manager\n======================== 8 failed, 14 passed in 3.65s =========================\n",
      "stderr": "",
      "returncode": 1
    },
    "unit_utilities": {
      "status": "FAILED",
      "duration": 5.020501613616943,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.13.6, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\MinhTC\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\ncachedir: .pytest_cache\nrootdir: C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, langsmith-0.4.13, asyncio-1.1.0, cov-6.2.1, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 27 items\n\ntests/unit/test_utils.py::TestLogger::test_logger_initialization PASSED  [  3%]\ntests/unit/test_utils.py::TestLogger::test_logger_debug PASSED           [  7%]\ntests/unit/test_utils.py::TestLogger::test_logger_info PASSED            [ 11%]\ntests/unit/test_utils.py::TestLogger::test_logger_warning PASSED         [ 14%]\ntests/unit/test_utils.py::TestLogger::test_logger_error PASSED           [ 18%]\ntests/unit/test_utils.py::TestLogger::test_logger_critical PASSED        [ 22%]\ntests/unit/test_utils.py::TestLogger::test_get_logger_function PASSED    [ 25%]\ntests/unit/test_utils.py::TestLogger::test_setup_logger_function PASSED  [ 29%]\ntests/unit/test_utils.py::TestLogger::test_track_time_decorator_success PASSED [ 33%]\ntests/unit/test_utils.py::TestLogger::test_track_time_decorator_failure PASSED [ 37%]\ntests/unit/test_utils.py::TestPromptHelper::test_prompt_helper_initialization PASSED [ 40%]\ntests/unit/test_utils.py::TestPromptHelper::test_clean_text FAILED       [ 44%]\ntests/unit/test_utils.py::TestPromptHelper::test_truncate_text FAILED    [ 48%]\ntests/unit/test_utils.py::TestPromptHelper::test_extract_keywords FAILED [ 51%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_price FAILED     [ 55%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_product_list FAILED [ 59%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_comparison_table FAILED [ 62%]\ntests/unit/test_utils.py::TestPromptHelper::test_extract_price_from_text FAILED [ 66%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_vietnamese_text FAILED [ 70%]\ntests/unit/test_utils.py::TestPromptHelper::test_safe_format_prompt FAILED [ 74%]\ntests/unit/test_utils.py::TestPromptHelper::test_safe_format_prompt_failure FAILED [ 77%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_conversation_history FAILED [ 81%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_tool_results FAILED [ 85%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_error_message PASSED [ 88%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_error_message_exception_handling PASSED [ 92%]\ntests/unit/test_utils.py::TestPromptHelper::test_validate_vietnamese_input FAILED [ 96%]\ntests/unit/test_utils.py::TestPromptHelper::test_normalize_query FAILED  [100%]\n\n================================== FAILURES ===================================\n______________________ TestPromptHelper.test_clean_text _______________________\ntests\\unit\\test_utils.py:169: in test_clean_text\n    result = prompt_helper.clean_text(input_text)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PromptHelper' object has no attribute 'clean_text'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:24 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:24 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n_____________________ TestPromptHelper.test_truncate_text _____________________\ntests\\unit\\test_utils.py:176: in test_truncate_text\n    result = prompt_helper.truncate_text(long_text, max_length=20)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PromptHelper' object has no attribute 'truncate_text'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n___________________ TestPromptHelper.test_extract_keywords ____________________\ntests\\unit\\test_utils.py:192: in test_extract_keywords\n    keywords = prompt_helper.extract_keywords(text)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PromptHelper' object has no attribute 'extract_keywords'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n_____________________ TestPromptHelper.test_format_price ______________________\ntests\\unit\\test_utils.py:211: in test_format_price\n    result = prompt_helper.format_price(price)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PromptHelper' object has no attribute 'format_price'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n__________________ TestPromptHelper.test_format_product_list __________________\ntests\\unit\\test_utils.py:216: in test_format_product_list\n    formatted = prompt_helper.format_product_list(sample_products)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PromptHelper' object has no attribute 'format_product_list'. Did you mean: 'format_products_list'?\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n________________ TestPromptHelper.test_format_comparison_table ________________\ntests\\unit\\test_utils.py:236: in test_format_comparison_table\n    assert \"Dell XPS 13\" in formatted\nE   AssertionError: assert 'Dell XPS 13' in 'Kh\\xf4ng th\\u1ec3 t\\u1ea1o b\\u1ea3ng so s\\xe1nh'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - ERROR - Error formatting comparison table: 0\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - ERROR - Error formatting comparison table: 0\n------------------------------ Captured log call ------------------------------\nERROR    ecommerce_ai_advisor.prompt_helper:logger.py:90 Error formatting comparison table: 0\n________________ TestPromptHelper.test_extract_price_from_text ________________\ntests\\unit\\test_utils.py:253: in test_extract_price_from_text\n    result = prompt_helper.extract_price_from_text(text)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PromptHelper' object has no attribute 'extract_price_from_text'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n________________ TestPromptHelper.test_format_vietnamese_text _________________\ntests\\unit\\test_utils.py:263: in test_format_vietnamese_text\n    formatted = prompt_helper.format_vietnamese_text(vietnamese_text)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PromptHelper' object has no attribute 'format_vietnamese_text'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n__________________ TestPromptHelper.test_safe_format_prompt ___________________\ntests\\unit\\test_utils.py:272: in test_safe_format_prompt\n    with patch('src.utils.prompt_helper.prompt_manager') as mock_prompt_manager:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <module 'src.utils.prompt_helper' from 'C:\\\\Users\\\\MinhTC\\\\Desktop\\\\Hackaton\\\\evlevate-dn-03\\\\Workshop_final\\\\src\\\\utils\\\\prompt_helper.py'> does not have the attribute 'prompt_manager'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n______________ TestPromptHelper.test_safe_format_prompt_failure _______________\ntests\\unit\\test_utils.py:287: in test_safe_format_prompt_failure\n    with patch('src.utils.prompt_helper.prompt_manager') as mock_prompt_manager:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <module 'src.utils.prompt_helper' from 'C:\\\\Users\\\\MinhTC\\\\Desktop\\\\Hackaton\\\\evlevate-dn-03\\\\Workshop_final\\\\src\\\\utils\\\\prompt_helper.py'> does not have the attribute 'prompt_manager'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n______________ TestPromptHelper.test_format_conversation_history ______________\ntests\\unit\\test_utils.py:298: in test_format_conversation_history\n    formatted = prompt_helper.format_conversation_history(sample_conversation_history)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PromptHelper' object has no attribute 'format_conversation_history'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n__________________ TestPromptHelper.test_format_tool_results __________________\ntests\\unit\\test_utils.py:313: in test_format_tool_results\n    formatted = prompt_helper.format_tool_results(tool_results)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PromptHelper' object has no attribute 'format_tool_results'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n_______________ TestPromptHelper.test_validate_vietnamese_input _______________\ntests\\unit\\test_utils.py:355: in test_validate_vietnamese_input\n    result = prompt_helper.validate_vietnamese_input(text)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PromptHelper' object has no attribute 'validate_vietnamese_input'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n____________________ TestPromptHelper.test_normalize_query ____________________\ntests\\unit\\test_utils.py:369: in test_normalize_query\n    result = prompt_helper.normalize_query(input_query)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'PromptHelper' object has no attribute 'normalize_query'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:25 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n=========================== short test summary info ===========================\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_clean_text - Attribut...\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_truncate_text - Attri...\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_extract_keywords - At...\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_format_price - Attrib...\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_format_product_list\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_format_comparison_table\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_extract_price_from_text\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_format_vietnamese_text\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_safe_format_prompt - ...\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_safe_format_prompt_failure\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_format_conversation_history\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_format_tool_results\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_validate_vietnamese_input\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_normalize_query - Att...\n======================== 14 failed, 13 passed in 3.32s ========================\n",
      "stderr": "",
      "returncode": 1
    },
    "unit_prompts": {
      "status": "FAILED",
      "duration": 5.0250184535980225,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.13.6, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\MinhTC\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\ncachedir: .pytest_cache\nrootdir: C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, langsmith-0.4.13, asyncio-1.1.0, cov-6.2.1, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 26 items\n\ntests/unit/test_prompts.py::TestPromptType::test_prompt_type_enum_values FAILED [  3%]\ntests/unit/test_prompts.py::TestPromptType::test_prompt_type_enum_is_enum PASSED [  7%]\ntests/unit/test_prompts.py::TestPromptManager::test_prompt_manager_initialization FAILED [ 11%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_intent_classification FAILED [ 15%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_search_system FAILED [ 19%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_compare_system FAILED [ 23%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_recommend_system FAILED [ 26%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_review_system FAILED [ 30%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_base_system FAILED [ 34%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_search FAILED [ 38%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_compare FAILED [ 42%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_recommend FAILED [ 46%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_review FAILED [ 50%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_direct FAILED [ 53%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_error_handling FAILED [ 57%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_greeting_response FAILED [ 61%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_invalid_type PASSED [ 65%]\ntests/unit/test_prompts.py::TestPromptManager::test_format_prompt_with_variables PASSED [ 69%]\ntests/unit/test_prompts.py::TestPromptManager::test_build_generation_prompt PASSED [ 73%]\ntests/unit/test_prompts.py::TestPromptManager::test_build_generation_prompt_minimal PASSED [ 76%]\ntests/unit/test_prompts.py::TestPromptManager::test_build_generation_prompt_error_handling PASSED [ 80%]\ntests/unit/test_prompts.py::TestPromptManager::test_prompt_templates_have_required_placeholders FAILED [ 84%]\ntests/unit/test_prompts.py::TestPromptManager::test_prompt_templates_are_vietnamese_friendly FAILED [ 88%]\ntests/unit/test_prompts.py::TestPromptManager::test_singleton_prompt_manager PASSED [ 92%]\ntests/unit/test_prompts.py::TestPromptManager::test_prompt_consistency PASSED [ 96%]\ntests/unit/test_prompts.py::TestPromptManager::test_all_prompt_types_have_prompts FAILED [100%]\n\n================================== FAILURES ===================================\n_________________ TestPromptType.test_prompt_type_enum_values _________________\ntests\\unit\\test_prompts.py:40: in test_prompt_type_enum_values\n    assert expected_type in actual_types\nE   AssertionError: assert 'SEARCH_SYSTEM' in ['SYSTEM_BASE', 'RECOMMEND_EXPLANATION', 'COMPARE_ANALYSIS', 'FALLBACK_SYSTEM', 'INTENT_CLASSIFICATION', 'SEARCH_EXTRACTION', ...]\n____________ TestPromptManager.test_prompt_manager_initialization _____________\ntests\\unit\\test_prompts.py:59: in test_prompt_manager_initialization\n    assert hasattr(prompt_manager, 'prompts')\nE   AssertionError: assert False\nE    +  where False = hasattr(<src.prompts.prompt_manager.PromptManager object at 0x000001F4DB43C050>, 'prompts')\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n___________ TestPromptManager.test_get_prompt_intent_classification ___________\ntests\\unit\\test_prompts.py:68: in test_get_prompt_intent_classification\n    assert isinstance(prompt, str)\nE   assert False\nE    +  where False = isinstance(PromptTemplate(input_variables=['user_input'], input_types={}, partial_variables={}, template='Ph\\xe2n t\\xedch \\xfd \\u0111\\u1ecbnh c\\u1ee7a ng\\u01b0\\u1eddi d\\xf9ng v\\xe0 tr\\u1ea3 v\\u1ec1 CH\\xcdNH X\\xc1C m\\u1ed9t trong c\\xe1c intent sau:\\\\n\\\\nINTENT OPTIONS:\\\\n- greeting: Ch\\xe0o h\\u1ecfi, c\\u1ea3m \\u01a1n, h\\u1ecfi v\\u1ec1 AI\\\\n- search: T\\xecm ki\\u1ebfm th\\xf4ng tin s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3, h\\u1ecfi c\\u1ea5u h\\xecnh, th\\xf4ng s\\u1ed1, gi\\xe1\\\\n- compare: So s\\xe1nh 2+ s\\u1ea3n ph\\u1ea9m\\\\n- recommend: Xin g\\u1ee3i \\xfd, t\\u01b0 v\\u1ea5n s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p v\\u1edbi nhu c\\u1ea7u\\\\n- review: Xem \\u0111\\xe1nh gi\\xe1, nh\\u1eadn x\\xe9t, reviews c\\u1ee7a s\\u1ea3n ph\\u1ea9m\\\\n- direct: C\\xe2u h\\u1ecfi t\\u1ed5ng qu\\xe1t v\\u1ec1 c\\xf4ng ngh\\u1ec7, thu\\u1eadt ng\\u1eef, kh\\xe1i ni\\u1ec7m\\\\n\\\\nUSER INPUT: \"{user_input}\"\\\\n\\\\nEXAMPLES:\\\\n- \"Xin ch\\xe0o\" \\u2192 greeting\\\\n- \"Dell Inspiron 14 5420 c\\u1ea5u h\\xecnh nh\\u01b0 th\\u1ebf n\\xe0o\" \\u2192 search\\\\n- \"iPhone 15 vs Samsung S24\" \\u2192 compare\\\\n- \"G\\u1ee3i \\xfd laptop cho sinh vi\\xean\" \\u2192 recommend\\\\n- \"T\\xf4i mu\\u1ed1n xem reviews iPhone 15\" \\u2192 review\\\\n- \"\\u0110\\xe1nh gi\\xe1 v\\u1ec1 Dell XPS 15\" \\u2192 review\\\\n- \"Ng\\u01b0\\u1eddi d\\xf9ng n\\xf3i g\\xec v\\u1ec1 Samsung S24?\" \\u2192 review\\\\n- \"Reviews laptop gaming ASUS ROG\" \\u2192 review\\\\n- \"C\\u1ea3m \\u01a1n b\\u1ea1n\" \\u2192 greeting\\\\n- \"RAM l\\xe0 g\\xec?\" \\u2192 direct\\\\n- \"S\\u1ef1 kh\\xe1c bi\\u1ec7t gi\\u1eefa SSD v\\xe0 HDD\" \\u2192 direct\\\\n- \"CPU Intel Core i7 ngh\\u0129a l\\xe0 g\\xec?\" \\u2192 direct\\\\n- \"L\\xe0m th\\u1ebf n\\xe0o \\u0111\\u1ec3 ch\\u1ecdn laptop ph\\xf9 h\\u1ee3p?\" \\u2192 direct\\\\n- \"M\\xe0n h\\xecnh OLED c\\xf3 \\u01b0u \\u0111i\\u1ec3m g\\xec?\" \\u2192 direct\\\\n- \"Xu h\\u01b0\\u1edbng smartphone 2024\" \\u2192 direct\\\\n\\\\nCh\\u1ec9 tr\\u1ea3 v\\u1ec1 T\\xcaN INTENT (greeting/search/compare/recommend/review/direct):'), str)\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_______________ TestPromptManager.test_get_prompt_search_system _______________\ntests\\unit\\test_prompts.py:75: in test_get_prompt_search_system\n    prompt = prompt_manager.get_prompt(PromptType.SEARCH_SYSTEM)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: type object 'PromptType' has no attribute 'SEARCH_SYSTEM'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n______________ TestPromptManager.test_get_prompt_compare_system _______________\ntests\\unit\\test_prompts.py:85: in test_get_prompt_compare_system\n    prompt = prompt_manager.get_prompt(PromptType.COMPARE_SYSTEM)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: type object 'PromptType' has no attribute 'COMPARE_SYSTEM'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_____________ TestPromptManager.test_get_prompt_recommend_system ______________\ntests\\unit\\test_prompts.py:94: in test_get_prompt_recommend_system\n    prompt = prompt_manager.get_prompt(PromptType.RECOMMEND_SYSTEM)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: type object 'PromptType' has no attribute 'RECOMMEND_SYSTEM'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_______________ TestPromptManager.test_get_prompt_review_system _______________\ntests\\unit\\test_prompts.py:103: in test_get_prompt_review_system\n    prompt = prompt_manager.get_prompt(PromptType.REVIEW_SYSTEM)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: type object 'PromptType' has no attribute 'REVIEW_SYSTEM'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n__________ TestPromptManager.test_get_prompt_generation_base_system ___________\ntests\\unit\\test_prompts.py:116: in test_get_prompt_generation_base_system\n    assert isinstance(prompt, str)\nE   AssertionError: assert False\nE    +  where False = isinstance(PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='B\\u1ea1n l\\xe0 AI Product Advisor - tr\\u1ee3 l\\xfd t\\u01b0 v\\u1ea5n s\\u1ea3n ph\\u1ea9m \\u0111i\\u1ec7n t\\u1eed chuy\\xean nghi\\u1ec7p.\\\\n\\\\n\\U0001f3af NHI\\u1ec6M V\\u1ee4: T\\u1ea1o c\\xe2u tr\\u1ea3 l\\u1eddi t\\u1ef1 nhi\\xean, h\\u1eefu \\xedch d\\u1ef1a tr\\xean th\\xf4ng tin s\\u1ea3n ph\\u1ea9m \\u0111\\u01b0\\u1ee3c cung c\\u1ea5p.\\\\n\\\\n\\u26a1 NGUY\\xcaN T\\u1eaeC:\\\\n- Lu\\xf4n d\\u1ef1a tr\\xean th\\xf4ng tin ch\\xednh x\\xe1c t\\u1eeb context\\\\n- Ng\\xf4n ng\\u1eef t\\u1ef1 nhi\\xean, th\\xe2n thi\\u1ec7n nh\\u01b0 b\\u1ea1n b\\xe8 am hi\\u1ec3u c\\xf4ng ngh\\u1ec7\\\\n- Gi\\u1ea3i th\\xedch thu\\u1eadt ng\\u1eef k\\u1ef9 thu\\u1eadt b\\u1eb1ng c\\xe1ch d\\u1ec5 hi\\u1ec3u\\\\n- \\u0110\\u01b0a ra l\\u1eddi khuy\\xean thi\\u1ebft th\\u1ef1c v\\xe0 c\\xf3 c\\u0103n c\\u1ee9'), str)\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_____________ TestPromptManager.test_get_prompt_generation_search _____________\ntests\\unit\\test_prompts.py:121: in test_get_prompt_generation_search\n    prompt = prompt_manager.get_prompt(PromptType.GENERATION_SEARCH)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: type object 'PromptType' has no attribute 'GENERATION_SEARCH'. Did you mean: 'GENERATION_SEARCH_INTENT'?\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n____________ TestPromptManager.test_get_prompt_generation_compare _____________\ntests\\unit\\test_prompts.py:130: in test_get_prompt_generation_compare\n    prompt = prompt_manager.get_prompt(PromptType.GENERATION_COMPARE)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: type object 'PromptType' has no attribute 'GENERATION_COMPARE'. Did you mean: 'GENERATION_COMPARE_INTENT'?\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n___________ TestPromptManager.test_get_prompt_generation_recommend ____________\ntests\\unit\\test_prompts.py:139: in test_get_prompt_generation_recommend\n    prompt = prompt_manager.get_prompt(PromptType.GENERATION_RECOMMEND)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: type object 'PromptType' has no attribute 'GENERATION_RECOMMEND'. Did you mean: 'GENERATION_RECOMMEND_INTENT'?\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_____________ TestPromptManager.test_get_prompt_generation_review _____________\ntests\\unit\\test_prompts.py:148: in test_get_prompt_generation_review\n    prompt = prompt_manager.get_prompt(PromptType.GENERATION_REVIEW)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: type object 'PromptType' has no attribute 'GENERATION_REVIEW'. Did you mean: 'GENERATION_REVIEW_INTENT'?\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_____________ TestPromptManager.test_get_prompt_generation_direct _____________\ntests\\unit\\test_prompts.py:157: in test_get_prompt_generation_direct\n    prompt = prompt_manager.get_prompt(PromptType.GENERATION_DIRECT)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: type object 'PromptType' has no attribute 'GENERATION_DIRECT'. Did you mean: 'GENERATION_DIRECT_INTENT'?\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n______________ TestPromptManager.test_get_prompt_error_handling _______________\ntests\\unit\\test_prompts.py:166: in test_get_prompt_error_handling\n    prompt = prompt_manager.get_prompt(PromptType.ERROR_HANDLING)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: type object 'PromptType' has no attribute 'ERROR_HANDLING'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_____________ TestPromptManager.test_get_prompt_greeting_response _____________\ntests\\unit\\test_prompts.py:175: in test_get_prompt_greeting_response\n    prompt = prompt_manager.get_prompt(PromptType.GREETING_RESPONSE)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: type object 'PromptType' has no attribute 'GREETING_RESPONSE'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_____ TestPromptManager.test_prompt_templates_have_required_placeholders ______\ntests\\unit\\test_prompts.py:256: in test_prompt_templates_have_required_placeholders\n    (PromptType.GENERATION_SEARCH, [\"{user_query}\", \"{search_results}\"]),\n     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: type object 'PromptType' has no attribute 'GENERATION_SEARCH'. Did you mean: 'GENERATION_SEARCH_INTENT'?\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_______ TestPromptManager.test_prompt_templates_are_vietnamese_friendly _______\ntests\\unit\\test_prompts.py:285: in test_prompt_templates_are_vietnamese_friendly\n    PromptType.GREETING_RESPONSE,\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: type object 'PromptType' has no attribute 'GREETING_RESPONSE'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n____________ TestPromptManager.test_all_prompt_types_have_prompts _____________\ntests\\unit\\test_prompts.py:327: in test_all_prompt_types_have_prompts\n    if prompt is None or prompt.strip() == \"\":\n                         ^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydantic\\main.py:991: in __getattr__\n    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\nE   AttributeError: 'ChatPromptTemplate' object has no attribute 'strip'\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:30 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n=========================== short test summary info ===========================\nFAILED tests/unit/test_prompts.py::TestPromptType::test_prompt_type_enum_values\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_prompt_manager_initialization\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_intent_classification\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_search_system\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_compare_system\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_recommend_system\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_review_system\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_base_system\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_search\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_compare\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_recommend\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_review\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_direct\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_error_handling\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_greeting_response\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_prompt_templates_have_required_placeholders\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_prompt_templates_are_vietnamese_friendly\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_all_prompt_types_have_prompts\n======================== 18 failed, 8 passed in 3.33s =========================\n",
      "stderr": "",
      "returncode": 1
    },
    "integration": {
      "status": "FAILED",
      "duration": 16.207799673080444,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.13.6, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\MinhTC\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\ncachedir: .pytest_cache\nrootdir: C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, langsmith-0.4.13, asyncio-1.1.0, cov-6.2.1, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 13 items\n\ntests/integration/test_end_to_end.py::TestEndToEndWorkflows::test_complete_search_workflow FAILED [  7%]\ntests/integration/test_end_to_end.py::TestEndToEndWorkflows::test_complete_comparison_workflow PASSED [ 15%]\ntests/integration/test_end_to_end.py::TestEndToEndWorkflows::test_multi_turn_conversation PASSED [ 23%]\ntests/integration/test_end_to_end.py::TestEndToEndWorkflows::test_error_recovery_workflow PASSED [ 30%]\ntests/integration/test_end_to_end.py::TestEndToEndWorkflows::test_greeting_workflow PASSED [ 38%]\ntests/integration/test_end_to_end.py::TestServiceIntegration::test_llm_pinecone_integration PASSED [ 46%]\ntests/integration/test_end_to_end.py::TestServiceIntegration::test_tool_service_integration FAILED [ 53%]\ntests/integration/test_end_to_end.py::TestAgentToolIntegration::test_agent_uses_correct_tools PASSED [ 61%]\ntests/integration/test_end_to_end.py::TestAgentToolIntegration::test_tool_error_handling_in_agent FAILED [ 69%]\ntests/integration/test_end_to_end.py::TestConfigurationIntegration::test_config_used_by_services PASSED [ 76%]\ntests/integration/test_end_to_end.py::TestConfigurationIntegration::test_config_validation_integration PASSED [ 84%]\ntests/integration/test_end_to_end.py::TestMemoryIntegration::test_session_memory_persistence PASSED [ 92%]\ntests/integration/test_end_to_end.py::TestMemoryIntegration::test_session_isolation PASSED [100%]\n\n================================== FAILURES ===================================\n_____________ TestEndToEndWorkflows.test_complete_search_workflow _____________\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:948: in assert_called\n    raise AssertionError(msg)\nE   AssertionError: Expected 'search_products' to have been called.\n\nDuring handling of the above exception, another exception occurred:\ntests\\integration\\test_end_to_end.py:62: in test_complete_search_workflow\n    mock_services[\"pinecone\"].search_products.assert_called()\nE   AssertionError: Expected 'search_products' to have been called.\n---------------------------- Captured stdout setup ----------------------------\n\\u2705 Configuration loaded successfully\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:11:32 - ecommerce_ai_advisor - INFO - \\u2705 Simple logging system initialized\\n2025-08-23 13:11:32 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:32 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:11:32 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:32 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:11:32 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:32 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:11:33 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:11:33 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:11:33 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:11:33 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:11:33 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:11:33 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:11:33 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:11:33 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:11:34 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:34 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:34 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:34 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:34 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 LangGraphAgentManager initialized\\n2025-08-23 13:11:34 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 LangGraphAgentManager initialized\\n2025-08-23 13:11:34 - ecommerce_ai_advisor.ui - INFO - \\u2705 LangGraph agent available\\n2025-08-23 13:11:34 - ecommerce_ai_advisor.ui - INFO - \\u2705 LangGraph agent available\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor:logger.py:132 \\u2705 Simple logging system initialized\\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\\nINFO     ecommerce_ai_advisor.tool_manager:logger.py:79 \\u2705 ToolManager initialized with 4 tools\\nINFO     ecommerce_ai_advisor.tool_manager:logger.py:79 \\u2705 ToolManager initialized with 4 tools\\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure LangChain LLM instance created\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 LangGraphAgentManager initialized\\nINFO     ecommerce_ai_advisor.ui:logger.py:79 \\u2705 LangGraph agent available\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:34 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:11:34 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f5e3\\ufe0f Processing user input: T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u... (session: test_ses)\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f5e3\\ufe0f Processing user input: T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u... (session: test_ses)\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Retrieving conversation history for session: test_session\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Retrieving conversation history for session: test_session\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Found 0 checkpoints\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Found 0 checkpoints\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d No checkpoints found\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d No checkpoints found\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Returning empty memory context\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Returning empty memory context\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Detecting context references in user input: 't\\xecm laptop dell d\\u01b0\\u1edbi 30 tri\\u1ec7u'\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Detecting context references in user input: 't\\xecm laptop dell d\\u01b0\\u1edbi 30 tri\\u1ec7u'\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - ERROR - \\u274c LLM intent classification failed: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2919984882624'>\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - ERROR - \\u274c LLM intent classification failed: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2919984882624'>\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f3af Intent analyzed (Rules): search\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f3af Intent analyzed (Rules): search\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f Failed to extract search params: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2919984882624'>\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f Failed to extract search params: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2919984882624'>\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u', 'metadata': {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': 30000000.0, 'max_results': 3, 'include_reviews': False}}\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u', 'metadata': {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': 30000000.0, 'max_results': 3, 'include_reviews': False}}\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u'\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u'\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': 30000000.0, 'max_results': 3, 'include_reviews': False}\\n2025-08-23 13:11:35 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': 30000000.0, 'max_results': 3, 'include_reviews': False}\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'c04effb7fd50d1ebe5feff5e4550e433', 'date': 'Sat, 23 Aug 2025 06:11:31 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'c04effb7fd50d1ebe5feff5e4550e433', 'date': 'Sat, 23 Aug 2025 06:11:31 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Search completed with structured input\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Search completed with structured input\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f916 Generating response for query: 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u...'\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f916 Generating response for query: 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u...'\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f3af Intent: search\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f3af Intent: search\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f527 Tools used: ['search_products']\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f527 Tools used: ['search_products']\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.generation_tool - ERROR - \\u274c RAG generation error: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2919984882624'>\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.generation_tool - ERROR - \\u274c RAG generation error: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2919984882624'>\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Response generated with conversation history updated\\n2025-08-23 13:11:36 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Response generated with conversation history updated\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.tool_manager:logger.py:79 \\u2705 ToolManager initialized with 4 tools\\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure LangChain LLM instance created\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f5e3\\ufe0f Processing user input: T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u... (session: test_ses)\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Retrieving conversation history for session: test_session\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Found 0 checkpoints\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d No checkpoints found\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Returning empty memory context\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Detecting context references in user input: 't\\xecm laptop dell d\\u01b0\\u1edbi 30 tri\\u1ec7u'\\nERROR    ecommerce_ai_advisor.langgraph_agent:logger.py:90 \\u274c LLM intent classification failed: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2919984882624'>\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f3af Intent analyzed (Rules): search\\nWARNING  ecommerce_ai_advisor.langgraph_agent:logger.py:83 \\u26a0\\ufe0f Failed to extract search params: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2919984882624'>\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f527 Parsed JSON tool input: {'query': 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u', 'metadata': {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': 30000000.0, 'max_results': 3, 'include_reviews': False}}\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f50d Searching products with query: 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u'\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f3af Search metadata: {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': 30000000.0, 'max_results': 3, 'include_reviews': False}\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'c04effb7fd50d1ebe5feff5e4550e433', 'date': 'Sat, 23 Aug 2025 06:11:31 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Search completed with structured input\\nINFO     ecommerce_ai_advisor.generation_tool:logger.py:79 \\U0001f916 Generating response for query: 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u...'\\nINFO     ecommerce_ai_advisor.generation_tool:logger.py:79 \\U0001f3af Intent: search\\nINFO     ecommerce_ai_advisor.generation_tool:logger.py:79 \\U0001f527 Tools used: ['search_products']\\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure LangChain LLM instance created\\nERROR    ecommerce_ai_advisor.generation_tool:logger.py:90 \\u274c RAG generation error: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2919984882624'>\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Response generated with conversation history updated\n____________ TestServiceIntegration.test_tool_service_integration _____________\ntests\\integration\\test_end_to_end.py:188: in test_tool_service_integration\n    assert search_response[\"success\"] is True\nE   assert False is True\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:40 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'laptop Dell'}\\n2025-08-23 13:11:40 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'laptop Dell'}\\n2025-08-23 13:11:40 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'laptop Dell'\\n2025-08-23 13:11:40 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'laptop Dell'\\n2025-08-23 13:11:40 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: None\\n2025-08-23 13:11:40 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: None\\n2025-08-23 13:11:41 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '0950db7de40fd339e5feff5e4550e2c7', 'date': 'Sat, 23 Aug 2025 06:11:36 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:41 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '0950db7de40fd339e5feff5e4550e2c7', 'date': 'Sat, 23 Aug 2025 06:11:36 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f527 Parsed JSON tool input: {'query': 'laptop Dell'}\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f50d Searching products with query: 'laptop Dell'\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f3af Search metadata: None\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '0950db7de40fd339e5feff5e4550e2c7', 'date': 'Sat, 23 Aug 2025 06:11:36 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\n_________ TestAgentToolIntegration.test_tool_error_handling_in_agent __________\ntests\\integration\\test_end_to_end.py:275: in test_tool_error_handling_in_agent\n    assert \"error\" in response or response[\"success\"] is False\nE   assert ('error' in {'agent_type': 'langgraph', 'context_info': {'context_references_used': False, 'has_previous_context': True, 'previous_products': []}, 'intent': 'search', 'intermediate_steps': [(<src.agents.langgraph_agent.Action object at 0x000002A7DE53FCB0>, '{\"success\": false, \"error\": \"L\\\\\\\\u1ed7i k\\\\\\\\u1ebft n\\\\\\\\u1ed1i c\\\\\\\\u01a1 s\\\\\\\\u1edf d\\\\\\\\u1eef li\\\\\\\\u1ec7u: (401)\\\\\\\\nRe...'), (<src.agents.langgraph_agent.Action object at 0x000002A7DE53FE00>, 'Xin l\\u1ed7i, t\\xf4i g\\u1eb7p v\\u1ea5n \\u0111\\u1ec1 khi t\\u1ea1o c\\xe2u tr\\u1ea3 l\\u1eddi. Vui l\\xf2ng th\\u1eed l\\u1ea1i.')], ...} or True is False)\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:42 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f5e3\\ufe0f Processing user input: T\\xecm laptop Dell... (session: error_te)\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f5e3\\ufe0f Processing user input: T\\xecm laptop Dell... (session: error_te)\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Retrieving conversation history for session: error_test\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Retrieving conversation history for session: error_test\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Found 0 checkpoints\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Found 0 checkpoints\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d No checkpoints found\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d No checkpoints found\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Returning empty memory context\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Returning empty memory context\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Detecting context references in user input: 't\\xecm laptop dell'\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Detecting context references in user input: 't\\xecm laptop dell'\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f3af Intent analyzed (LLM): search\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f3af Intent analyzed (LLM): search\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f Failed to extract search params: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2920012838768'>\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f Failed to extract search params: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2920012838768'>\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'T\\xecm laptop Dell', 'metadata': {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': None, 'max_results': 3, 'include_reviews': False}}\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'T\\xecm laptop Dell', 'metadata': {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': None, 'max_results': 3, 'include_reviews': False}}\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'T\\xecm laptop Dell'\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'T\\xecm laptop Dell'\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': None, 'max_results': 3, 'include_reviews': False}\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': None, 'max_results': 3, 'include_reviews': False}\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'c561cca3344b4ab7875d006db4ce51de', 'date': 'Sat, 23 Aug 2025 06:11:38 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'c561cca3344b4ab7875d006db4ce51de', 'date': 'Sat, 23 Aug 2025 06:11:38 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Search completed with structured input\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Search completed with structured input\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f916 Generating response for query: 'T\\xecm laptop Dell...'\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f916 Generating response for query: 'T\\xecm laptop Dell...'\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f3af Intent: search\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f3af Intent: search\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f527 Tools used: ['search_products']\\n2025-08-23 13:11:42 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f527 Tools used: ['search_products']\\n2025-08-23 13:11:43 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:43 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:43 - ecommerce_ai_advisor.generation_tool - ERROR - \\u274c RAG generation error: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2920012838768'>\\n2025-08-23 13:11:43 - ecommerce_ai_advisor.generation_tool - ERROR - \\u274c RAG generation error: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2920012838768'>\\n2025-08-23 13:11:43 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Response generated with conversation history updated\\n2025-08-23 13:11:43 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Response generated with conversation history updated\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.tool_manager:logger.py:79 \\u2705 ToolManager initialized with 4 tools\\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure LangChain LLM instance created\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f5e3\\ufe0f Processing user input: T\\xecm laptop Dell... (session: error_te)\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Retrieving conversation history for session: error_test\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Found 0 checkpoints\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d No checkpoints found\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Returning empty memory context\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Detecting context references in user input: 't\\xecm laptop dell'\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f3af Intent analyzed (LLM): search\\nWARNING  ecommerce_ai_advisor.langgraph_agent:logger.py:83 \\u26a0\\ufe0f Failed to extract search params: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2920012838768'>\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f527 Parsed JSON tool input: {'query': 'T\\xecm laptop Dell', 'metadata': {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': None, 'max_results': 3, 'include_reviews': False}}\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f50d Searching products with query: 'T\\xecm laptop Dell'\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f3af Search metadata: {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': None, 'max_results': 3, 'include_reviews': False}\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'c561cca3344b4ab7875d006db4ce51de', 'date': 'Sat, 23 Aug 2025 06:11:38 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Search completed with structured input\\nINFO     ecommerce_ai_advisor.generation_tool:logger.py:79 \\U0001f916 Generating response for query: 'T\\xecm laptop Dell...'\\nINFO     ecommerce_ai_advisor.generation_tool:logger.py:79 \\U0001f3af Intent: search\\nINFO     ecommerce_ai_advisor.generation_tool:logger.py:79 \\U0001f527 Tools used: ['search_products']\\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure LangChain LLM instance created\\nERROR    ecommerce_ai_advisor.generation_tool:logger.py:90 \\u274c RAG generation error: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2920012838768'>\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Response generated with conversation history updated\n=========================== short test summary info ===========================\nFAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflows::test_complete_search_workflow\nFAILED tests/integration/test_end_to_end.py::TestServiceIntegration::test_tool_service_integration\nFAILED tests/integration/test_end_to_end.py::TestAgentToolIntegration::test_tool_error_handling_in_agent\n======================== 3 failed, 10 passed in 14.49s ========================\n",
      "stderr": "",
      "returncode": 1
    },
    "comprehensive": {
      "status": "FAILED",
      "duration": 24.281084537506104,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.13.6, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\MinhTC\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\ncachedir: .pytest_cache\nrootdir: C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, langsmith-0.4.13, asyncio-1.1.0, cov-6.2.1, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 164 items\n\ntests/integration/test_end_to_end.py::TestEndToEndWorkflows::test_complete_search_workflow FAILED [  0%]\ntests/integration/test_end_to_end.py::TestEndToEndWorkflows::test_complete_comparison_workflow PASSED [  1%]\ntests/integration/test_end_to_end.py::TestEndToEndWorkflows::test_multi_turn_conversation PASSED [  1%]\ntests/integration/test_end_to_end.py::TestEndToEndWorkflows::test_error_recovery_workflow PASSED [  2%]\ntests/integration/test_end_to_end.py::TestEndToEndWorkflows::test_greeting_workflow PASSED [  3%]\ntests/integration/test_end_to_end.py::TestServiceIntegration::test_llm_pinecone_integration PASSED [  3%]\ntests/integration/test_end_to_end.py::TestServiceIntegration::test_tool_service_integration FAILED [  4%]\ntests/integration/test_end_to_end.py::TestAgentToolIntegration::test_agent_uses_correct_tools PASSED [  4%]\ntests/integration/test_end_to_end.py::TestAgentToolIntegration::test_tool_error_handling_in_agent FAILED [  5%]\ntests/integration/test_end_to_end.py::TestConfigurationIntegration::test_config_used_by_services PASSED [  6%]\ntests/integration/test_end_to_end.py::TestConfigurationIntegration::test_config_validation_integration PASSED [  6%]\ntests/integration/test_end_to_end.py::TestMemoryIntegration::test_session_memory_persistence PASSED [  7%]\ntests/integration/test_end_to_end.py::TestMemoryIntegration::test_session_isolation PASSED [  7%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_agent_initialization PASSED [  8%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_create_graph_structure FAILED [  9%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_classify_intent_with_llm_success FAILED [  9%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_classify_intent_with_llm_failure PASSED [ 10%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_classify_intent_with_rules FAILED [ 10%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_analyze_intent_node PASSED [ 11%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_handle_greeting_node PASSED [ 12%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_search_products_node PASSED [ 12%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_compare_products_node PASSED [ 13%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_recommend_products_node PASSED [ 14%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_get_reviews_node FAILED [ 14%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_generate_response_node PASSED [ 15%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_handle_error_node PASSED [ 15%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_route_after_intent_analysis FAILED [ 16%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_route_to_response_or_error FAILED [ 17%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_extract_search_params FAILED [ 17%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_chat_method PASSED [ 18%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_chat_method_with_error PASSED [ 18%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_clear_memory PASSED [ 19%]\ntests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_agent_state_structure PASSED [ 20%]\ntests/unit/test_agents.py::TestAgentManager::test_get_agent_manager PASSED [ 20%]\ntests/unit/test_agents.py::TestAgentManager::test_get_langgraph_agent_manager FAILED [ 21%]\ntests/unit/test_config.py::TestConfig::test_config_initialization PASSED [ 21%]\ntests/unit/test_config.py::TestConfig::test_default_values PASSED        [ 22%]\ntests/unit/test_config.py::TestConfig::test_environment_variable_loading PASSED [ 23%]\ntests/unit/test_config.py::TestConfig::test_config_validation_success PASSED [ 23%]\ntests/unit/test_config.py::TestConfig::test_config_validation_failure FAILED [ 24%]\ntests/unit/test_config.py::TestConfig::test_get_openai_config FAILED     [ 25%]\ntests/unit/test_config.py::TestConfig::test_config_immutability PASSED   [ 25%]\ntests/unit/test_config.py::TestConfig::test_search_settings PASSED       [ 26%]\ntests/unit/test_config.py::TestConfig::test_llm_settings PASSED          [ 26%]\ntests/unit/test_config.py::TestConfig::test_ui_settings PASSED           [ 27%]\ntests/unit/test_config.py::TestConfig::test_empty_environment_variables FAILED [ 28%]\ntests/unit/test_config.py::TestConfig::test_model_names PASSED           [ 28%]\ntests/unit/test_config.py::TestConfig::test_numeric_constraints PASSED   [ 29%]\ntests/unit/test_config.py::TestConfig::test_custom_endpoint_detection PASSED [ 29%]\ntests/unit/test_llm_service.py::TestLLMService::test_llm_service_initialization FAILED [ 30%]\ntests/unit/test_llm_service.py::TestLLMService::test_custom_endpoint_initialization FAILED [ 31%]\ntests/unit/test_llm_service.py::TestLLMService::test_get_langchain_llm_azure FAILED [ 31%]\ntests/unit/test_llm_service.py::TestLLMService::test_get_langchain_llm_custom FAILED [ 32%]\ntests/unit/test_llm_service.py::TestLLMService::test_classify_intent_success FAILED [ 32%]\ntests/unit/test_llm_service.py::TestLLMService::test_classify_intent_failure FAILED [ 33%]\ntests/unit/test_llm_service.py::TestLLMService::test_generate_response_success FAILED [ 34%]\ntests/unit/test_llm_service.py::TestLLMService::test_generate_response_failure FAILED [ 34%]\ntests/unit/test_llm_service.py::TestLLMService::test_extract_parameters_success FAILED [ 35%]\ntests/unit/test_llm_service.py::TestLLMService::test_extract_parameters_invalid_json FAILED [ 35%]\ntests/unit/test_llm_service.py::TestLLMService::test_health_check_success FAILED [ 36%]\ntests/unit/test_llm_service.py::TestLLMService::test_health_check_failure FAILED [ 37%]\ntests/unit/test_llm_service.py::TestLLMService::test_response_format_enum PASSED [ 37%]\ntests/unit/test_llm_service.py::TestLLMService::test_singleton_instance PASSED [ 38%]\ntests/unit/test_llm_service.py::TestLLMService::test_format_prompt_for_intent FAILED [ 39%]\ntests/unit/test_llm_service.py::TestLLMService::test_format_prompt_for_generation FAILED [ 39%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_pinecone_service_initialization PASSED [ 40%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_create_embedding_success PASSED [ 40%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_create_embedding_failure FAILED [ 41%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_upsert_products_success FAILED [ 42%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_upsert_products_failure FAILED [ 42%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_search_products_success PASSED [ 43%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_search_products_with_filters PASSED [ 43%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_search_products_failure FAILED [ 44%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_get_index_stats_success PASSED [ 45%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_get_index_stats_failure FAILED [ 45%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_delete_all_vectors_success PASSED [ 46%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_delete_all_vectors_failure PASSED [ 46%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_health_check_success FAILED [ 47%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_health_check_failure FAILED [ 48%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_prepare_product_for_indexing FAILED [ 48%]\ntests/unit/test_pinecone_service.py::TestPineconeService::test_singleton_instance PASSED [ 49%]\ntests/unit/test_prompts.py::TestPromptType::test_prompt_type_enum_values FAILED [ 50%]\ntests/unit/test_prompts.py::TestPromptType::test_prompt_type_enum_is_enum PASSED [ 50%]\ntests/unit/test_prompts.py::TestPromptManager::test_prompt_manager_initialization FAILED [ 51%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_intent_classification FAILED [ 51%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_search_system FAILED [ 52%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_compare_system FAILED [ 53%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_recommend_system FAILED [ 53%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_review_system FAILED [ 54%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_base_system FAILED [ 54%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_search FAILED [ 55%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_compare FAILED [ 56%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_recommend FAILED [ 56%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_review FAILED [ 57%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_direct FAILED [ 57%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_error_handling FAILED [ 58%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_greeting_response FAILED [ 59%]\ntests/unit/test_prompts.py::TestPromptManager::test_get_prompt_invalid_type PASSED [ 59%]\ntests/unit/test_prompts.py::TestPromptManager::test_format_prompt_with_variables PASSED [ 60%]\ntests/unit/test_prompts.py::TestPromptManager::test_build_generation_prompt PASSED [ 60%]\ntests/unit/test_prompts.py::TestPromptManager::test_build_generation_prompt_minimal PASSED [ 61%]\ntests/unit/test_prompts.py::TestPromptManager::test_build_generation_prompt_error_handling PASSED [ 62%]\ntests/unit/test_prompts.py::TestPromptManager::test_prompt_templates_have_required_placeholders FAILED [ 62%]\ntests/unit/test_prompts.py::TestPromptManager::test_prompt_templates_are_vietnamese_friendly FAILED [ 63%]\ntests/unit/test_prompts.py::TestPromptManager::test_singleton_prompt_manager PASSED [ 64%]\ntests/unit/test_prompts.py::TestPromptManager::test_prompt_consistency PASSED [ 64%]\ntests/unit/test_prompts.py::TestPromptManager::test_all_prompt_types_have_prompts FAILED [ 65%]\ntests/unit/test_tools.py::TestToolManager::test_tool_manager_initialization PASSED [ 65%]\ntests/unit/test_tools.py::TestToolManager::test_get_all_tools PASSED     [ 66%]\ntests/unit/test_tools.py::TestToolManager::test_get_tool_by_name PASSED  [ 67%]\ntests/unit/test_tools.py::TestToolManager::test_get_tool_names PASSED    [ 67%]\ntests/unit/test_tools.py::TestToolManager::test_describe_tools PASSED    [ 68%]\ntests/unit/test_tools.py::TestSearchTool::test_search_tool_initialization FAILED [ 68%]\ntests/unit/test_tools.py::TestSearchTool::test_search_tool_success PASSED [ 69%]\ntests/unit/test_tools.py::TestSearchTool::test_search_tool_empty_query PASSED [ 70%]\ntests/unit/test_tools.py::TestSearchTool::test_search_tool_pinecone_error PASSED [ 70%]\ntests/unit/test_tools.py::TestSearchTool::test_search_tool_singleton PASSED [ 71%]\ntests/unit/test_tools.py::TestCompareTool::test_compare_tool_initialization FAILED [ 71%]\ntests/unit/test_tools.py::TestCompareTool::test_compare_tool_success PASSED [ 72%]\ntests/unit/test_tools.py::TestCompareTool::test_compare_tool_no_products_found PASSED [ 73%]\ntests/unit/test_tools.py::TestCompareTool::test_compare_tool_singleton PASSED [ 73%]\ntests/unit/test_tools.py::TestRecommendTool::test_recommend_tool_initialization FAILED [ 74%]\ntests/unit/test_tools.py::TestRecommendTool::test_recommend_tool_success PASSED [ 75%]\ntests/unit/test_tools.py::TestRecommendTool::test_recommend_tool_no_products PASSED [ 75%]\ntests/unit/test_tools.py::TestRecommendTool::test_recommend_tool_singleton PASSED [ 76%]\ntests/unit/test_tools.py::TestReviewTool::test_review_tool_initialization FAILED [ 76%]\ntests/unit/test_tools.py::TestReviewTool::test_review_tool_success PASSED [ 77%]\ntests/unit/test_tools.py::TestReviewTool::test_review_tool_product_not_found PASSED [ 78%]\ntests/unit/test_tools.py::TestReviewTool::test_review_tool_singleton PASSED [ 78%]\ntests/unit/test_tools.py::TestGenerationTool::test_generation_tool_initialization FAILED [ 79%]\ntests/unit/test_tools.py::TestGenerationTool::test_generation_tool_success FAILED [ 79%]\ntests/unit/test_tools.py::TestGenerationTool::test_generation_tool_llm_failure FAILED [ 80%]\ntests/unit/test_tools.py::TestGenerationTool::test_generation_tool_singleton PASSED [ 81%]\ntests/unit/test_tools.py::TestToolIntegration::test_all_tools_have_required_attributes PASSED [ 81%]\ntests/unit/test_tools.py::TestToolIntegration::test_tool_names_are_unique PASSED [ 82%]\ntests/unit/test_tools.py::TestToolIntegration::test_tools_return_json_strings FAILED [ 82%]\ntests/unit/test_tools.py::TestToolIntegration::test_tool_manager_contains_all_tools FAILED [ 83%]\ntests/unit/test_utils.py::TestLogger::test_logger_initialization PASSED  [ 84%]\ntests/unit/test_utils.py::TestLogger::test_logger_debug PASSED           [ 84%]\ntests/unit/test_utils.py::TestLogger::test_logger_info PASSED            [ 85%]\ntests/unit/test_utils.py::TestLogger::test_logger_warning PASSED         [ 85%]\ntests/unit/test_utils.py::TestLogger::test_logger_error PASSED           [ 86%]\ntests/unit/test_utils.py::TestLogger::test_logger_critical PASSED        [ 87%]\ntests/unit/test_utils.py::TestLogger::test_get_logger_function PASSED    [ 87%]\ntests/unit/test_utils.py::TestLogger::test_setup_logger_function PASSED  [ 88%]\ntests/unit/test_utils.py::TestLogger::test_track_time_decorator_success PASSED [ 89%]\ntests/unit/test_utils.py::TestLogger::test_track_time_decorator_failure PASSED [ 89%]\ntests/unit/test_utils.py::TestPromptHelper::test_prompt_helper_initialization PASSED [ 90%]\ntests/unit/test_utils.py::TestPromptHelper::test_clean_text FAILED       [ 90%]\ntests/unit/test_utils.py::TestPromptHelper::test_truncate_text FAILED    [ 91%]\ntests/unit/test_utils.py::TestPromptHelper::test_extract_keywords FAILED [ 92%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_price FAILED     [ 92%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_product_list FAILED [ 93%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_comparison_table FAILED [ 93%]\ntests/unit/test_utils.py::TestPromptHelper::test_extract_price_from_text FAILED [ 94%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_vietnamese_text FAILED [ 95%]\ntests/unit/test_utils.py::TestPromptHelper::test_safe_format_prompt FAILED [ 95%]\ntests/unit/test_utils.py::TestPromptHelper::test_safe_format_prompt_failure FAILED [ 96%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_conversation_history FAILED [ 96%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_tool_results FAILED [ 97%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_error_message PASSED [ 98%]\ntests/unit/test_utils.py::TestPromptHelper::test_format_error_message_exception_handling PASSED [ 98%]\ntests/unit/test_utils.py::TestPromptHelper::test_validate_vietnamese_input FAILED [ 99%]\ntests/unit/test_utils.py::TestPromptHelper::test_normalize_query FAILED  [100%]\n\n================================== FAILURES ===================================\n_____________ TestEndToEndWorkflows.test_complete_search_workflow _____________\n\nself = <MagicMock name='pinecone_service.search_products' id='2827791633776'>\n\n    def assert_called(self):\n        \"\"\"assert that the mock was called at least once\n        \"\"\"\n        if self.call_count == 0:\n            msg = (\"Expected '%s' to have been called.\" %\n                   (self._mock_name or 'mock'))\n>           raise AssertionError(msg)\nE           AssertionError: Expected 'search_products' to have been called.\n\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:948: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <tests.integration.test_end_to_end.TestEndToEndWorkflows object at 0x00000292542C7110>\nmock_services = {'llm': <MagicMock name='llm_service' id='2827791633440'>, 'pinecone': <MagicMock name='pinecone_service' id='2827791633104'>}\n\n    def test_complete_search_workflow(self, mock_services):\n        \"\"\"Test complete search workflow from user input to response\"\"\"\n        from src.agents.langgraph_agent import ProductAdvisorLangGraphAgent\n    \n        # Initialize agent\n        agent = ProductAdvisorLangGraphAgent()\n    \n        # Test complete search workflow\n        response = agent.chat(\"T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u\", session_id=\"test_session\")\n    \n        # Verify response structure\n        assert response[\"success\"] is True\n        assert response[\"intent\"] == \"search\"\n        assert \"search_products\" in response[\"tools_used\"]\n        assert response[\"response\"] is not None\n        assert len(response[\"response\"]) > 0\n    \n        # Verify services were called\n>       mock_services[\"pinecone\"].search_products.assert_called()\nE       AssertionError: Expected 'search_products' to have been called.\n\ntests\\integration\\test_end_to_end.py:62: AssertionError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:52 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f5e3\\ufe0f Processing user input: T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u... (session: test_ses)\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f5e3\\ufe0f Processing user input: T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u... (session: test_ses)\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Retrieving conversation history for session: test_session\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Retrieving conversation history for session: test_session\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Found 0 checkpoints\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Found 0 checkpoints\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d No checkpoints found\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d No checkpoints found\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Returning empty memory context\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Returning empty memory context\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Detecting context references in user input: 't\\xecm laptop dell d\\u01b0\\u1edbi 30 tri\\u1ec7u'\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Detecting context references in user input: 't\\xecm laptop dell d\\u01b0\\u1edbi 30 tri\\u1ec7u'\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - ERROR - \\u274c LLM intent classification failed: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827791646208'>\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - ERROR - \\u274c LLM intent classification failed: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827791646208'>\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f3af Intent analyzed (Rules): search\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f3af Intent analyzed (Rules): search\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f Failed to extract search params: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827791646208'>\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f Failed to extract search params: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827791646208'>\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u', 'metadata': {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': 30000000.0, 'max_results': 3, 'include_reviews': False}}\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u', 'metadata': {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': 30000000.0, 'max_results': 3, 'include_reviews': False}}\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u'\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u'\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': 30000000.0, 'max_results': 3, 'include_reviews': False}\\n2025-08-23 13:11:52 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': 30000000.0, 'max_results': 3, 'include_reviews': False}\\n2025-08-23 13:11:53 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'e36ddf98764ad745de86c67738ffb025', 'date': 'Sat, 23 Aug 2025 06:11:49 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:53 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'e36ddf98764ad745de86c67738ffb025', 'date': 'Sat, 23 Aug 2025 06:11:49 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:53 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Search completed with structured input\\n2025-08-23 13:11:53 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Search completed with structured input\\n2025-08-23 13:11:53 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f916 Generating response for query: 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u...'\\n2025-08-23 13:11:53 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f916 Generating response for query: 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u...'\\n2025-08-23 13:11:53 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f3af Intent: search\\n2025-08-23 13:11:53 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f3af Intent: search\\n2025-08-23 13:11:53 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f527 Tools used: ['search_products']\\n2025-08-23 13:11:53 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f527 Tools used: ['search_products']\\n2025-08-23 13:11:54 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:54 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:11:54 - ecommerce_ai_advisor.generation_tool - ERROR - \\u274c RAG generation error: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827791646208'>\\n2025-08-23 13:11:54 - ecommerce_ai_advisor.generation_tool - ERROR - \\u274c RAG generation error: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827791646208'>\\n2025-08-23 13:11:54 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Response generated with conversation history updated\\n2025-08-23 13:11:54 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Response generated with conversation history updated\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.tool_manager:logger.py:79 \\u2705 ToolManager initialized with 4 tools\\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure LangChain LLM instance created\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f5e3\\ufe0f Processing user input: T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u... (session: test_ses)\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Retrieving conversation history for session: test_session\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Found 0 checkpoints\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d No checkpoints found\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Returning empty memory context\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Detecting context references in user input: 't\\xecm laptop dell d\\u01b0\\u1edbi 30 tri\\u1ec7u'\\nERROR    ecommerce_ai_advisor.langgraph_agent:logger.py:90 \\u274c LLM intent classification failed: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827791646208'>\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f3af Intent analyzed (Rules): search\\nWARNING  ecommerce_ai_advisor.langgraph_agent:logger.py:83 \\u26a0\\ufe0f Failed to extract search params: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827791646208'>\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f527 Parsed JSON tool input: {'query': 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u', 'metadata': {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': 30000000.0, 'max_results': 3, 'include_reviews': False}}\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f50d Searching products with query: 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u'\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f3af Search metadata: {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': 30000000.0, 'max_results': 3, 'include_reviews': False}\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'e36ddf98764ad745de86c67738ffb025', 'date': 'Sat, 23 Aug 2025 06:11:49 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Search completed with structured input\\nINFO     ecommerce_ai_advisor.generation_tool:logger.py:79 \\U0001f916 Generating response for query: 'T\\xecm laptop Dell d\\u01b0\\u1edbi 30 tri\\u1ec7u...'\\nINFO     ecommerce_ai_advisor.generation_tool:logger.py:79 \\U0001f3af Intent: search\\nINFO     ecommerce_ai_advisor.generation_tool:logger.py:79 \\U0001f527 Tools used: ['search_products']\\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure LangChain LLM instance created\\nERROR    ecommerce_ai_advisor.generation_tool:logger.py:90 \\u274c RAG generation error: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827791646208'>\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Response generated with conversation history updated\n____________ TestServiceIntegration.test_tool_service_integration _____________\n\nself = <tests.integration.test_end_to_end.TestServiceIntegration object at 0x00000292542C7750>\n\n    def test_tool_service_integration(self):\n        \"\"\"Test tool integration with services\"\"\"\n        with patch('src.services.pinecone_service.pinecone_service') as mock_pinecone, \\\n             patch('src.services.llm_service.llm_service') as mock_llm:\n    \n            # Setup mocks\n            mock_pinecone.search_products.return_value = [\n                {\"name\": \"Dell XPS 13\", \"price\": 25000000}\n            ]\n            mock_llm.generate_response.return_value = \"Generated response\"\n    \n            from src.tools.search_tool import search_tool\n            from src.tools.generation_tool import generation_tool\n    \n            # Test search tool with service\n            search_result = search_tool.run('{\"query\": \"laptop Dell\"}')\n            search_response = json.loads(search_result)\n>           assert search_response[\"success\"] is True\nE           assert False is True\n\ntests\\integration\\test_end_to_end.py:188: AssertionError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:11:58 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'laptop Dell'}\\n2025-08-23 13:11:58 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'laptop Dell'}\\n2025-08-23 13:11:58 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'laptop Dell'\\n2025-08-23 13:11:58 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'laptop Dell'\\n2025-08-23 13:11:58 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: None\\n2025-08-23 13:11:58 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: None\\n2025-08-23 13:11:59 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '9871a2668b2a1808bdfac26e4956623f', 'date': 'Sat, 23 Aug 2025 06:11:54 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:11:59 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '9871a2668b2a1808bdfac26e4956623f', 'date': 'Sat, 23 Aug 2025 06:11:54 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f527 Parsed JSON tool input: {'query': 'laptop Dell'}\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f50d Searching products with query: 'laptop Dell'\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f3af Search metadata: None\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '9871a2668b2a1808bdfac26e4956623f', 'date': 'Sat, 23 Aug 2025 06:11:54 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\n_________ TestAgentToolIntegration.test_tool_error_handling_in_agent __________\n\nself = <tests.integration.test_end_to_end.TestAgentToolIntegration object at 0x00000292542C79D0>\nmock_all_services = {'compare': <MagicMock name='compare_tool' id='2827817051408'>, 'llm': <MagicMock name='llm_service' id='2827817052080...ck name='pinecone_service' id='2827817054768'>, 'recommend': <MagicMock name='recommend_tool' id='2827817051072'>, ...}\n\n    def test_tool_error_handling_in_agent(self, mock_all_services):\n        \"\"\"Test agent handles tool errors gracefully\"\"\"\n        from src.agents.langgraph_agent import ProductAdvisorLangGraphAgent\n    \n        # Setup tool to fail\n        mock_all_services[\"search\"].run.side_effect = Exception(\"Tool error\")\n    \n        agent = ProductAdvisorLangGraphAgent()\n    \n        # Test that agent handles tool error\n        with patch.object(agent, '_classify_intent_with_llm', return_value=\"search\"):\n            response = agent.chat(\"Tìm laptop Dell\", session_id=\"error_test\")\n    \n            # Should handle error gracefully\n>           assert \"error\" in response or response[\"success\"] is False\nE           assert ('error' in {'agent_type': 'langgraph', 'context_info': {'context_references_used': False, 'has_previous_context': True, 'previous_products': []}, 'intent': 'search', 'intermediate_steps': [(<src.agents.langgraph_agent.Action object at 0x000002926707C6E0>, '{\"success\": false, \"error\": \"L\\\\\\\\u1ed7i k\\\\\\\\u1ebft n\\\\\\\\u1ed1i c\\\\\\\\u01a1 s\\\\\\\\u1edf d\\\\\\\\u1eef li\\\\\\\\u1ec7u: (401)\\\\\\\\nRe...'), (<src.agents.langgraph_agent.Action object at 0x000002926707C440>, 'Xin l\\u1ed7i, t\\xf4i g\\u1eb7p v\\u1ea5n \\u0111\\u1ec1 khi t\\u1ea1o c\\xe2u tr\\u1ea3 l\\u1eddi. Vui l\\xf2ng th\\u1eed l\\u1ea1i.')], ...} or True is False)\n\ntests\\integration\\test_end_to_end.py:275: AssertionError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:00 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f5e3\\ufe0f Processing user input: T\\xecm laptop Dell... (session: error_te)\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f5e3\\ufe0f Processing user input: T\\xecm laptop Dell... (session: error_te)\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Retrieving conversation history for session: error_test\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Retrieving conversation history for session: error_test\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Found 0 checkpoints\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Found 0 checkpoints\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d No checkpoints found\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d No checkpoints found\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Returning empty memory context\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Returning empty memory context\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Detecting context references in user input: 't\\xecm laptop dell'\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f50d Detecting context references in user input: 't\\xecm laptop dell'\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f3af Intent analyzed (LLM): search\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f3af Intent analyzed (LLM): search\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f Failed to extract search params: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827817045024'>\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f Failed to extract search params: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827817045024'>\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'T\\xecm laptop Dell', 'metadata': {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': None, 'max_results': 3, 'include_reviews': False}}\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'T\\xecm laptop Dell', 'metadata': {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': None, 'max_results': 3, 'include_reviews': False}}\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'T\\xecm laptop Dell'\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'T\\xecm laptop Dell'\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': None, 'max_results': 3, 'include_reviews': False}\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': None, 'max_results': 3, 'include_reviews': False}\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '9827c4c6242e9b9fbdfac26e4956630b', 'date': 'Sat, 23 Aug 2025 06:11:56 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '9827c4c6242e9b9fbdfac26e4956630b', 'date': 'Sat, 23 Aug 2025 06:11:56 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Search completed with structured input\\n2025-08-23 13:12:00 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Search completed with structured input\\n2025-08-23 13:12:01 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f916 Generating response for query: 'T\\xecm laptop Dell...'\\n2025-08-23 13:12:01 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f916 Generating response for query: 'T\\xecm laptop Dell...'\\n2025-08-23 13:12:01 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f3af Intent: search\\n2025-08-23 13:12:01 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f3af Intent: search\\n2025-08-23 13:12:01 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f527 Tools used: ['search_products']\\n2025-08-23 13:12:01 - ecommerce_ai_advisor.generation_tool - INFO - \\U0001f527 Tools used: ['search_products']\\n2025-08-23 13:12:01 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:12:01 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure LangChain LLM instance created\\n2025-08-23 13:12:01 - ecommerce_ai_advisor.generation_tool - ERROR - \\u274c RAG generation error: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827817045024'>\\n2025-08-23 13:12:01 - ecommerce_ai_advisor.generation_tool - ERROR - \\u274c RAG generation error: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827817045024'>\\n2025-08-23 13:12:01 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Response generated with conversation history updated\\n2025-08-23 13:12:01 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Response generated with conversation history updated\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.tool_manager:logger.py:79 \\u2705 ToolManager initialized with 4 tools\\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure LangChain LLM instance created\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f5e3\\ufe0f Processing user input: T\\xecm laptop Dell... (session: error_te)\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Retrieving conversation history for session: error_test\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Found 0 checkpoints\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d No checkpoints found\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Returning empty memory context\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f50d Detecting context references in user input: 't\\xecm laptop dell'\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f3af Intent analyzed (LLM): search\\nWARNING  ecommerce_ai_advisor.langgraph_agent:logger.py:83 \\u26a0\\ufe0f Failed to extract search params: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827817045024'>\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f527 Parsed JSON tool input: {'query': 'T\\xecm laptop Dell', 'metadata': {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': None, 'max_results': 3, 'include_reviews': False}}\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f50d Searching products with query: 'T\\xecm laptop Dell'\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f3af Search metadata: {'category': 'laptop', 'brand': 'dell', 'price_min': None, 'price_max': None, 'max_results': 3, 'include_reviews': False}\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '9827c4c6242e9b9fbdfac26e4956630b', 'date': 'Sat, 23 Aug 2025 06:11:56 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Search completed with structured input\\nINFO     ecommerce_ai_advisor.generation_tool:logger.py:79 \\U0001f916 Generating response for query: 'T\\xecm laptop Dell...'\\nINFO     ecommerce_ai_advisor.generation_tool:logger.py:79 \\U0001f3af Intent: search\\nINFO     ecommerce_ai_advisor.generation_tool:logger.py:79 \\U0001f527 Tools used: ['search_products']\\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure LangChain LLM instance created\\nERROR    ecommerce_ai_advisor.generation_tool:logger.py:90 \\u274c RAG generation error: <MagicMock name='AzureOpenAI().chat.completions.create().model_dump().get()' id='2827817045024'>\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Response generated with conversation history updated\n________ TestProductAdvisorLangGraphAgent.test_create_graph_structure _________\n\nself = <tests.unit.test_agents.TestProductAdvisorLangGraphAgent object at 0x000002926561B110>\nmock_dependencies = {'generation_tool': <MagicMock name='generation_tool' id='2827816233216'>, 'llm': <MagicMock name='llm_service' id='28...MagicMock name='prompt_manager' id='2827816233552'>, 'tool_manager': <MagicMock name='ToolManager' id='2827816232880'>}\n\n    def test_create_graph_structure(self, mock_dependencies):\n        \"\"\"Test graph structure creation\"\"\"\n        agent = ProductAdvisorLangGraphAgent()\n    \n        # Verify graph has required nodes\n>       graph_dict = agent.graph.get_graph().to_dict()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: 'Graph' object has no attribute 'to_dict'\n\ntests\\unit\\test_agents.py:54: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:04 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:12:04 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\n___ TestProductAdvisorLangGraphAgent.test_classify_intent_with_llm_success ____\n\nself = <tests.unit.test_agents.TestProductAdvisorLangGraphAgent object at 0x0000029264A422C0>\nmock_dependencies = {'generation_tool': <MagicMock name='generation_tool' id='2827791634448'>, 'llm': <MagicMock name='llm_service' id='28...MagicMock name='prompt_manager' id='2827791636464'>, 'tool_manager': <MagicMock name='ToolManager' id='2827791643856'>}\n\n    def test_classify_intent_with_llm_success(self, mock_dependencies):\n        \"\"\"Test successful LLM intent classification\"\"\"\n        mock_dependencies[\"llm\"].get_langchain_llm.return_value.invoke.return_value.content = \"search\"\n    \n        agent = ProductAdvisorLangGraphAgent()\n    \n        # Test intent classification\n        intent = agent._classify_intent_with_llm(\"Tìm laptop Dell\")\n    \n        # Verify result\n>       assert intent == \"search\"\nE       AssertionError: assert None == 'search'\n\ntests\\unit\\test_agents.py:81: AssertionError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:04 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:12:04 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:12:04 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f LLM returned invalid intent: <MagicMock name='llm_service.get_llm().invoke().content.strip().lower()' id='2827794179680'>\\n2025-08-23 13:12:04 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f LLM returned invalid intent: <MagicMock name='llm_service.get_llm().invoke().content.strip().lower()' id='2827794179680'>\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\\nWARNING  ecommerce_ai_advisor.langgraph_agent:logger.py:83 \\u26a0\\ufe0f LLM returned invalid intent: <MagicMock name='llm_service.get_llm().invoke().content.strip().lower()' id='2827794179680'>\n______ TestProductAdvisorLangGraphAgent.test_classify_intent_with_rules _______\n\nself = <tests.unit.test_agents.TestProductAdvisorLangGraphAgent object at 0x000002926551EC30>\nmock_dependencies = {'generation_tool': <MagicMock name='generation_tool' id='2827817047376'>, 'llm': <MagicMock name='llm_service' id='28...MagicMock name='prompt_manager' id='2827817046032'>, 'tool_manager': <MagicMock name='ToolManager' id='2827817052752'>}\n\n    def test_classify_intent_with_rules(self, mock_dependencies):\n        \"\"\"Test rule-based intent classification\"\"\"\n        agent = ProductAdvisorLangGraphAgent()\n    \n        # Test various intents\n        test_cases = [\n            (\"xin chào\", \"greeting\"),\n            (\"tìm laptop dell\", \"search\"),\n            (\"so sánh iphone và samsung\", \"compare\"),\n            (\"g\\u1ee3i \\xfd \\u0111i\\u1ec7n tho\\u1ea1i t\\u1ed1t\", \"recommend\"),\n            (\"\\u0111\\xe1nh gi\\xe1 macbook\", \"review\"),\n            (\"random text\", \"direct\")\n        ]\n    \n        for user_input, expected_intent in test_cases:\n            intent = agent._classify_intent_with_rules(user_input)\n>           assert intent == expected_intent\nE           AssertionError: assert 'search' == 'review'\nE             \nE             - review\nE             + search\n\ntests\\unit\\test_agents.py:111: AssertionError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:04 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:12:04 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\n___________ TestProductAdvisorLangGraphAgent.test_get_reviews_node ____________\n\nself = <tests.unit.test_agents.TestProductAdvisorLangGraphAgent object at 0x00000292543319A0>\nmock_dependencies = {'generation_tool': <MagicMock name='generation_tool' id='2827816230528'>, 'llm': <MagicMock name='llm_service' id='28...MagicMock name='prompt_manager' id='2827817049728'>, 'tool_manager': <MagicMock name='ToolManager' id='2827816230192'>}\nsample_agent_state = {'comparison_results': None, 'context_data': None, 'context_references': None, 'conversation_history': [], ...}\n\n    def test_get_reviews_node(self, mock_dependencies, sample_agent_state):\n        \"\"\"Test get reviews node\"\"\"\n        # Setup mock tool\n        mock_review_tool = Mock()\n        mock_review_tool.run.return_value = json.dumps({\n            \"success\": True,\n            \"reviews\": [{\"rating\": 5, \"content\": \"Great laptop\"}]\n        })\n        mock_dependencies[\"tool_manager\"].return_value.get_tool.return_value = mock_review_tool\n    \n        agent = ProductAdvisorLangGraphAgent()\n    \n        # Test review analysis\n        state = sample_agent_state.copy()\n        state[\"user_input\"] = \"\\u0110\\xe1nh gi\\xe1 Dell XPS 13\"\n        state[\"intent\"] = \"review\"\n    \n        result_state = agent._get_reviews(state)\n    \n        # Verify review results\n        assert \"review_results\" in result_state\n>       assert \"get_reviews\" in result_state[\"tools_used\"]\nE       AssertionError: assert 'get_reviews' in ['get_product_reviews']\n\ntests\\unit\\test_agents.py:235: AssertionError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f3af Extracted review params: {'product_name': 'dell xps 13', 'limit': 5, 'sort_by': 'newest'}\\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - INFO - \\U0001f3af Extracted review params: {'product_name': 'dell xps 13', 'limit': 5, 'sort_by': 'newest'}\\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Reviews retrieved successfully\\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Reviews retrieved successfully\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\U0001f3af Extracted review params: {'product_name': 'dell xps 13', 'limit': 5, 'sort_by': 'newest'}\\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Reviews retrieved successfully\n______ TestProductAdvisorLangGraphAgent.test_route_after_intent_analysis ______\n\nself = <tests.unit.test_agents.TestProductAdvisorLangGraphAgent object at 0x0000029265772DD0>\nmock_dependencies = {'generation_tool': <MagicMock name='generation_tool' id='2827794181360'>, 'llm': <MagicMock name='llm_service' id='28...MagicMock name='prompt_manager' id='2827794185392'>, 'tool_manager': <MagicMock name='ToolManager' id='2827794183040'>}\n\n    def test_route_after_intent_analysis(self, mock_dependencies):\n        \"\"\"Test routing after intent analysis\"\"\"\n        agent = ProductAdvisorLangGraphAgent()\n    \n        # Test different routing scenarios\n        test_cases = [\n            ({\"intent\": \"greeting\"}, \"handle_greeting\"),\n            ({\"intent\": \"search\"}, \"search_products\"),\n            ({\"intent\": \"compare\"}, \"compare_products\"),\n            ({\"intent\": \"recommend\"}, \"recommend_products\"),\n            ({\"intent\": \"review\"}, \"get_reviews\"),\n            ({\"intent\": \"direct\"}, \"generate_response\"),\n            ({\"intent\": \"unknown\"}, \"generate_response\")\n        ]\n    \n        for state, expected_route in test_cases:\n>           route = agent._route_after_intent_analysis(state)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'ProductAdvisorLangGraphAgent' object has no attribute '_route_after_intent_analysis'\n\ntests\\unit\\test_agents.py:283: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\n______ TestProductAdvisorLangGraphAgent.test_route_to_response_or_error _______\n\nself = <tests.unit.test_agents.TestProductAdvisorLangGraphAgent object at 0x000002925433CA10>\nmock_dependencies = {'generation_tool': <MagicMock name='generation_tool' id='2827791631424'>, 'llm': <MagicMock name='llm_service' id='28...MagicMock name='prompt_manager' id='2827791634112'>, 'tool_manager': <MagicMock name='ToolManager' id='2827791642848'>}\n\n    def test_route_to_response_or_error(self, mock_dependencies):\n        \"\"\"Test routing to response or error\"\"\"\n        agent = ProductAdvisorLangGraphAgent()\n    \n        # Test routing scenarios\n        test_cases = [\n            ({\"error_count\": 0}, \"generate_response\"),\n            ({\"error_count\": 3}, \"handle_error\"),\n            ({\"error_count\": 5}, \"handle_error\")\n        ]\n    \n        for state, expected_route in test_cases:\n>           route = agent._route_to_response_or_error(state)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'ProductAdvisorLangGraphAgent' object has no attribute '_route_to_response_or_error'\n\ntests\\unit\\test_agents.py:298: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\n_________ TestProductAdvisorLangGraphAgent.test_extract_search_params _________\n\nself = <tests.unit.test_agents.TestProductAdvisorLangGraphAgent object at 0x000002925433CF50>\nmock_dependencies = {'generation_tool': <MagicMock name='generation_tool' id='2827791634784'>, 'llm': <MagicMock name='llm_service' id='28...MagicMock name='prompt_manager' id='2827791632432'>, 'tool_manager': <MagicMock name='ToolManager' id='2827791633440'>}\n\n    def test_extract_search_params(self, mock_dependencies):\n        \"\"\"Test search parameter extraction\"\"\"\n        agent = ProductAdvisorLangGraphAgent()\n    \n        # Test parameter extraction\n        test_cases = [\n            (\"laptop Dell d\\u01b0\\u1edbi 20 tri\\u1ec7u\", {\"query\": \"laptop Dell\", \"price_max\": 20000000}),\n            (\"\\u0111i\\u1ec7n tho\\u1ea1i Samsung\", {\"query\": \"\\u0111i\\u1ec7n tho\\u1ea1i Samsung\"}),\n            (\"laptop gaming\", {\"query\": \"laptop gaming\"})\n        ]\n    \n        for user_input, expected_params in test_cases:\n            params = agent._extract_search_params(user_input)\n            assert \"query\" in params\n            for key, value in expected_params.items():\n                if key in params:\n>                   assert params[key] == value\nE                   AssertionError: assert 'laptop Dell d\\u01b0\\u1edbi 20 tri\\u1ec7u' == 'laptop Dell'\nE                     \nE                     - laptop Dell\nE                     + laptop Dell d\\u01b0\\u1edbi 20 tri\\u1ec7u\n\ntests\\unit\\test_agents.py:317: AssertionError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - INFO - \\u2705 Enhanced LangGraph Agent initialized with native memory\\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f Failed to extract search params: the JSON object must be str, bytes or bytearray, not MagicMock\\n2025-08-23 13:12:05 - ecommerce_ai_advisor.langgraph_agent - WARNING - \\u26a0\\ufe0f Failed to extract search params: the JSON object must be str, bytes or bytearray, not MagicMock\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.langgraph_agent:logger.py:79 \\u2705 Enhanced LangGraph Agent initialized with native memory\\nWARNING  ecommerce_ai_advisor.langgraph_agent:logger.py:83 \\u26a0\\ufe0f Failed to extract search params: the JSON object must be str, bytes or bytearray, not MagicMock\n______________ TestAgentManager.test_get_langgraph_agent_manager ______________\n\nself = <tests.unit.test_agents.TestAgentManager object at 0x000002926561B4D0>\nmock_agent_class = <MagicMock name='ProductAdvisorLangGraphAgent' id='2827794181696'>\n\n    @patch('src.agents.langgraph_agent.ProductAdvisorLangGraphAgent')\n    def test_get_langgraph_agent_manager(self, mock_agent_class):\n        \"\"\"Test get_langgraph_agent_manager function\"\"\"\n>       from src.agents.langgraph_agent import get_langgraph_agent_manager\nE       ImportError: cannot import name 'get_langgraph_agent_manager' from 'src.agents.langgraph_agent' (C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\\src\\agents\\langgraph_agent.py)\n\ntests\\unit\\test_agents.py:404: ImportError\n__________________ TestConfig.test_config_validation_failure __________________\n\nself = <tests.unit.test_config.TestConfig object at 0x000002926576A0F0>\n\n    @patch.dict(os.environ, {\n        'AZURE_OPENAI_API_ENDPOINT': '',\n        'AZURE_OPENAI_EMBEDDING_API_KEY': '',\n        'AZURE_OPENAI_LLM_API_KEY': ''\n    })\n    def test_config_validation_failure(self):\n        \"\"\"Test configuration validation failure with missing fields\"\"\"\n        # Test that validation fails with missing required fields\n>       with pytest.raises(ValueError, match=\"Missing required environment variables\"):\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       Failed: DID NOT RAISE <class 'ValueError'>\n\ntests\\unit\\test_config.py:82: Failed\n______________________ TestConfig.test_get_openai_config ______________________\n\nself = <tests.unit.test_config.TestConfig object at 0x0000029265741040>\n\n    def test_get_openai_config(self):\n        \"\"\"Test OpenAI configuration retrieval\"\"\"\n        with patch.dict(os.environ, {\n            'AZURE_OPENAI_API_ENDPOINT': 'https://test.openai.azure.com/',\n            'AZURE_OPENAI_EMBEDDING_API_KEY': 'test_embedding_key',\n            'AZURE_OPENAI_API_VERSION': '2024-07-01-preview'\n        }):\n            # Reload config to pick up environment variables\n            import importlib\n            from src.config import config\n            importlib.reload(config)\n    \n            openai_config = config.Config.get_openai_config()\n    \n>           assert openai_config[\"api_key\"] == 'test_embedding_key'\nE           AssertionError: assert 'sk-9-fFflHflOhQR-Y9VZcMCg' == 'test_embedding_key'\nE             \nE             - test_embedding_key\nE             + sk-9-fFflHflOhQR-Y9VZcMCg\n\ntests\\unit\\test_config.py:99: AssertionError\n---------------------------- Captured stdout call -----------------------------\n\\u2705 Configuration loaded successfully\n_________________ TestConfig.test_empty_environment_variables _________________\n\nself = <tests.unit.test_config.TestConfig object at 0x0000029264E8B2F0>\n\n    @patch.dict(os.environ, {}, clear=True)\n    def test_empty_environment_variables(self):\n        \"\"\"Test behavior with empty environment variables\"\"\"\n        # Reload config with empty environment\n        import importlib\n        from src.config import config\n        importlib.reload(config)\n    \n        # Test that empty strings are returned for missing env vars\n>       assert config.Config.PINECONE_API_KEY == \"\"\nE       AssertionError: assert 'pcsk_3fZQv8_...4pr6UWVvMpED3' == ''\nE         \nE         + pcsk_3fZQv8_As1xDMbGK8G5gVQMzL243ZtkwFe4eUzKP4rQaC2NFfAkw3Bj454pr6UWVvMpED3\n\ntests\\unit\\test_config.py:150: AssertionError\n---------------------------- Captured stdout call -----------------------------\n\\u2705 Configuration loaded successfully\n_______________ TestLLMService.test_llm_service_initialization ________________\n\nself = <tests.unit.test_llm_service.TestLLMService object at 0x000002926561BB10>\nmock_config = <MagicMock name='Config' id='2827791642848'>\nmock_azure_openai = <MagicMock name='AzureOpenAI' id='2827791632432'>\n\n    @patch('src.services.llm_service.AzureOpenAI')\n    @patch('src.config.config.Config')\n    def test_llm_service_initialization(self, mock_config, mock_azure_openai):\n        \"\"\"Test LLM service initialization\"\"\"\n        # Setup mock config\n        mock_config.AZURE_OPENAI_LLM_MODEL = \"GPT-4o-mini\"\n        mock_config.TEMPERATURE = 0.7\n        mock_config.MAX_TOKENS = 1000\n        mock_config.AZURE_OPENAI_API_ENDPOINT = \"https://test.openai.azure.com/\"\n        mock_config.get_openai_config.return_value = {\n            \"api_key\": \"test_key\",\n            \"api_base\": \"https://test.openai.azure.com/\",\n            \"api_version\": \"2024-07-01-preview\"\n        }\n    \n        # Initialize service\n        service = LLMService()\n    \n        # Verify initialization\n        assert service.model == \"GPT-4o-mini\"\n        assert service.temperature == 0.7\n>       assert service.max_tokens == 1000\nE       assert 5000 == 1000\nE        +  where 5000 = <src.services.llm_service.LLMService object at 0x0000029266FD8770>.max_tokens\n\ntests\\unit\\test_llm_service.py:56: AssertionError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:05 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:12:05 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n_____________ TestLLMService.test_custom_endpoint_initialization ______________\n\nself = <tests.unit.test_llm_service.TestLLMService object at 0x000002926561BC50>\nmock_config = <MagicMock name='Config' id='2827794179008'>\nmock_azure_openai = <MagicMock name='AzureOpenAI' id='2827794180352'>\n\n    @patch('src.services.llm_service.AzureOpenAI')\n    @patch('src.config.config.Config')\n    def test_custom_endpoint_initialization(self, mock_config, mock_azure_openai):\n        \"\"\"Test initialization with custom endpoint\"\"\"\n        # Setup mock config for custom endpoint\n        mock_config.AZURE_OPENAI_API_ENDPOINT = \"https://custom.aiportalapi.com/\"\n        mock_config.AZURE_OPENAI_LLM_API_KEY = \"test_key\"\n        mock_config.AZURE_OPENAI_LLM_MODEL = \"GPT-4o-mini\"\n        mock_config.TEMPERATURE = 0.7\n        mock_config.MAX_TOKENS = 1000\n    \n>       with patch('src.services.llm_service.OpenAI') as mock_openai:\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ntests\\unit\\test_llm_service.py:70: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <unittest.mock._patch object at 0x0000029266EBE0B0>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'src.services.llm_service' from 'C:\\\\Users\\\\MinhTC\\\\Desktop\\\\Hackaton\\\\evlevate-dn-03\\\\Workshop_final\\\\src\\\\services\\\\llm_service.py'> does not have the attribute 'OpenAI'\n\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1467: AttributeError\n_________________ TestLLMService.test_get_langchain_llm_azure _________________\n\nargs = (<tests.unit.test_llm_service.TestLLMService object at 0x000002926566E2C0>,)\nkeywargs = {}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1423: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1405: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <unittest.mock._patch object at 0x00000292657991D0>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'src.services.llm_service' from 'C:\\\\Users\\\\MinhTC\\\\Desktop\\\\Hackaton\\\\evlevate-dn-03\\\\Workshop_final\\\\src\\\\services\\\\llm_service.py'> does not have the attribute 'AzureChatOpenAI'\n\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1467: AttributeError\n________________ TestLLMService.test_get_langchain_llm_custom _________________\n\nargs = (<tests.unit.test_llm_service.TestLLMService object at 0x000002926566E3F0>,)\nkeywargs = {}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1423: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1405: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <unittest.mock._patch object at 0x0000029265799390>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'src.services.llm_service' from 'C:\\\\Users\\\\MinhTC\\\\Desktop\\\\Hackaton\\\\evlevate-dn-03\\\\Workshop_final\\\\src\\\\services\\\\llm_service.py'> does not have the attribute 'ChatOpenAI'\n\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1467: AttributeError\n_________________ TestLLMService.test_classify_intent_success _________________\n\nself = <tests.unit.test_llm_service.TestLLMService object at 0x00000292657AC710>\nmock_azure_openai_client = <Mock id='2827794184384'>\n\n    def test_classify_intent_success(self, mock_azure_openai_client):\n        \"\"\"Test successful intent classification\"\"\"\n        with patch('src.services.llm_service.AzureOpenAI', return_value=mock_azure_openai_client):\n            service = LLMService()\n    \n            # Test intent classification\n>           result = service.classify_intent(\"Tìm laptop Dell\")\n                     ^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'LLMService' object has no attribute 'classify_intent'\n\ntests\\unit\\test_llm_service.py:120: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n_________________ TestLLMService.test_classify_intent_failure _________________\n\nself = <tests.unit.test_llm_service.TestLLMService object at 0x0000029265741260>\n\n    def test_classify_intent_failure(self):\n        \"\"\"Test intent classification failure\"\"\"\n        with patch('src.services.llm_service.AzureOpenAI') as mock_azure_openai:\n            mock_client = Mock()\n            mock_client.chat.completions.create.side_effect = Exception(\"API Error\")\n            mock_azure_openai.return_value = mock_client\n    \n            service = LLMService()\n    \n            # Test intent classification failure\n>           result = service.classify_intent(\"Tìm laptop Dell\")\n                     ^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'LLMService' object has no attribute 'classify_intent'\n\ntests\\unit\\test_llm_service.py:136: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n________________ TestLLMService.test_generate_response_success ________________\n\nself = <tests.unit.test_llm_service.TestLLMService object at 0x0000029265741370>\nmock_azure_openai_client = <Mock id='2827794185056'>\n\n    def test_generate_response_success(self, mock_azure_openai_client):\n        \"\"\"Test successful response generation\"\"\"\n        # Setup mock response\n        mock_response = Mock()\n        mock_response.choices = [Mock()]\n        mock_response.choices[0].message.content = \"T\\xf4i \\u0111\\xe3 t\\xecm th\\u1ea5y laptop Dell ph\\xf9 h\\u1ee3p.\"\n        mock_azure_openai_client.chat.completions.create.return_value = mock_response\n    \n        with patch('src.services.llm_service.AzureOpenAI', return_value=mock_azure_openai_client):\n            service = LLMService()\n    \n            # Test response generation\n>           result = service.generate_response(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n                prompt=\"Generate response for laptop search\",\n                format_type=ResponseFormat.CONVERSATIONAL\n            )\nE           AttributeError: 'LLMService' object has no attribute 'generate_response'\n\ntests\\unit\\test_llm_service.py:153: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n________________ TestLLMService.test_generate_response_failure ________________\n\nself = <tests.unit.test_llm_service.TestLLMService object at 0x0000029265721250>\n\n    def test_generate_response_failure(self):\n        \"\"\"Test response generation failure\"\"\"\n        with patch('src.services.llm_service.AzureOpenAI') as mock_azure_openai:\n            mock_client = Mock()\n            mock_client.chat.completions.create.side_effect = Exception(\"API Error\")\n            mock_azure_openai.return_value = mock_client\n    \n            service = LLMService()\n    \n            # Test response generation failure\n>           result = service.generate_response(\"Test prompt\")\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'LLMService' object has no attribute 'generate_response'\n\ntests\\unit\\test_llm_service.py:172: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n_______________ TestLLMService.test_extract_parameters_success ________________\n\nself = <tests.unit.test_llm_service.TestLLMService object at 0x0000029265721550>\nmock_azure_openai_client = <Mock id='2827791634784'>\n\n    def test_extract_parameters_success(self, mock_azure_openai_client):\n        \"\"\"Test successful parameter extraction\"\"\"\n        # Setup mock response with JSON\n        mock_response = Mock()\n        mock_response.choices = [Mock()]\n        mock_response.choices[0].message.content = '{\"query\": \"laptop Dell\", \"price_max\": 20000000}'\n        mock_azure_openai_client.chat.completions.create.return_value = mock_response\n    \n        with patch('src.services.llm_service.AzureOpenAI', return_value=mock_azure_openai_client):\n            service = LLMService()\n    \n            # Test parameter extraction\n>           result = service.extract_parameters(\"T\\xecm laptop Dell d\\u01b0\\u1edbi 20 tri\\u1ec7u\")\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'LLMService' object has no attribute 'extract_parameters'\n\ntests\\unit\\test_llm_service.py:189: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n_____________ TestLLMService.test_extract_parameters_invalid_json _____________\n\nself = <tests.unit.test_llm_service.TestLLMService object at 0x0000029264E8B4D0>\nmock_azure_openai_client = <Mock id='2827817042672'>\n\n    def test_extract_parameters_invalid_json(self, mock_azure_openai_client):\n        \"\"\"Test parameter extraction with invalid JSON\"\"\"\n        # Setup mock response with invalid JSON\n        mock_response = Mock()\n        mock_response.choices = [Mock()]\n        mock_response.choices[0].message.content = \"invalid json response\"\n        mock_azure_openai_client.chat.completions.create.return_value = mock_response\n    \n        with patch('src.services.llm_service.AzureOpenAI', return_value=mock_azure_openai_client):\n            service = LLMService()\n    \n            # Test parameter extraction with invalid JSON\n>           result = service.extract_parameters(\"Tìm laptop Dell\")\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'LLMService' object has no attribute 'extract_parameters'\n\ntests\\unit\\test_llm_service.py:207: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n__________________ TestLLMService.test_health_check_success ___________________\n\nself = <tests.unit.test_llm_service.TestLLMService object at 0x0000029264E8B5C0>\nmock_azure_openai_client = <Mock id='2827817044688'>\n\n    def test_health_check_success(self, mock_azure_openai_client):\n        \"\"\"Test successful health check\"\"\"\n        # Setup mock response\n        mock_response = Mock()\n        mock_response.choices = [Mock()]\n        mock_response.choices[0].message.content = \"OK\"\n        mock_azure_openai_client.chat.completions.create.return_value = mock_response\n    \n        with patch('src.services.llm_service.AzureOpenAI', return_value=mock_azure_openai_client):\n            service = LLMService()\n    \n            # Test health check\n>           result = service.health_check()\n                     ^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'LLMService' object has no attribute 'health_check'\n\ntests\\unit\\test_llm_service.py:224: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n__________________ TestLLMService.test_health_check_failure ___________________\n\nself = <tests.unit.test_llm_service.TestLLMService object at 0x0000029265747070>\n\n    def test_health_check_failure(self):\n        \"\"\"Test health check failure\"\"\"\n        with patch('src.services.llm_service.AzureOpenAI') as mock_azure_openai:\n            mock_client = Mock()\n            mock_client.chat.completions.create.side_effect = Exception(\"Connection Error\")\n            mock_azure_openai.return_value = mock_client\n    \n            service = LLMService()\n    \n            # Test health check failure\n>           result = service.health_check()\n                     ^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'LLMService' object has no attribute 'health_check'\n\ntests\\unit\\test_llm_service.py:240: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n________________ TestLLMService.test_format_prompt_for_intent _________________\n\nself = <tests.unit.test_llm_service.TestLLMService object at 0x00000292656E2990>\n\n    def test_format_prompt_for_intent(self):\n        \"\"\"Test prompt formatting for intent classification\"\"\"\n        with patch('src.services.llm_service.AzureOpenAI'):\n            service = LLMService()\n    \n            # Test prompt formatting\n            user_input = \"Tìm laptop Dell\"\n>           formatted_prompt = service._format_prompt_for_intent(user_input)\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'LLMService' object has no attribute '_format_prompt_for_intent'\n\ntests\\unit\\test_llm_service.py:268: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n______________ TestLLMService.test_format_prompt_for_generation _______________\n\nself = <tests.unit.test_llm_service.TestLLMService object at 0x00000292656E2A50>\n\n    def test_format_prompt_for_generation(self):\n        \"\"\"Test prompt formatting for response generation\"\"\"\n        with patch('src.services.llm_service.AzureOpenAI'):\n            service = LLMService()\n    \n            # Test prompt formatting\n            query = \"Tìm laptop Dell\"\n            context = \"Found 3 Dell laptops\"\n>           formatted_prompt = service._format_prompt_for_generation(query, context)\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'LLMService' object has no attribute '_format_prompt_for_generation'\n\ntests\\unit\\test_llm_service.py:282: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.llm_service - INFO - \\u2705 Azure OpenAI LLM client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.llm_service:logger.py:79 \\u2705 Azure OpenAI LLM client initialized\n______________ TestPineconeService.test_create_embedding_failure ______________\n\nself = <tests.unit.test_pinecone_service.TestPineconeService object at 0x000002926566E650>\nmock_azure_openai = <MagicMock name='AzureOpenAI' id='2827815981072'>\nmock_pinecone = <MagicMock name='Pinecone' id='2827815981408'>\n\n    @patch('src.services.pinecone_service.Pinecone')\n    @patch('src.services.pinecone_service.AzureOpenAI')\n    def test_create_embedding_failure(self, mock_azure_openai, mock_pinecone):\n        \"\"\"Test embedding creation failure\"\"\"\n        mock_client = Mock()\n        mock_client.embeddings.create.side_effect = Exception(\"API Error\")\n        mock_azure_openai.return_value = mock_client\n    \n        service = PineconeService()\n    \n        # Test embedding creation failure\n        result = service.create_embedding(\"laptop Dell\")\n    \n        # Verify failure handling\n>       assert result is None\nE       assert [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...] is None\n\ntests\\unit\\test_pinecone_service.py:87: AssertionError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Failed to create embedding: API Error\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Failed to create embedding: API Error\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Failed to create embedding: API Error\n______________ TestPineconeService.test_upsert_products_success _______________\n\nself = <tests.unit.test_pinecone_service.TestPineconeService object at 0x000002926566E780>\nmock_azure_openai = <MagicMock name='AzureOpenAI' id='2827817049392'>\nmock_pinecone = <MagicMock name='Pinecone' id='2827817047040'>\nmock_embedding_client = <Mock name='AzureOpenAI()' id='2827817051744'>\nsample_products = [{'availability': 'in_stock', 'brand': 'Dell', 'category': 'laptop', 'currency': 'VND', ...}, {'availability': 'in_stock', 'brand': 'Apple', 'category': 'smartphone', 'currency': 'VND', ...}]\n\n    @patch('src.services.pinecone_service.Pinecone')\n    @patch('src.services.pinecone_service.AzureOpenAI')\n    def test_upsert_products_success(self, mock_azure_openai, mock_pinecone, mock_embedding_client, sample_products):\n        \"\"\"Test successful product upserting\"\"\"\n        mock_pc, mock_index = self.mock_pinecone_client()\n        mock_pinecone.return_value = mock_pc\n        mock_azure_openai.return_value = mock_embedding_client\n    \n        service = PineconeService()\n        service.index = mock_index\n    \n        # Test product upserting\n>       result = service.upsert_products(sample_products)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: 'PineconeService' object has no attribute 'upsert_products'. Did you mean: 'search_products'?\n\ntests\\unit\\test_pinecone_service.py:101: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\n______________ TestPineconeService.test_upsert_products_failure _______________\n\nself = <tests.unit.test_pinecone_service.TestPineconeService object at 0x000002926551F0B0>\nmock_azure_openai = <MagicMock name='AzureOpenAI' id='2827817045024'>\nmock_pinecone = <MagicMock name='Pinecone' id='2827817050064'>\nsample_products = [{'availability': 'in_stock', 'brand': 'Dell', 'category': 'laptop', 'currency': 'VND', ...}, {'availability': 'in_stock', 'brand': 'Apple', 'category': 'smartphone', 'currency': 'VND', ...}]\n\n    @patch('src.services.pinecone_service.Pinecone')\n    @patch('src.services.pinecone_service.AzureOpenAI')\n    def test_upsert_products_failure(self, mock_azure_openai, mock_pinecone, sample_products):\n        \"\"\"Test product upserting failure\"\"\"\n        mock_pc, mock_index = self.mock_pinecone_client()\n        mock_index.upsert.side_effect = Exception(\"Upsert Error\")\n        mock_pinecone.return_value = mock_pc\n    \n        service = PineconeService()\n        service.index = mock_index\n    \n        # Test product upserting failure\n>       result = service.upsert_products(sample_products)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: 'PineconeService' object has no attribute 'upsert_products'. Did you mean: 'search_products'?\n\ntests\\unit\\test_pinecone_service.py:119: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\n______________ TestPineconeService.test_search_products_failure _______________\n\nself = <tests.unit.test_pinecone_service.TestPineconeService object at 0x0000029265721850>\nmock_azure_openai = <MagicMock name='AzureOpenAI' id='2827794184384'>\nmock_pinecone = <MagicMock name='Pinecone' id='2827816230528'>\n\n    @patch('src.services.pinecone_service.Pinecone')\n    @patch('src.services.pinecone_service.AzureOpenAI')\n    def test_search_products_failure(self, mock_azure_openai, mock_pinecone):\n        \"\"\"Test product search failure\"\"\"\n        mock_pc, mock_index = self.mock_pinecone_client()\n        mock_index.query.side_effect = Exception(\"Search Error\")\n        mock_pinecone.return_value = mock_pc\n    \n        service = PineconeService()\n        service.index = mock_index\n    \n        # Test product search failure\n>       results = service.search_products(\"laptop Dell\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ntests\\unit\\test_pinecone_service.py:200: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nsrc\\services\\pinecone_service.py:246: in search_products\n    raise e\nsrc\\services\\pinecone_service.py:199: in search_products\n    results = self.index.query(\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1169: in __call__\n    return self._mock_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1173: in _mock_call\n    return self._execute_mock_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Mock name='Pinecone().Index().query' id='2827818528656'>, args = ()\nkwargs = {'filter': {'type': 'product'}, 'include_metadata': True, 'top_k': 5, 'vector': <MagicMock name='AzureOpenAI().embeddings.create().data.__getitem__().embedding' id='2827794178672'>}\neffect = Exception('Search Error')\n\n    def _execute_mock_call(self, /, *args, **kwargs):\n        # separate from _increment_mock_call so that awaited functions are\n        # executed separately from their call, also AsyncMock overrides this method\n    \n        effect = self.side_effect\n        if effect is not None:\n            if _is_exception(effect):\n>               raise effect\nE               Exception: Search Error\n\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1228: Exception\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\U0001f50d Searching for: 'laptop Dell' with filters: {'type': 'product'}\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\U0001f50d Searching for: 'laptop Dell' with filters: {'type': 'product'}\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - Metadata filter applied:\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - Metadata filter applied:\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO -   type: product\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO -   type: product\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: Search Error\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: Search Error\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\U0001f50d Searching for: 'laptop Dell' with filters: {'type': 'product'}\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 Metadata filter applied:\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79   type: product\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: Search Error\n______________ TestPineconeService.test_get_index_stats_failure _______________\n\nself = <tests.unit.test_pinecone_service.TestPineconeService object at 0x0000029264E8B7A0>\nmock_azure_openai = <MagicMock name='AzureOpenAI' id='2827817046704'>\nmock_pinecone = <MagicMock name='Pinecone' id='2827817054096'>\n\n    @patch('src.services.pinecone_service.Pinecone')\n    @patch('src.services.pinecone_service.AzureOpenAI')\n    def test_get_index_stats_failure(self, mock_azure_openai, mock_pinecone):\n        \"\"\"Test index stats retrieval failure\"\"\"\n        mock_pc, mock_index = self.mock_pinecone_client()\n        mock_index.describe_index_stats.side_effect = Exception(\"Stats Error\")\n        mock_pinecone.return_value = mock_pc\n    \n        service = PineconeService()\n        service.index = mock_index\n    \n        # Test index stats retrieval failure\n        stats = service.get_index_stats()\n    \n        # Verify failure handling\n>       assert stats is None\nE       assert {} is None\n\ntests\\unit\\test_pinecone_service.py:245: AssertionError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Failed to get index stats: Stats Error\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Failed to get index stats: Stats Error\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Failed to get index stats: Stats Error\n________________ TestPineconeService.test_health_check_success ________________\n\nself = <tests.unit.test_pinecone_service.TestPineconeService object at 0x00000292657C44B0>\nmock_azure_openai = <MagicMock name='AzureOpenAI' id='2827818526304'>\nmock_pinecone = <MagicMock name='Pinecone' id='2827818529664'>\n\n    @patch('src.services.pinecone_service.Pinecone')\n    @patch('src.services.pinecone_service.AzureOpenAI')\n    def test_health_check_success(self, mock_azure_openai, mock_pinecone):\n        \"\"\"Test successful health check\"\"\"\n        mock_pc, mock_index = self.mock_pinecone_client()\n        mock_pinecone.return_value = mock_pc\n        mock_index.describe_index_stats.return_value = {\"total_vector_count\": 100}\n    \n        service = PineconeService()\n        service.index = mock_index\n    \n        # Test health check\n>       result = service.health_check()\n                 ^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: 'PineconeService' object has no attribute 'health_check'\n\ntests\\unit\\test_pinecone_service.py:293: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\n________________ TestPineconeService.test_health_check_failure ________________\n\nself = <tests.unit.test_pinecone_service.TestPineconeService object at 0x0000029265772F70>\nmock_azure_openai = <MagicMock name='AzureOpenAI' id='2827817045360'>\nmock_pinecone = <MagicMock name='Pinecone' id='2827794183376'>\n\n    @patch('src.services.pinecone_service.Pinecone')\n    @patch('src.services.pinecone_service.AzureOpenAI')\n    def test_health_check_failure(self, mock_azure_openai, mock_pinecone):\n        \"\"\"Test health check failure\"\"\"\n        mock_pc, mock_index = self.mock_pinecone_client()\n        mock_index.describe_index_stats.side_effect = Exception(\"Health Check Error\")\n        mock_pinecone.return_value = mock_pc\n    \n        service = PineconeService()\n        service.index = mock_index\n    \n        # Test health check failure\n>       result = service.health_check()\n                 ^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: 'PineconeService' object has no attribute 'health_check'\n\ntests\\unit\\test_pinecone_service.py:311: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\n____________ TestPineconeService.test_prepare_product_for_indexing ____________\n\nself = <tests.unit.test_pinecone_service.TestPineconeService object at 0x00000292656E2E10>\nsample_products = [{'availability': 'in_stock', 'brand': 'Dell', 'category': 'laptop', 'currency': 'VND', ...}, {'availability': 'in_stock', 'brand': 'Apple', 'category': 'smartphone', 'currency': 'VND', ...}]\n\n    def test_prepare_product_for_indexing(self, sample_products):\n        \"\"\"Test product preparation for indexing\"\"\"\n        with patch('src.services.pinecone_service.Pinecone'), \\\n             patch('src.services.pinecone_service.AzureOpenAI'):\n            service = PineconeService()\n    \n            # Test product preparation\n            product = sample_products[0]\n>           prepared = service._prepare_product_for_indexing(product)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'PineconeService' object has no attribute '_prepare_product_for_indexing'\n\ntests\\unit\\test_pinecone_service.py:324: AttributeError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Pinecone client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.pinecone_service - INFO - \\u2705 Azure OpenAI embedding client initialized\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Pinecone client initialized\\nINFO     ecommerce_ai_advisor.pinecone_service:logger.py:79 \\u2705 Azure OpenAI embedding client initialized\n_________________ TestPromptType.test_prompt_type_enum_values _________________\n\nself = <tests.unit.test_prompts.TestPromptType object at 0x00000292657D02D0>\n\n    def test_prompt_type_enum_values(self):\n        \"\"\"Test PromptType enum has required values\"\"\"\n        # Test that all expected prompt types exist\n        expected_types = [\n            \"INTENT_CLASSIFICATION\",\n            \"SEARCH_SYSTEM\",\n            \"COMPARE_SYSTEM\",\n            \"RECOMMEND_SYSTEM\",\n            \"REVIEW_SYSTEM\",\n            \"GENERATION_BASE_SYSTEM\",\n            \"GENERATION_SEARCH\",\n            \"GENERATION_COMPARE\",\n            \"GENERATION_RECOMMEND\",\n            \"GENERATION_REVIEW\",\n            \"GENERATION_DIRECT\",\n            \"ERROR_HANDLING\",\n            \"GREETING_RESPONSE\"\n        ]\n    \n        # Get all enum values\n        actual_types = [prompt_type.name for prompt_type in PromptType]\n    \n        # Verify all expected types exist\n        for expected_type in expected_types:\n>           assert expected_type in actual_types\nE           AssertionError: assert 'SEARCH_SYSTEM' in ['SYSTEM_BASE', 'RECOMMEND_EXPLANATION', 'COMPARE_ANALYSIS', 'FALLBACK_SYSTEM', 'INTENT_CLASSIFICATION', 'SEARCH_EXTRACTION', ...]\n\ntests\\unit\\test_prompts.py:40: AssertionError\n____________ TestPromptManager.test_prompt_manager_initialization _____________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x00000292657D0550>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x0000029265A3B890>\n\n    def test_prompt_manager_initialization(self, prompt_manager):\n        \"\"\"Test PromptManager initialization\"\"\"\n        assert prompt_manager is not None\n>       assert hasattr(prompt_manager, 'prompts')\nE       AssertionError: assert False\nE        +  where False = hasattr(<src.prompts.prompt_manager.PromptManager object at 0x0000029265A3B890>, 'prompts')\n\ntests\\unit\\test_prompts.py:59: AssertionError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n___________ TestPromptManager.test_get_prompt_intent_classification ___________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x00000292657D0690>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x00000292657D39D0>\n\n    def test_get_prompt_intent_classification(self, prompt_manager):\n        \"\"\"Test getting intent classification prompt\"\"\"\n        prompt = prompt_manager.get_prompt(PromptType.INTENT_CLASSIFICATION)\n    \n        # Verify prompt exists and contains expected elements\n        assert prompt is not None\n>       assert isinstance(prompt, str)\nE       assert False\nE        +  where False = isinstance(PromptTemplate(input_variables=['user_input'], input_types={}, partial_variables={}, template='Ph\\xe2n t\\xedch \\xfd \\u0111\\u1ecbnh c\\u1ee7a ng\\u01b0\\u1eddi d\\xf9ng v\\xe0 tr\\u1ea3 v\\u1ec1 CH\\xcdNH X\\xc1C m\\u1ed9t trong c\\xe1c intent sau:\\\\n\\\\nINTENT OPTIONS:\\\\n- greeting: Ch\\xe0o h\\u1ecfi, c\\u1ea3m \\u01a1n, h\\u1ecfi v\\u1ec1 AI\\\\n- search: T\\xecm ki\\u1ebfm th\\xf4ng tin s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3, h\\u1ecfi c\\u1ea5u h\\xecnh, th\\xf4ng s\\u1ed1, gi\\xe1\\\\n- compare: So s\\xe1nh 2+ s\\u1ea3n ph\\u1ea9m\\\\n- recommend: Xin g\\u1ee3i \\xfd, t\\u01b0 v\\u1ea5n s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p v\\u1edbi nhu c\\u1ea7u\\\\n- review: Xem \\u0111\\xe1nh gi\\xe1, nh\\u1eadn x\\xe9t, reviews c\\u1ee7a s\\u1ea3n ph\\u1ea9m\\\\n- direct: C\\xe2u h\\u1ecfi t\\u1ed5ng qu\\xe1t v\\u1ec1 c\\xf4ng ngh\\u1ec7, thu\\u1eadt ng\\u1eef, kh\\xe1i ni\\u1ec7m\\\\n\\\\nUSER INPUT: \"{user_input}\"\\\\n\\\\nEXAMPLES:\\\\n- \"Xin ch\\xe0o\" \\u2192 greeting\\\\n- \"Dell Inspiron 14 5420 c\\u1ea5u h\\xecnh nh\\u01b0 th\\u1ebf n\\xe0o\" \\u2192 search\\\\n- \"iPhone 15 vs Samsung S24\" \\u2192 compare\\\\n- \"G\\u1ee3i \\xfd laptop cho sinh vi\\xean\" \\u2192 recommend\\\\n- \"T\\xf4i mu\\u1ed1n xem reviews iPhone 15\" \\u2192 review\\\\n- \"\\u0110\\xe1nh gi\\xe1 v\\u1ec1 Dell XPS 15\" \\u2192 review\\\\n- \"Ng\\u01b0\\u1eddi d\\xf9ng n\\xf3i g\\xec v\\u1ec1 Samsung S24?\" \\u2192 review\\\\n- \"Reviews laptop gaming ASUS ROG\" \\u2192 review\\\\n- \"C\\u1ea3m \\u01a1n b\\u1ea1n\" \\u2192 greeting\\\\n- \"RAM l\\xe0 g\\xec?\" \\u2192 direct\\\\n- \"S\\u1ef1 kh\\xe1c bi\\u1ec7t gi\\u1eefa SSD v\\xe0 HDD\" \\u2192 direct\\\\n- \"CPU Intel Core i7 ngh\\u0129a l\\xe0 g\\xec?\" \\u2192 direct\\\\n- \"L\\xe0m th\\u1ebf n\\xe0o \\u0111\\u1ec3 ch\\u1ecdn laptop ph\\xf9 h\\u1ee3p?\" \\u2192 direct\\\\n- \"M\\xe0n h\\xecnh OLED c\\xf3 \\u01b0u \\u0111i\\u1ec3m g\\xec?\" \\u2192 direct\\\\n- \"Xu h\\u01b0\\u1edbng smartphone 2024\" \\u2192 direct\\\\n\\\\nCh\\u1ec9 tr\\u1ea3 v\\u1ec1 T\\xcaN INTENT (greeting/search/compare/recommend/review/direct):'), str)\n\ntests\\unit\\test_prompts.py:68: AssertionError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_______________ TestPromptManager.test_get_prompt_search_system _______________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x000002926566E8B0>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x0000029266FD96E0>\n\n    def test_get_prompt_search_system(self, prompt_manager):\n        \"\"\"Test getting search system prompt\"\"\"\n>       prompt = prompt_manager.get_prompt(PromptType.SEARCH_SYSTEM)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: type object 'PromptType' has no attribute 'SEARCH_SYSTEM'\n\ntests\\unit\\test_prompts.py:75: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:06 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:06 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n______________ TestPromptManager.test_get_prompt_compare_system _______________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x000002926566E9E0>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x0000029266FD95B0>\n\n    def test_get_prompt_compare_system(self, prompt_manager):\n        \"\"\"Test getting compare system prompt\"\"\"\n>       prompt = prompt_manager.get_prompt(PromptType.COMPARE_SYSTEM)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: type object 'PromptType' has no attribute 'COMPARE_SYSTEM'\n\ntests\\unit\\test_prompts.py:85: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_____________ TestPromptManager.test_get_prompt_recommend_system ______________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x00000292657AED50>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x000002926705C050>\n\n    def test_get_prompt_recommend_system(self, prompt_manager):\n        \"\"\"Test getting recommend system prompt\"\"\"\n>       prompt = prompt_manager.get_prompt(PromptType.RECOMMEND_SYSTEM)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: type object 'PromptType' has no attribute 'RECOMMEND_SYSTEM'\n\ntests\\unit\\test_prompts.py:94: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_______________ TestPromptManager.test_get_prompt_review_system _______________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x0000029265741BF0>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x000002926709E690>\n\n    def test_get_prompt_review_system(self, prompt_manager):\n        \"\"\"Test getting review system prompt\"\"\"\n>       prompt = prompt_manager.get_prompt(PromptType.REVIEW_SYSTEM)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: type object 'PromptType' has no attribute 'REVIEW_SYSTEM'\n\ntests\\unit\\test_prompts.py:103: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n__________ TestPromptManager.test_get_prompt_generation_base_system ___________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x0000029265741D00>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x000002926709E250>\n\n    def test_get_prompt_generation_base_system(self, prompt_manager):\n        \"\"\"Test getting generation base system prompt\"\"\"\n        prompt = prompt_manager.get_prompt(PromptType.GENERATION_BASE_SYSTEM)\n    \n        # Verify prompt\n        assert prompt is not None\n>       assert isinstance(prompt, str)\nE       AssertionError: assert False\nE        +  where False = isinstance(PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='B\\u1ea1n l\\xe0 AI Product Advisor - tr\\u1ee3 l\\xfd t\\u01b0 v\\u1ea5n s\\u1ea3n ph\\u1ea9m \\u0111i\\u1ec7n t\\u1eed chuy\\xean nghi\\u1ec7p.\\\\n\\\\n\\U0001f3af NHI\\u1ec6M V\\u1ee4: T\\u1ea1o c\\xe2u tr\\u1ea3 l\\u1eddi t\\u1ef1 nhi\\xean, h\\u1eefu \\xedch d\\u1ef1a tr\\xean th\\xf4ng tin s\\u1ea3n ph\\u1ea9m \\u0111\\u01b0\\u1ee3c cung c\\u1ea5p.\\\\n\\\\n\\u26a1 NGUY\\xcaN T\\u1eaeC:\\\\n- Lu\\xf4n d\\u1ef1a tr\\xean th\\xf4ng tin ch\\xednh x\\xe1c t\\u1eeb context\\\\n- Ng\\xf4n ng\\u1eef t\\u1ef1 nhi\\xean, th\\xe2n thi\\u1ec7n nh\\u01b0 b\\u1ea1n b\\xe8 am hi\\u1ec3u c\\xf4ng ngh\\u1ec7\\\\n- Gi\\u1ea3i th\\xedch thu\\u1eadt ng\\u1eef k\\u1ef9 thu\\u1eadt b\\u1eb1ng c\\xe1ch d\\u1ec5 hi\\u1ec3u\\\\n- \\u0110\\u01b0a ra l\\u1eddi khuy\\xean thi\\u1ebft th\\u1ef1c v\\xe0 c\\xf3 c\\u0103n c\\u1ee9'), str)\n\ntests\\unit\\test_prompts.py:116: AssertionError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_____________ TestPromptManager.test_get_prompt_generation_search _____________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x0000029265722650>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x00000292658BC650>\n\n    def test_get_prompt_generation_search(self, prompt_manager):\n        \"\"\"Test getting generation search prompt\"\"\"\n>       prompt = prompt_manager.get_prompt(PromptType.GENERATION_SEARCH)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: type object 'PromptType' has no attribute 'GENERATION_SEARCH'. Did you mean: 'GENERATION_SEARCH_INTENT'?\n\ntests\\unit\\test_prompts.py:121: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n____________ TestPromptManager.test_get_prompt_generation_compare _____________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x0000029265722750>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x00000292658BCB50>\n\n    def test_get_prompt_generation_compare(self, prompt_manager):\n        \"\"\"Test getting generation compare prompt\"\"\"\n>       prompt = prompt_manager.get_prompt(PromptType.GENERATION_COMPARE)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: type object 'PromptType' has no attribute 'GENERATION_COMPARE'. Did you mean: 'GENERATION_COMPARE_INTENT'?\n\ntests\\unit\\test_prompts.py:130: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n___________ TestPromptManager.test_get_prompt_generation_recommend ____________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x0000029264E8B980>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x000002926584E4E0>\n\n    def test_get_prompt_generation_recommend(self, prompt_manager):\n        \"\"\"Test getting generation recommend prompt\"\"\"\n>       prompt = prompt_manager.get_prompt(PromptType.GENERATION_RECOMMEND)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: type object 'PromptType' has no attribute 'GENERATION_RECOMMEND'. Did you mean: 'GENERATION_RECOMMEND_INTENT'?\n\ntests\\unit\\test_prompts.py:139: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_____________ TestPromptManager.test_get_prompt_generation_review _____________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x0000029264E8BA70>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x000002926584EA80>\n\n    def test_get_prompt_generation_review(self, prompt_manager):\n        \"\"\"Test getting generation review prompt\"\"\"\n>       prompt = prompt_manager.get_prompt(PromptType.GENERATION_REVIEW)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: type object 'PromptType' has no attribute 'GENERATION_REVIEW'. Did you mean: 'GENERATION_REVIEW_INTENT'?\n\ntests\\unit\\test_prompts.py:148: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_____________ TestPromptManager.test_get_prompt_generation_direct _____________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x00000292657C6A50>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x000002926726CBB0>\n\n    def test_get_prompt_generation_direct(self, prompt_manager):\n        \"\"\"Test getting generation direct prompt\"\"\"\n>       prompt = prompt_manager.get_prompt(PromptType.GENERATION_DIRECT)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: type object 'PromptType' has no attribute 'GENERATION_DIRECT'. Did you mean: 'GENERATION_DIRECT_INTENT'?\n\ntests\\unit\\test_prompts.py:157: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n______________ TestPromptManager.test_get_prompt_error_handling _______________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x00000292657C6DD0>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x00000292671E3AF0>\n\n    def test_get_prompt_error_handling(self, prompt_manager):\n        \"\"\"Test getting error handling prompt\"\"\"\n>       prompt = prompt_manager.get_prompt(PromptType.ERROR_HANDLING)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: type object 'PromptType' has no attribute 'ERROR_HANDLING'\n\ntests\\unit\\test_prompts.py:166: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_____________ TestPromptManager.test_get_prompt_greeting_response _____________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x00000292657735F0>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x0000029266EB6F70>\n\n    def test_get_prompt_greeting_response(self, prompt_manager):\n        \"\"\"Test getting greeting response prompt\"\"\"\n>       prompt = prompt_manager.get_prompt(PromptType.GREETING_RESPONSE)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: type object 'PromptType' has no attribute 'GREETING_RESPONSE'\n\ntests\\unit\\test_prompts.py:175: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_____ TestPromptManager.test_prompt_templates_have_required_placeholders ______\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x00000292657B56D0>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x0000029267073A70>\n\n    def test_prompt_templates_have_required_placeholders(self, prompt_manager):\n        \"\"\"Test that prompt templates have required placeholders\"\"\"\n        # Test specific prompts have expected placeholders\n        test_cases = [\n            (PromptType.INTENT_CLASSIFICATION, [\"{user_input}\"]),\n>           (PromptType.GENERATION_SEARCH, [\"{user_query}\", \"{search_results}\"]),\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n            (PromptType.GENERATION_COMPARE, [\"{user_query}\", \"{comparison_results}\"]),\n            (PromptType.GENERATION_RECOMMEND, [\"{user_query}\", \"{recommendation_results}\"]),\n            (PromptType.GENERATION_REVIEW, [\"{user_query}\", \"{review_results}\"]),\n            (PromptType.GENERATION_DIRECT, [\"{user_query}\"])\n        ]\nE       AttributeError: type object 'PromptType' has no attribute 'GENERATION_SEARCH'. Did you mean: 'GENERATION_SEARCH_INTENT'?\n\ntests\\unit\\test_prompts.py:256: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_______ TestPromptManager.test_prompt_templates_are_vietnamese_friendly _______\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x000002926578B0B0>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x0000029265A82450>\n\n    def test_prompt_templates_are_vietnamese_friendly(self, prompt_manager):\n        \"\"\"Test that prompt templates support Vietnamese\"\"\"\n        # Get a few key prompts\n        prompts_to_test = [\n            PromptType.GENERATION_BASE_SYSTEM,\n>           PromptType.GREETING_RESPONSE,\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n            PromptType.ERROR_HANDLING\n        ]\nE       AttributeError: type object 'PromptType' has no attribute 'GREETING_RESPONSE'\n\ntests\\unit\\test_prompts.py:285: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n____________ TestPromptManager.test_all_prompt_types_have_prompts _____________\n\nself = <tests.unit.test_prompts.TestPromptManager object at 0x00000292657AB1C0>\nprompt_manager = <src.prompts.prompt_manager.PromptManager object at 0x00000292670091D0>\n\n    def test_all_prompt_types_have_prompts(self, prompt_manager):\n        \"\"\"Test that all prompt types have corresponding prompts\"\"\"\n        missing_prompts = []\n    \n        for prompt_type in PromptType:\n            prompt = prompt_manager.get_prompt(prompt_type)\n>           if prompt is None or prompt.strip() == \"\":\n                                 ^^^^^^^^^^^^\n\ntests\\unit\\test_prompts.py:327: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = ChatPromptTemplate(input_variables=['context', 'special_instructions'], input_types={}, partial_variables={}, messages... c\\u1ea7n l\\u01b0u \\xfd (n\\u1ebfu c\\xf3)\\\\n\\\\n\\U0001f3a8 NG\\u1eee C\\u1ea2NH: {context}\\\\n\\\\n\\U0001f4dd H\\u01af\\u1edaNG D\\u1eaaN \\u0110\\u1eb6C BI\\u1ec6T: {special_instructions}'), additional_kwargs={})])\nitem = 'strip'\n\n    def __getattr__(self, item: str) -> Any:\n        private_attributes = object.__getattribute__(self, '__private_attributes__')\n        if item in private_attributes:\n            attribute = private_attributes[item]\n            if hasattr(attribute, '__get__'):\n                return attribute.__get__(self, type(self))  # type: ignore\n    \n            try:\n                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items\n                return self.__pydantic_private__[item]  # type: ignore\n            except KeyError as exc:\n                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc\n        else:\n            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.\n            # See `BaseModel.__repr_args__` for more details\n            try:\n                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')\n            except AttributeError:\n                pydantic_extra = None\n    \n            if pydantic_extra:\n                try:\n                    return pydantic_extra[item]\n                except KeyError as exc:\n                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc\n            else:\n                if hasattr(self.__class__, item):\n                    return super().__getattribute__(item)  # Raises AttributeError if appropriate\n                else:\n                    # this is the current error\n>                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\nE                   AttributeError: 'ChatPromptTemplate' object has no attribute 'strip'\n\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydantic\\main.py:991: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.prompts - INFO - \\u2705 Prompt templates initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompts:logger.py:79 \\u2705 Prompt templates initialized\n_______________ TestSearchTool.test_search_tool_initialization ________________\n\nself = <tests.unit.test_tools.TestSearchTool object at 0x00000292657D0A50>\nmock_pinecone_service = <MagicMock name='pinecone_service' id='2827794177664'>\n\n    @patch('src.tools.search_tool.pinecone_service')\n    def test_search_tool_initialization(self, mock_pinecone_service):\n        \"\"\"Test SearchTool initialization\"\"\"\n        tool = SearchTool()\n    \n        # Verify initialization\n        assert tool.name == \"search_products\"\n>       assert \"search\" in tool.description.lower()\nE       assert 'search' in '\\U0001f50d t\\xecm ki\\u1ebfm s\\u1ea3n ph\\u1ea9m theo ti\\xeau ch\\xed c\\u1ee5 th\\u1ec3.\\\\n    \\\\n    m\\u1ee5c \\u0111\\xedch: t\\xecm s\\u1ea3n ph\\u1ea9m d\\u1ef1a tr\\xean c\\xe1c b\\u1ed9 l\\u1ecdc v\\xe0 ti\\xeau ch\\xed nh\\u1ea5t \\u0111\\u1ecbnh\\\\n    \\\\n    s\\u1eed d\\u1ee5ng khi:\\\\n    - kh\\xe1ch h\\xe0ng t\\xecm s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3: \"t\\xecm laptop dell\", \"iphone 15 pro max\"\\\\n    - l\\u1ecdc theo th\\u01b0\\u01a1ng hi\\u1ec7u: \"laptop hp\", \"smartphone samsung\"  \\\\n    - l\\u1ecdc theo gi\\xe1: \"laptop d\\u01b0\\u1edbi 25 tri\\u1ec7u\", \"\\u0111i\\u1ec7n tho\\u1ea1i t\\u1eeb 10-20 tri\\u1ec7u\"\\\\n    - l\\u1ecdc theo t\\xednh n\\u0103ng: \"laptop c\\xf3 ssd\", \"smartphone camera 48mp\"\\\\n    - t\\xecm theo m\\u1ee5c \\u0111\\xedch s\\u1eed d\\u1ee5ng: \"laptop gaming\", \"smartphone ch\\u1ee5p \\u1ea3nh\"\\\\n    \\\\n    kh\\xf4ng d\\xf9ng cho: g\\u1ee3i \\xfd ho\\u1eb7c t\\u01b0 v\\u1ea5n s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p\\\\n    \\\\n    output: danh s\\xe1ch s\\u1ea3n ph\\u1ea9m kh\\u1edbp v\\u1edbi filters, kh\\xf4ng c\\xf3 ranking'\nE        +  where '\\U0001f50d t\\xecm ki\\u1ebfm s\\u1ea3n ph\\u1ea9m theo ti\\xeau ch\\xed c\\u1ee5 th\\u1ec3.\\\\n    \\\\n    m\\u1ee5c \\u0111\\xedch: t\\xecm s\\u1ea3n ph\\u1ea9m d\\u1ef1a tr\\xean c\\xe1c b\\u1ed9 l\\u1ecdc v\\xe0 ti\\xeau ch\\xed nh\\u1ea5t \\u0111\\u1ecbnh\\\\n    \\\\n    s\\u1eed d\\u1ee5ng khi:\\\\n    - kh\\xe1ch h\\xe0ng t\\xecm s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3: \"t\\xecm laptop dell\", \"iphone 15 pro max\"\\\\n    - l\\u1ecdc theo th\\u01b0\\u01a1ng hi\\u1ec7u: \"laptop hp\", \"smartphone samsung\"  \\\\n    - l\\u1ecdc theo gi\\xe1: \"laptop d\\u01b0\\u1edbi 25 tri\\u1ec7u\", \"\\u0111i\\u1ec7n tho\\u1ea1i t\\u1eeb 10-20 tri\\u1ec7u\"\\\\n    - l\\u1ecdc theo t\\xednh n\\u0103ng: \"laptop c\\xf3 ssd\", \"smartphone camera 48mp\"\\\\n    - t\\xecm theo m\\u1ee5c \\u0111\\xedch s\\u1eed d\\u1ee5ng: \"laptop gaming\", \"smartphone ch\\u1ee5p \\u1ea3nh\"\\\\n    \\\\n    kh\\xf4ng d\\xf9ng cho: g\\u1ee3i \\xfd ho\\u1eb7c t\\u01b0 v\\u1ea5n s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p\\\\n    \\\\n    output: danh s\\xe1ch s\\u1ea3n ph\\u1ea9m kh\\u1edbp v\\u1edbi filters, kh\\xf4ng c\\xf3 ranking' = <built-in method lower of str object at 0x0000029253950B70>()\nE        +    where <built-in method lower of str object at 0x0000029253950B70> = '\\U0001f50d T\\xccM KI\\u1ebeM s\\u1ea3n ph\\u1ea9m theo ti\\xeau ch\\xed c\\u1ee5 th\\u1ec3.\\\\n    \\\\n    M\\u1ee4C \\u0110\\xcdCH: T\\xecm s\\u1ea3n ph\\u1ea9m d\\u1ef1a tr\\xean c\\xe1c b\\u1ed9 l\\u1ecdc v\\xe0 ti\\xeau ch\\xed nh\\u1ea5t \\u0111\\u1ecbnh\\\\n    \\\\n    S\\u1eec D\\u1ee4NG KHI:\\\\n    - Kh\\xe1ch h\\xe0ng T\\xccM s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3: \"t\\xecm laptop Dell\", \"iPhone 15 Pro Max\"\\\\n    - L\\u1ecdc theo th\\u01b0\\u01a1ng hi\\u1ec7u: \"laptop HP\", \"smartphone Samsung\"  \\\\n    - L\\u1ecdc theo gi\\xe1: \"laptop d\\u01b0\\u1edbi 25 tri\\u1ec7u\", \"\\u0111i\\u1ec7n tho\\u1ea1i t\\u1eeb 10-20 tri\\u1ec7u\"\\\\n    - L\\u1ecdc theo t\\xednh n\\u0103ng: \"laptop c\\xf3 SSD\", \"smartphone camera 48MP\"\\\\n    - T\\xecm theo m\\u1ee5c \\u0111\\xedch s\\u1eed d\\u1ee5ng: \"laptop gaming\", \"smartphone ch\\u1ee5p \\u1ea3nh\"\\\\n    \\\\n    KH\\xd4NG d\\xf9ng cho: G\\u1ee3i \\xfd ho\\u1eb7c t\\u01b0 v\\u1ea5n s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p\\\\n    \\\\n    OUTPUT: Danh s\\xe1ch s\\u1ea3n ph\\u1ea9m kh\\u1edbp v\\u1edbi filters, kh\\xf4ng c\\xf3 ranking'.lower\nE        +      where '\\U0001f50d T\\xccM KI\\u1ebeM s\\u1ea3n ph\\u1ea9m theo ti\\xeau ch\\xed c\\u1ee5 th\\u1ec3.\\\\n    \\\\n    M\\u1ee4C \\u0110\\xcdCH: T\\xecm s\\u1ea3n ph\\u1ea9m d\\u1ef1a tr\\xean c\\xe1c b\\u1ed9 l\\u1ecdc v\\xe0 ti\\xeau ch\\xed nh\\u1ea5t \\u0111\\u1ecbnh\\\\n    \\\\n    S\\u1eec D\\u1ee4NG KHI:\\\\n    - Kh\\xe1ch h\\xe0ng T\\xccM s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3: \"t\\xecm laptop Dell\", \"iPhone 15 Pro Max\"\\\\n    - L\\u1ecdc theo th\\u01b0\\u01a1ng hi\\u1ec7u: \"laptop HP\", \"smartphone Samsung\"  \\\\n    - L\\u1ecdc theo gi\\xe1: \"laptop d\\u01b0\\u1edbi 25 tri\\u1ec7u\", \"\\u0111i\\u1ec7n tho\\u1ea1i t\\u1eeb 10-20 tri\\u1ec7u\"\\\\n    - L\\u1ecdc theo t\\xednh n\\u0103ng: \"laptop c\\xf3 SSD\", \"smartphone camera 48MP\"\\\\n    - T\\xecm theo m\\u1ee5c \\u0111\\xedch s\\u1eed d\\u1ee5ng: \"laptop gaming\", \"smartphone ch\\u1ee5p \\u1ea3nh\"\\\\n    \\\\n    KH\\xd4NG d\\xf9ng cho: G\\u1ee3i \\xfd ho\\u1eb7c t\\u01b0 v\\u1ea5n s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p\\\\n    \\\\n    OUTPUT: Danh s\\xe1ch s\\u1ea3n ph\\u1ea9m kh\\u1edbp v\\u1edbi filters, kh\\xf4ng c\\xf3 ranking' = SearchTool().description\n\ntests\\unit\\test_tools.py:99: AssertionError\n______________ TestCompareTool.test_compare_tool_initialization _______________\n\nself = <tests.unit.test_tools.TestCompareTool object at 0x00000292657D0CD0>\nmock_pinecone_service = <MagicMock name='pinecone_service' id='2827816233552'>\n\n    @patch('src.tools.compare_tool.pinecone_service')\n    def test_compare_tool_initialization(self, mock_pinecone_service):\n        \"\"\"Test CompareTool initialization\"\"\"\n        tool = CompareTool()\n    \n        # Verify initialization\n        assert tool.name == \"compare_products\"\n>       assert \"compare\" in tool.description.lower()\nE       assert 'compare' in 'so s\\xe1nh chi ti\\u1ebft nhi\\u1ec1u s\\u1ea3n ph\\u1ea9m c\\u1ea1nh nhau.\\\\n    \\\\n    s\\u1eed d\\u1ee5ng tool n\\xe0y khi:\\\\n    - kh\\xe1ch h\\xe0ng mu\\u1ed1n so s\\xe1nh 2-3 s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3\\\\n    - c\\u1ea7n ph\\xe2n t\\xedch \\u01b0u nh\\u01b0\\u1ee3c \\u0111i\\u1ec3m t\\u1eebng s\\u1ea3n ph\\u1ea9m\\\\n    - mu\\u1ed1n \\u0111\\u01b0a ra k\\u1ebft lu\\u1eadn v\\u1ec1 s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p nh\\u1ea5t\\\\n    - so s\\xe1nh theo kh\\xeda c\\u1ea1nh c\\u1ee5 th\\u1ec3 (gi\\xe1, hi\\u1ec7u n\\u0103ng, camera, v.v.)\\\\n    \\\\n    input format:\\\\n    {\\\\n        \"product_ids\": [\"t\\xean ho\\u1eb7c id s\\u1ea3n ph\\u1ea9m 1\", \"t\\xean ho\\u1eb7c id s\\u1ea3n ph\\u1ea9m 2\"],\\\\n        \"comparison_aspects\": [\"kh\\xeda c\\u1ea1nh 1\", \"kh\\xeda c\\u1ea1nh 2\"],\\\\n        \"include_reviews\": true/false\\\\n    }\\\\n    \\\\n    v\\xed d\\u1ee5 s\\u1eed d\\u1ee5ng:\\\\n    - {\"product_ids\": [\"iphone 15\", \"iphone 15 pro max\"], \"comparison_aspects\": [\"gi\\xe1\", \"camera\", \"hi\\u1ec7u n\\u0103ng\"]}\\\\n    - {\"product_ids\": [\"dell xps 15\", \"macbook air m2\"], \"comparison_aspects\": [\"hi\\u1ec7u n\\u0103ng\", \"gi\\xe1\", \"pin\"]}\\\\n    \\\\n    tool s\\u1ebd t\\u1ef1 \\u0111\\u1ed9ng t\\xecm s\\u1ea3n ph\\u1ea9m theo t\\xean v\\xe0 tr\\u1ea3 v\\u1ec1 b\\u1ea3ng so s\\xe1nh chi ti\\u1ebft.'\nE        +  where 'so s\\xe1nh chi ti\\u1ebft nhi\\u1ec1u s\\u1ea3n ph\\u1ea9m c\\u1ea1nh nhau.\\\\n    \\\\n    s\\u1eed d\\u1ee5ng tool n\\xe0y khi:\\\\n    - kh\\xe1ch h\\xe0ng mu\\u1ed1n so s\\xe1nh 2-3 s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3\\\\n    - c\\u1ea7n ph\\xe2n t\\xedch \\u01b0u nh\\u01b0\\u1ee3c \\u0111i\\u1ec3m t\\u1eebng s\\u1ea3n ph\\u1ea9m\\\\n    - mu\\u1ed1n \\u0111\\u01b0a ra k\\u1ebft lu\\u1eadn v\\u1ec1 s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p nh\\u1ea5t\\\\n    - so s\\xe1nh theo kh\\xeda c\\u1ea1nh c\\u1ee5 th\\u1ec3 (gi\\xe1, hi\\u1ec7u n\\u0103ng, camera, v.v.)\\\\n    \\\\n    input format:\\\\n    {\\\\n        \"product_ids\": [\"t\\xean ho\\u1eb7c id s\\u1ea3n ph\\u1ea9m 1\", \"t\\xean ho\\u1eb7c id s\\u1ea3n ph\\u1ea9m 2\"],\\\\n        \"comparison_aspects\": [\"kh\\xeda c\\u1ea1nh 1\", \"kh\\xeda c\\u1ea1nh 2\"],\\\\n        \"include_reviews\": true/false\\\\n    }\\\\n    \\\\n    v\\xed d\\u1ee5 s\\u1eed d\\u1ee5ng:\\\\n    - {\"product_ids\": [\"iphone 15\", \"iphone 15 pro max\"], \"comparison_aspects\": [\"gi\\xe1\", \"camera\", \"hi\\u1ec7u n\\u0103ng\"]}\\\\n    - {\"product_ids\": [\"dell xps 15\", \"macbook air m2\"], \"comparison_aspects\": [\"hi\\u1ec7u n\\u0103ng\", \"gi\\xe1\", \"pin\"]}\\\\n    \\\\n    tool s\\u1ebd t\\u1ef1 \\u0111\\u1ed9ng t\\xecm s\\u1ea3n ph\\u1ea9m theo t\\xean v\\xe0 tr\\u1ea3 v\\u1ec1 b\\u1ea3ng so s\\xe1nh chi ti\\u1ebft.' = <built-in method lower of str object at 0x0000029252D60020>()\nE        +    where <built-in method lower of str object at 0x0000029252D60020> = 'So s\\xe1nh chi ti\\u1ebft nhi\\u1ec1u s\\u1ea3n ph\\u1ea9m c\\u1ea1nh nhau.\\\\n    \\\\n    S\\u1eed d\\u1ee5ng tool n\\xe0y khi:\\\\n    - Kh\\xe1ch h\\xe0ng mu\\u1ed1n so s\\xe1nh 2-3 s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3\\\\n    - C\\u1ea7n ph\\xe2n t\\xedch \\u01b0u nh\\u01b0\\u1ee3c \\u0111i\\u1ec3m t\\u1eebng s\\u1ea3n ph\\u1ea9m\\\\n    - Mu\\u1ed1n \\u0111\\u01b0a ra k\\u1ebft lu\\u1eadn v\\u1ec1 s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p nh\\u1ea5t\\\\n    - So s\\xe1nh theo kh\\xeda c\\u1ea1nh c\\u1ee5 th\\u1ec3 (gi\\xe1, hi\\u1ec7u n\\u0103ng, camera, v.v.)\\\\n    \\\\n    INPUT FORMAT:\\\\n    {\\\\n        \"product_ids\": [\"t\\xean ho\\u1eb7c ID s\\u1ea3n ph\\u1ea9m 1\", \"t\\xean ho\\u1eb7c ID s\\u1ea3n ph\\u1ea9m 2\"],\\\\n        \"comparison_aspects\": [\"kh\\xeda c\\u1ea1nh 1\", \"kh\\xeda c\\u1ea1nh 2\"],\\\\n        \"include_reviews\": true/false\\\\n    }\\\\n    \\\\n    V\\xcd D\\u1ee4 S\\u1eec D\\u1ee4NG:\\\\n    - {\"product_ids\": [\"iPhone 15\", \"iPhone 15 Pro Max\"], \"comparison_aspects\": [\"gi\\xe1\", \"camera\", \"hi\\u1ec7u n\\u0103ng\"]}\\\\n    - {\"product_ids\": [\"Dell XPS 15\", \"MacBook Air M2\"], \"comparison_aspects\": [\"hi\\u1ec7u n\\u0103ng\", \"gi\\xe1\", \"pin\"]}\\\\n    \\\\n    Tool s\\u1ebd t\\u1ef1 \\u0111\\u1ed9ng t\\xecm s\\u1ea3n ph\\u1ea9m theo t\\xean v\\xe0 tr\\u1ea3 v\\u1ec1 b\\u1ea3ng so s\\xe1nh chi ti\\u1ebft.'.lower\nE        +      where 'So s\\xe1nh chi ti\\u1ebft nhi\\u1ec1u s\\u1ea3n ph\\u1ea9m c\\u1ea1nh nhau.\\\\n    \\\\n    S\\u1eed d\\u1ee5ng tool n\\xe0y khi:\\\\n    - Kh\\xe1ch h\\xe0ng mu\\u1ed1n so s\\xe1nh 2-3 s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3\\\\n    - C\\u1ea7n ph\\xe2n t\\xedch \\u01b0u nh\\u01b0\\u1ee3c \\u0111i\\u1ec3m t\\u1eebng s\\u1ea3n ph\\u1ea9m\\\\n    - Mu\\u1ed1n \\u0111\\u01b0a ra k\\u1ebft lu\\u1eadn v\\u1ec1 s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p nh\\u1ea5t\\\\n    - So s\\xe1nh theo kh\\xeda c\\u1ea1nh c\\u1ee5 th\\u1ec3 (gi\\xe1, hi\\u1ec7u n\\u0103ng, camera, v.v.)\\\\n    \\\\n    INPUT FORMAT:\\\\n    {\\\\n        \"product_ids\": [\"t\\xean ho\\u1eb7c ID s\\u1ea3n ph\\u1ea9m 1\", \"t\\xean ho\\u1eb7c ID s\\u1ea3n ph\\u1ea9m 2\"],\\\\n        \"comparison_aspects\": [\"kh\\xeda c\\u1ea1nh 1\", \"kh\\xeda c\\u1ea1nh 2\"],\\\\n        \"include_reviews\": true/false\\\\n    }\\\\n    \\\\n    V\\xcd D\\u1ee4 S\\u1eec D\\u1ee4NG:\\\\n    - {\"product_ids\": [\"iPhone 15\", \"iPhone 15 Pro Max\"], \"comparison_aspects\": [\"gi\\xe1\", \"camera\", \"hi\\u1ec7u n\\u0103ng\"]}\\\\n    - {\"product_ids\": [\"Dell XPS 15\", \"MacBook Air M2\"], \"comparison_aspects\": [\"hi\\u1ec7u n\\u0103ng\", \"gi\\xe1\", \"pin\"]}\\\\n    \\\\n    Tool s\\u1ebd t\\u1ef1 \\u0111\\u1ed9ng t\\xecm s\\u1ea3n ph\\u1ea9m theo t\\xean v\\xe0 tr\\u1ea3 v\\u1ec1 b\\u1ea3ng so s\\xe1nh chi ti\\u1ebft.' = CompareTool().description\n\ntests\\unit\\test_tools.py:166: AssertionError\n____________ TestRecommendTool.test_recommend_tool_initialization _____________\n\nself = <tests.unit.test_tools.TestRecommendTool object at 0x00000292657D0F50>\nmock_pinecone_service = <MagicMock name='pinecone_service' id='2827816233216'>\n\n    @patch('src.tools.recommend_tool.pinecone_service')\n    def test_recommend_tool_initialization(self, mock_pinecone_service):\n        \"\"\"Test RecommendTool initialization\"\"\"\n        tool = RecommendTool()\n    \n        # Verify initialization\n        assert tool.name == \"recommend_products\"\n>       assert \"recommend\" in tool.description.lower()\nE       assert 'recommend' in '\\U0001f4a1 t\\u01b0 v\\u1ea5n v\\xe0 g\\u1ee3i \\xfd s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p v\\u1edbi nhu c\\u1ea7u c\\xe1 nh\\xe2n.\\\\n    \\\\n    m\\u1ee5c \\u0111\\xedch: \\u0111\\u01b0a ra g\\u1ee3i \\xfd s\\u1ea3n ph\\u1ea9m t\\u1ed1i \\u01b0u d\\u1ef1a tr\\xean ph\\xe2n t\\xedch nhu c\\u1ea7u ng\\u01b0\\u1eddi d\\xf9ng\\\\n    \\\\n    s\\u1eed d\\u1ee5ng khi:\\\\n    - kh\\xe1ch h\\xe0ng c\\u1ea7n t\\u01b0 v\\u1ea5n: \"g\\u1ee3i \\xfd laptop cho sinh vi\\xean\", \"n\\xean mua smartphone n\\xe0o\"\\\\n    - m\\xf4 t\\u1ea3 nhu c\\u1ea7u s\\u1eed d\\u1ee5ng: \"c\\u1ea7n laptop l\\u1eadp tr\\xecnh\", \"smartphone ch\\u1ee5p \\u1ea3nh \\u0111\\u1eb9p\"\\\\n    - c\\xf3 ng\\xe2n s\\xe1ch v\\xe0 y\\xeau c\\u1ea7u: \"laptop gaming d\\u01b0\\u1edbi 30 tri\\u1ec7u\", \"iphone hay samsung t\\u1ed1t h\\u01a1n\"\\\\n    - kh\\xf4ng bi\\u1ebft ch\\u1ecdn g\\xec: \"t\\u01b0 v\\u1ea5n laptop ph\\xf9 h\\u1ee3p\", \"\\u0111i\\u1ec7n tho\\u1ea1i n\\xe0o \\u0111\\xe1ng mua\"\\\\n    - so s\\xe1nh l\\u1ef1a ch\\u1ecdn: \"dell hay hp t\\u1ed1t h\\u01a1n cho v\\u0103n ph\\xf2ng\"\\\\n    \\\\n    kh\\xf4ng d\\xf9ng cho: t\\xecm ki\\u1ebfm s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3 \\u0111\\xe3 bi\\u1ebft t\\xean\\\\n    \\\\n    output: top g\\u1ee3i \\xfd c\\xf3 ranking + l\\xfd do chi ti\\u1ebft t\\u1ea1i sao ph\\xf9 h\\u1ee3p'\nE        +  where '\\U0001f4a1 t\\u01b0 v\\u1ea5n v\\xe0 g\\u1ee3i \\xfd s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p v\\u1edbi nhu c\\u1ea7u c\\xe1 nh\\xe2n.\\\\n    \\\\n    m\\u1ee5c \\u0111\\xedch: \\u0111\\u01b0a ra g\\u1ee3i \\xfd s\\u1ea3n ph\\u1ea9m t\\u1ed1i \\u01b0u d\\u1ef1a tr\\xean ph\\xe2n t\\xedch nhu c\\u1ea7u ng\\u01b0\\u1eddi d\\xf9ng\\\\n    \\\\n    s\\u1eed d\\u1ee5ng khi:\\\\n    - kh\\xe1ch h\\xe0ng c\\u1ea7n t\\u01b0 v\\u1ea5n: \"g\\u1ee3i \\xfd laptop cho sinh vi\\xean\", \"n\\xean mua smartphone n\\xe0o\"\\\\n    - m\\xf4 t\\u1ea3 nhu c\\u1ea7u s\\u1eed d\\u1ee5ng: \"c\\u1ea7n laptop l\\u1eadp tr\\xecnh\", \"smartphone ch\\u1ee5p \\u1ea3nh \\u0111\\u1eb9p\"\\\\n    - c\\xf3 ng\\xe2n s\\xe1ch v\\xe0 y\\xeau c\\u1ea7u: \"laptop gaming d\\u01b0\\u1edbi 30 tri\\u1ec7u\", \"iphone hay samsung t\\u1ed1t h\\u01a1n\"\\\\n    - kh\\xf4ng bi\\u1ebft ch\\u1ecdn g\\xec: \"t\\u01b0 v\\u1ea5n laptop ph\\xf9 h\\u1ee3p\", \"\\u0111i\\u1ec7n tho\\u1ea1i n\\xe0o \\u0111\\xe1ng mua\"\\\\n    - so s\\xe1nh l\\u1ef1a ch\\u1ecdn: \"dell hay hp t\\u1ed1t h\\u01a1n cho v\\u0103n ph\\xf2ng\"\\\\n    \\\\n    kh\\xf4ng d\\xf9ng cho: t\\xecm ki\\u1ebfm s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3 \\u0111\\xe3 bi\\u1ebft t\\xean\\\\n    \\\\n    output: top g\\u1ee3i \\xfd c\\xf3 ranking + l\\xfd do chi ti\\u1ebft t\\u1ea1i sao ph\\xf9 h\\u1ee3p' = <built-in method lower of str object at 0x0000029253BE8430>()\nE        +    where <built-in method lower of str object at 0x0000029253BE8430> = '\\U0001f4a1 T\\u01af V\\u1ea4N v\\xe0 G\\u1ee2I \\xdd s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p v\\u1edbi nhu c\\u1ea7u c\\xe1 nh\\xe2n.\\\\n    \\\\n    M\\u1ee4C \\u0110\\xcdCH: \\u0110\\u01b0a ra g\\u1ee3i \\xfd s\\u1ea3n ph\\u1ea9m t\\u1ed1i \\u01b0u d\\u1ef1a tr\\xean ph\\xe2n t\\xedch nhu c\\u1ea7u ng\\u01b0\\u1eddi d\\xf9ng\\\\n    \\\\n    S\\u1eec D\\u1ee4NG KHI:\\\\n    - Kh\\xe1ch h\\xe0ng C\\u1ea6N T\\u01af V\\u1ea4N: \"g\\u1ee3i \\xfd laptop cho sinh vi\\xean\", \"n\\xean mua smartphone n\\xe0o\"\\\\n    - M\\xf4 t\\u1ea3 nhu c\\u1ea7u s\\u1eed d\\u1ee5ng: \"c\\u1ea7n laptop l\\u1eadp tr\\xecnh\", \"smartphone ch\\u1ee5p \\u1ea3nh \\u0111\\u1eb9p\"\\\\n    - C\\xf3 ng\\xe2n s\\xe1ch v\\xe0 y\\xeau c\\u1ea7u: \"laptop gaming d\\u01b0\\u1edbi 30 tri\\u1ec7u\", \"iPhone hay Samsung t\\u1ed1t h\\u01a1n\"\\\\n    - Kh\\xf4ng bi\\u1ebft ch\\u1ecdn g\\xec: \"t\\u01b0 v\\u1ea5n laptop ph\\xf9 h\\u1ee3p\", \"\\u0111i\\u1ec7n tho\\u1ea1i n\\xe0o \\u0111\\xe1ng mua\"\\\\n    - So s\\xe1nh l\\u1ef1a ch\\u1ecdn: \"Dell hay HP t\\u1ed1t h\\u01a1n cho v\\u0103n ph\\xf2ng\"\\\\n    \\\\n    KH\\xd4NG d\\xf9ng cho: T\\xecm ki\\u1ebfm s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3 \\u0111\\xe3 bi\\u1ebft t\\xean\\\\n    \\\\n    OUTPUT: Top g\\u1ee3i \\xfd c\\xf3 ranking + l\\xfd do chi ti\\u1ebft t\\u1ea1i sao ph\\xf9 h\\u1ee3p'.lower\nE        +      where '\\U0001f4a1 T\\u01af V\\u1ea4N v\\xe0 G\\u1ee2I \\xdd s\\u1ea3n ph\\u1ea9m ph\\xf9 h\\u1ee3p v\\u1edbi nhu c\\u1ea7u c\\xe1 nh\\xe2n.\\\\n    \\\\n    M\\u1ee4C \\u0110\\xcdCH: \\u0110\\u01b0a ra g\\u1ee3i \\xfd s\\u1ea3n ph\\u1ea9m t\\u1ed1i \\u01b0u d\\u1ef1a tr\\xean ph\\xe2n t\\xedch nhu c\\u1ea7u ng\\u01b0\\u1eddi d\\xf9ng\\\\n    \\\\n    S\\u1eec D\\u1ee4NG KHI:\\\\n    - Kh\\xe1ch h\\xe0ng C\\u1ea6N T\\u01af V\\u1ea4N: \"g\\u1ee3i \\xfd laptop cho sinh vi\\xean\", \"n\\xean mua smartphone n\\xe0o\"\\\\n    - M\\xf4 t\\u1ea3 nhu c\\u1ea7u s\\u1eed d\\u1ee5ng: \"c\\u1ea7n laptop l\\u1eadp tr\\xecnh\", \"smartphone ch\\u1ee5p \\u1ea3nh \\u0111\\u1eb9p\"\\\\n    - C\\xf3 ng\\xe2n s\\xe1ch v\\xe0 y\\xeau c\\u1ea7u: \"laptop gaming d\\u01b0\\u1edbi 30 tri\\u1ec7u\", \"iPhone hay Samsung t\\u1ed1t h\\u01a1n\"\\\\n    - Kh\\xf4ng bi\\u1ebft ch\\u1ecdn g\\xec: \"t\\u01b0 v\\u1ea5n laptop ph\\xf9 h\\u1ee3p\", \"\\u0111i\\u1ec7n tho\\u1ea1i n\\xe0o \\u0111\\xe1ng mua\"\\\\n    - So s\\xe1nh l\\u1ef1a ch\\u1ecdn: \"Dell hay HP t\\u1ed1t h\\u01a1n cho v\\u0103n ph\\xf2ng\"\\\\n    \\\\n    KH\\xd4NG d\\xf9ng cho: T\\xecm ki\\u1ebfm s\\u1ea3n ph\\u1ea9m c\\u1ee5 th\\u1ec3 \\u0111\\xe3 bi\\u1ebft t\\xean\\\\n    \\\\n    OUTPUT: Top g\\u1ee3i \\xfd c\\xf3 ranking + l\\xfd do chi ti\\u1ebft t\\u1ea1i sao ph\\xf9 h\\u1ee3p' = RecommendTool().description\n\ntests\\unit\\test_tools.py:228: AssertionError\n_______________ TestReviewTool.test_review_tool_initialization ________________\n\nself = <tests.unit.test_tools.TestReviewTool object at 0x00000292657D11D0>\nmock_pinecone_service = <MagicMock name='pinecone_service' id='2827816231872'>\n\n    @patch('src.tools.review_tool.pinecone_service')\n    def test_review_tool_initialization(self, mock_pinecone_service):\n        \"\"\"Test ReviewTool initialization\"\"\"\n        tool = ReviewTool()\n    \n        # Verify initialization\n>       assert tool.name == \"get_reviews\"\nE       AssertionError: assert 'get_product_reviews' == 'get_reviews'\nE         \nE         - get_reviews\nE         + get_product_reviews\n\ntests\\unit\\test_tools.py:292: AssertionError\n___________ TestGenerationTool.test_generation_tool_initialization ____________\n\nself = <tests.unit.test_tools.TestGenerationTool object at 0x00000292657D1450>\nmock_llm_service = <MagicMock name='llm_service' id='2827794174976'>\n\n    @patch('src.tools.generation_tool.llm_service')\n    def test_generation_tool_initialization(self, mock_llm_service):\n        \"\"\"Test GenerationTool initialization\"\"\"\n        tool = GenerationTool()\n    \n        # Verify initialization\n>       assert tool.name == \"generate_response\"\nE       AssertionError: assert 'answer_with_context' == 'generate_response'\nE         \nE         - generate_response\nE         + answer_with_context\n\ntests\\unit\\test_tools.py:358: AssertionError\n_______________ TestGenerationTool.test_generation_tool_success _______________\n\nself = <tests.unit.test_tools.TestGenerationTool object at 0x00000292657D1590>\nmock_llm_service = <MagicMock name='llm_service' id='2827794181696'>\n\n    @patch('src.tools.generation_tool.llm_service')\n    def test_generation_tool_success(self, mock_llm_service):\n        \"\"\"Test successful generation tool execution\"\"\"\n        # Setup mock\n        mock_llm_service.generate_response.return_value = \"Generated response in Vietnamese\"\n    \n        tool = GenerationTool()\n    \n        # Test response generation\n        generation_input = {\n            \"query\": \"What laptop should I buy?\",\n            \"context\": \"Found 3 Dell laptops in budget\",\n            \"intent\": \"search\",\n            \"conversation_history\": []\n        }\n>       result = tool.run(json.dumps(generation_input))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ntests\\unit\\test_tools.py:377: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:888: in run\n    raise error_to_raise\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:850: in run\n    tool_args, tool_kwargs = self._to_args_and_kwargs(\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:765: in _to_args_and_kwargs\n    tool_input = self._parse_input(tool_input, tool_call_id)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = GenerationTool()\ntool_input = '{\"query\": \"What laptop should I buy?\", \"context\": \"Found 3 Dell laptops in budget\", \"intent\": \"search\", \"conversation_history\": []}'\ntool_call_id = None\n\n    def _parse_input(\n        self, tool_input: Union[str, dict], tool_call_id: Optional[str]\n    ) -> Union[str, dict[str, Any]]:\n        \"\"\"Parse and validate tool input using the args schema.\n    \n        Args:\n            tool_input: The raw input to the tool.\n            tool_call_id: The ID of the tool call, if available.\n    \n        Returns:\n            The parsed and validated input.\n    \n        Raises:\n            ValueError: If string input is provided with JSON schema or if\n                InjectedToolCallId is required but not provided.\n            NotImplementedError: If args_schema is not a supported type.\n        \"\"\"\n        input_args = self.args_schema\n        if isinstance(tool_input, str):\n            if input_args is not None:\n                if isinstance(input_args, dict):\n                    msg = (\n                        \"String tool inputs are not allowed when \"\n                        \"using tools with JSON schema args_schema.\"\n                    )\n                    raise ValueError(msg)\n                key_ = next(iter(get_fields(input_args).keys()))\n                if issubclass(input_args, BaseModel):\n>                   input_args.model_validate({key_: tool_input})\nE                   pydantic_core._pydantic_core.ValidationError: 1 validation error for GenerationInput\nE                   intent\nE                     Field required [type=missing, input_value={'user_query': '{\"query\":...ersation_history\": []}'}, input_type=dict]\nE                       For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:646: ValidationError\n_____________ TestGenerationTool.test_generation_tool_llm_failure _____________\n\nself = <tests.unit.test_tools.TestGenerationTool object at 0x000002926566F820>\nmock_llm_service = <MagicMock name='llm_service' id='2827794178000'>\n\n    @patch('src.tools.generation_tool.llm_service')\n    def test_generation_tool_llm_failure(self, mock_llm_service):\n        \"\"\"Test generation tool when LLM fails\"\"\"\n        # Setup mock to return None (failure)\n        mock_llm_service.generate_response.return_value = None\n    \n        tool = GenerationTool()\n    \n        # Test generation with LLM failure\n        generation_input = {\n            \"query\": \"Test query\",\n            \"context\": \"Test context\"\n        }\n>       result = tool.run(json.dumps(generation_input))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ntests\\unit\\test_tools.py:399: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:888: in run\n    raise error_to_raise\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:850: in run\n    tool_args, tool_kwargs = self._to_args_and_kwargs(\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:765: in _to_args_and_kwargs\n    tool_input = self._parse_input(tool_input, tool_call_id)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = GenerationTool()\ntool_input = '{\"query\": \"Test query\", \"context\": \"Test context\"}'\ntool_call_id = None\n\n    def _parse_input(\n        self, tool_input: Union[str, dict], tool_call_id: Optional[str]\n    ) -> Union[str, dict[str, Any]]:\n        \"\"\"Parse and validate tool input using the args schema.\n    \n        Args:\n            tool_input: The raw input to the tool.\n            tool_call_id: The ID of the tool call, if available.\n    \n        Returns:\n            The parsed and validated input.\n    \n        Raises:\n            ValueError: If string input is provided with JSON schema or if\n                InjectedToolCallId is required but not provided.\n            NotImplementedError: If args_schema is not a supported type.\n        \"\"\"\n        input_args = self.args_schema\n        if isinstance(tool_input, str):\n            if input_args is not None:\n                if isinstance(input_args, dict):\n                    msg = (\n                        \"String tool inputs are not allowed when \"\n                        \"using tools with JSON schema args_schema.\"\n                    )\n                    raise ValueError(msg)\n                key_ = next(iter(get_fields(input_args).keys()))\n                if issubclass(input_args, BaseModel):\n>                   input_args.model_validate({key_: tool_input})\nE                   pydantic_core._pydantic_core.ValidationError: 1 validation error for GenerationInput\nE                   intent\nE                     Field required [type=missing, input_value={'user_query': '{\"query\":...text\": \"Test context\"}'}, input_type=dict]\nE                       For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:646: ValidationError\n_____________ TestToolIntegration.test_tools_return_json_strings ______________\n\nself = <tests.unit.test_tools.TestToolIntegration object at 0x000002926566FA80>\n\n    def test_tools_return_json_strings(self):\n        \"\"\"Test that all tools return valid JSON strings\"\"\"\n        # This is a basic test with minimal inputs\n        tools_and_inputs = [\n            (search_tool, '{\"query\": \"test\"}'),\n            (compare_tool, '{\"product_ids\": [\"test\"], \"comparison_aspects\": [\"price\"]}'),\n            (recommend_tool, '{\"user_needs\": \"test\", \"budget\": 1000000}'),\n            (review_tool, '{\"product_id\": \"test\"}'),\n            (generation_tool, '{\"query\": \"test\", \"context\": \"test\"}')\n        ]\n    \n        for tool, test_input in tools_and_inputs:\n            with patch('src.services.pinecone_service.pinecone_service'), \\\n                 patch('src.services.llm_service.llm_service'):\n                try:\n>                   result = tool.run(test_input)\n                             ^^^^^^^^^^^^^^^^^^^^\n\ntests\\unit\\test_tools.py:451: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:888: in run\n    raise error_to_raise\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:850: in run\n    tool_args, tool_kwargs = self._to_args_and_kwargs(\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:765: in _to_args_and_kwargs\n    tool_input = self._parse_input(tool_input, tool_call_id)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = GenerationTool(), tool_input = '{\"query\": \"test\", \"context\": \"test\"}'\ntool_call_id = None\n\n    def _parse_input(\n        self, tool_input: Union[str, dict], tool_call_id: Optional[str]\n    ) -> Union[str, dict[str, Any]]:\n        \"\"\"Parse and validate tool input using the args schema.\n    \n        Args:\n            tool_input: The raw input to the tool.\n            tool_call_id: The ID of the tool call, if available.\n    \n        Returns:\n            The parsed and validated input.\n    \n        Raises:\n            ValueError: If string input is provided with JSON schema or if\n                InjectedToolCallId is required but not provided.\n            NotImplementedError: If args_schema is not a supported type.\n        \"\"\"\n        input_args = self.args_schema\n        if isinstance(tool_input, str):\n            if input_args is not None:\n                if isinstance(input_args, dict):\n                    msg = (\n                        \"String tool inputs are not allowed when \"\n                        \"using tools with JSON schema args_schema.\"\n                    )\n                    raise ValueError(msg)\n                key_ = next(iter(get_fields(input_args).keys()))\n                if issubclass(input_args, BaseModel):\n>                   input_args.model_validate({key_: tool_input})\nE                   pydantic_core._pydantic_core.ValidationError: 1 validation error for GenerationInput\nE                   intent\nE                     Field required [type=missing, input_value={'user_query': '{\"query\":...t\", \"context\": \"test\"}'}, input_type=dict]\nE                       For further information visit https://errors.pydantic.dev/2.11/v/missing\n\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:646: ValidationError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <tests.unit.test_tools.TestToolIntegration object at 0x000002926566FA80>\n\n    def test_tools_return_json_strings(self):\n        \"\"\"Test that all tools return valid JSON strings\"\"\"\n        # This is a basic test with minimal inputs\n        tools_and_inputs = [\n            (search_tool, '{\"query\": \"test\"}'),\n            (compare_tool, '{\"product_ids\": [\"test\"], \"comparison_aspects\": [\"price\"]}'),\n            (recommend_tool, '{\"user_needs\": \"test\", \"budget\": 1000000}'),\n            (review_tool, '{\"product_id\": \"test\"}'),\n            (generation_tool, '{\"query\": \"test\", \"context\": \"test\"}')\n        ]\n    \n        for tool, test_input in tools_and_inputs:\n            with patch('src.services.pinecone_service.pinecone_service'), \\\n                 patch('src.services.llm_service.llm_service'):\n                try:\n                    result = tool.run(test_input)\n                    # Should be valid JSON\n                    json.loads(result)\n                except Exception as e:\n>                   pytest.fail(f\"Tool {tool.name} failed to return valid JSON: {e}\")\nE                   Failed: Tool answer_with_context failed to return valid JSON: 1 validation error for GenerationInput\nE                   intent\nE                     Field required [type=missing, input_value={'user_query': '{\"query\":...t\", \"context\": \"test\"}'}, input_type=dict]\nE                       For further information visit https://errors.pydantic.dev/2.11/v/missing\n\ntests\\unit\\test_tools.py:455: Failed\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:07 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'test'}\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f527 Parsed JSON tool input: {'query': 'test'}\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'test'\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f50d Searching products with query: 'test'\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: None\\n2025-08-23 13:12:07 - ecommerce_ai_advisor.search_tool - INFO - \\U0001f3af Search metadata: None\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '69630241c30c5d69bb65737a4e0e8a54', 'date': 'Sat, 23 Aug 2025 06:12:03 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '69630241c30c5d69bb65737a4e0e8a54', 'date': 'Sat, 23 Aug 2025 06:12:03 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Parsed JSON tool input: {'product_ids': ['test'], 'comparison_aspects': ['price']}\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Parsed JSON tool input: {'product_ids': ['test'], 'comparison_aspects': ['price']}\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Raw input - product_ids type: <class 'list'>, value: ['test']\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Raw input - product_ids type: <class 'list'>, value: ['test']\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Raw input - comparison_aspects: ['price']\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Raw input - comparison_aspects: ['price']\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Raw input - kwargs: {}\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Raw input - kwargs: {}\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Trying to parse JSON string: test\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f527 Trying to parse JSON string: test\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - ERROR - \\U0001f527 JSON decode error: Expecting value: line 1 column 1 (char 0)\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - ERROR - \\U0001f527 JSON decode error: Expecting value: line 1 column 1 (char 0)\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f50d Comparing products: ['test']\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f50d Comparing products: ['test']\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f50d Comparison aspects: ['price']\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f50d Comparison aspects: ['price']\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f50d Product count: 1\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.compare_tool - INFO - \\U0001f50d Product count: 1\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f527 Parsed JSON tool input: {'user_needs': 'test', 'budget': 1000000}\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f527 Parsed JSON tool input: {'user_needs': 'test', 'budget': 1000000}\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f3af Generating recommendations for: 'test'\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f3af Generating recommendations for: 'test'\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f4ca Recommendation metadata: None\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f4ca Recommendation metadata: None\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f50d Search filters applied: {'rating': {'$gte': 3.5}}\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.recommend_tool - INFO - \\U0001f50d Search filters applied: {'rating': {'$gte': 3.5}}\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'b52fb489a36ee9aabb65737a4e0e8df3', 'date': 'Sat, 23 Aug 2025 06:12:03 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'b52fb489a36ee9aabb65737a4e0e8df3', 'date': 'Sat, 23 Aug 2025 06:12:03 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.recommend_tool - ERROR - \\u274c Recommend tool error: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'b52fb489a36ee9aabb65737a4e0e8df3', 'date': 'Sat, 23 Aug 2025 06:12:03 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.recommend_tool - ERROR - \\u274c Recommend tool error: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'b52fb489a36ee9aabb65737a4e0e8df3', 'date': 'Sat, 23 Aug 2025 06:12:03 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.review_tool - INFO - \\U0001f4dd Getting reviews for product: '{\"product_id\": \"test\"}'\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.review_tool - INFO - \\U0001f4dd Getting reviews for product: '{\"product_id\": \"test\"}'\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '19c9a48c3b1c6858bb65737a4e0e8c8d', 'date': 'Sat, 23 Aug 2025 06:12:04 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.pinecone_service - ERROR - \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '19c9a48c3b1c6858bb65737a4e0e8c8d', 'date': 'Sat, 23 Aug 2025 06:12:04 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.review_tool - ERROR - \\u274c Error finding product: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '19c9a48c3b1c6858bb65737a4e0e8c8d', 'date': 'Sat, 23 Aug 2025 06:12:04 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.review_tool - ERROR - \\u274c Error finding product: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '19c9a48c3b1c6858bb65737a4e0e8c8d', 'date': 'Sat, 23 Aug 2025 06:12:04 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f527 Parsed JSON tool input: {'query': 'test'}\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f50d Searching products with query: 'test'\\nINFO     ecommerce_ai_advisor.search_tool:logger.py:79 \\U0001f3af Search metadata: None\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '69630241c30c5d69bb65737a4e0e8a54', 'date': 'Sat, 23 Aug 2025 06:12:03 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f527 Parsed JSON tool input: {'product_ids': ['test'], 'comparison_aspects': ['price']}\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f527 Raw input - product_ids type: <class 'list'>, value: ['test']\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f527 Raw input - comparison_aspects: ['price']\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f527 Raw input - kwargs: {}\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f527 Trying to parse JSON string: test\\nERROR    ecommerce_ai_advisor.compare_tool:logger.py:90 \\U0001f527 JSON decode error: Expecting value: line 1 column 1 (char 0)\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f50d Comparing products: ['test']\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f50d Comparison aspects: ['price']\\nINFO     ecommerce_ai_advisor.compare_tool:logger.py:79 \\U0001f50d Product count: 1\\nINFO     ecommerce_ai_advisor.recommend_tool:logger.py:79 \\U0001f527 Parsed JSON tool input: {'user_needs': 'test', 'budget': 1000000}\\nINFO     ecommerce_ai_advisor.recommend_tool:logger.py:79 \\U0001f3af Generating recommendations for: 'test'\\nINFO     ecommerce_ai_advisor.recommend_tool:logger.py:79 \\U0001f4ca Recommendation metadata: None\\nINFO     ecommerce_ai_advisor.recommend_tool:logger.py:79 \\U0001f50d Search filters applied: {'rating': {'$gte': 3.5}}\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'b52fb489a36ee9aabb65737a4e0e8df3', 'date': 'Sat, 23 Aug 2025 06:12:03 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\nERROR    ecommerce_ai_advisor.recommend_tool:logger.py:90 \\u274c Recommend tool error: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': 'b52fb489a36ee9aabb65737a4e0e8df3', 'date': 'Sat, 23 Aug 2025 06:12:03 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\nINFO     ecommerce_ai_advisor.review_tool:logger.py:79 \\U0001f4dd Getting reviews for product: '{\"product_id\": \"test\"}'\\nERROR    ecommerce_ai_advisor.pinecone_service:logger.py:90 \\u274c Search failed: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '19c9a48c3b1c6858bb65737a4e0e8c8d', 'date': 'Sat, 23 Aug 2025 06:12:04 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\\n\\nERROR    ecommerce_ai_advisor.review_tool:logger.py:90 \\u274c Error finding product: (401)\\nReason: Unauthorized\\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2025-04', 'x-cloud-trace-context': '19c9a48c3b1c6858bb65737a4e0e8c8d', 'date': 'Sat, 23 Aug 2025 06:12:04 GMT', 'content-type': 'text/html', 'server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\\nHTTP response body: Invalid API Key\n__________ TestToolIntegration.test_tool_manager_contains_all_tools ___________\n\nself = <tests.unit.test_tools.TestToolIntegration object at 0x000002926566FBB0>\n\n    def test_tool_manager_contains_all_tools(self):\n        \"\"\"Test that ToolManager contains all expected tools\"\"\"\n        manager = ToolManager()\n    \n        # Get all tools from manager\n        manager_tools = manager.get_all_tools()\n        manager_tool_names = [tool.name for tool in manager_tools]\n    \n        # Expected tool names\n        expected_names = [\n            \"search_products\",\n            \"compare_products\",\n            \"recommend_products\",\n            \"get_reviews\"\n        ]\n    \n        # Verify all expected tools are present\n        for expected_name in expected_names:\n>           assert expected_name in manager_tool_names\nE           AssertionError: assert 'get_reviews' in ['search_products', 'compare_products', 'recommend_products', 'get_product_reviews']\n\ntests\\unit\\test_tools.py:475: AssertionError\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:08 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.tool_manager - INFO - \\u2705 ToolManager initialized with 4 tools\n------------------------------ Captured log call ------------------------------\nINFO     ecommerce_ai_advisor.tool_manager:logger.py:79 \\u2705 ToolManager initialized with 4 tools\n______________________ TestPromptHelper.test_clean_text _______________________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x00000292657D1D10>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x00000292657D25D0>\n\n    def test_clean_text(self, prompt_helper):\n        \"\"\"Test text cleaning functionality\"\"\"\n        # Test cases for text cleaning\n        test_cases = [\n            (\"  Hello World  \", \"Hello World\"),\n            (\"Text\\nwith\\nnewlines\", \"Text with newlines\"),\n            (\"Text\\twith\\ttabs\", \"Text with tabs\"),\n            (\"Multiple   spaces\", \"Multiple spaces\"),\n            (\"\", \"\"),\n            (\"   \", \"\")\n        ]\n    \n        for input_text, expected_output in test_cases:\n>           result = prompt_helper.clean_text(input_text)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'PromptHelper' object has no attribute 'clean_text'\n\ntests\\unit\\test_utils.py:169: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n_____________________ TestPromptHelper.test_truncate_text _____________________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x000002926581C050>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x0000029265A0A3F0>\n\n    def test_truncate_text(self, prompt_helper):\n        \"\"\"Test text truncation\"\"\"\n        # Test normal truncation\n        long_text = \"This is a very long text that should be truncated\"\n>       result = prompt_helper.truncate_text(long_text, max_length=20)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: 'PromptHelper' object has no attribute 'truncate_text'\n\ntests\\unit\\test_utils.py:176: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n___________________ TestPromptHelper.test_extract_keywords ____________________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x000002926581C180>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x0000029265A0A780>\n\n    def test_extract_keywords(self, prompt_helper):\n        \"\"\"Test keyword extraction\"\"\"\n        text = \"T\\xecm laptop Dell XPS 13 v\\u1edbi gi\\xe1 d\\u01b0\\u1edbi 20 tri\\u1ec7u\"\n>       keywords = prompt_helper.extract_keywords(text)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: 'PromptHelper' object has no attribute 'extract_keywords'\n\ntests\\unit\\test_utils.py:192: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n_____________________ TestPromptHelper.test_format_price ______________________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x00000292657AE450>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x0000029266FD8770>\n\n    def test_format_price(self, prompt_helper):\n        \"\"\"Test price formatting\"\"\"\n        # Test various price formats\n        test_cases = [\n            (25000000, \"25,000,000 VND\"),\n            (1500000, \"1,500,000 VND\"),\n            (0, \"0 VND\"),\n            (999, \"999 VND\")\n        ]\n    \n        for price, expected_format in test_cases:\n>           result = prompt_helper.format_price(price)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'PromptHelper' object has no attribute 'format_price'\n\ntests\\unit\\test_utils.py:211: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n__________________ TestPromptHelper.test_format_product_list __________________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x00000292657429C0>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x0000029266FD9480>\nsample_products = [{'availability': 'in_stock', 'brand': 'Dell', 'category': 'laptop', 'currency': 'VND', ...}, {'availability': 'in_stock', 'brand': 'Apple', 'category': 'smartphone', 'currency': 'VND', ...}]\n\n    def test_format_product_list(self, prompt_helper, sample_products):\n        \"\"\"Test product list formatting\"\"\"\n>       formatted = prompt_helper.format_product_list(sample_products)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: 'PromptHelper' object has no attribute 'format_product_list'. Did you mean: 'format_products_list'?\n\ntests\\unit\\test_utils.py:216: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n________________ TestPromptHelper.test_format_comparison_table ________________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x0000029265742AD0>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x0000029266FD9BA0>\n\n    def test_format_comparison_table(self, prompt_helper):\n        \"\"\"Test comparison table formatting\"\"\"\n        comparison_data = {\n            \"Dell XPS 13\": {\"price\": 25000000, \"rating\": 4.5},\n            \"MacBook Air\": {\"price\": 30000000, \"rating\": 4.6}\n        }\n    \n        formatted = prompt_helper.format_comparison_table(comparison_data)\n    \n        # Verify formatting\n        assert isinstance(formatted, str)\n>       assert \"Dell XPS 13\" in formatted\nE       AssertionError: assert 'Dell XPS 13' in 'Kh\\xf4ng th\\u1ec3 t\\u1ea1o b\\u1ea3ng so s\\xe1nh'\n\ntests\\unit\\test_utils.py:236: AssertionError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n---------------------------- Captured stderr call -----------------------------\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - ERROR - Error formatting comparison table: 0\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - ERROR - Error formatting comparison table: 0\n------------------------------ Captured log call ------------------------------\nERROR    ecommerce_ai_advisor.prompt_helper:logger.py:90 Error formatting comparison table: 0\n________________ TestPromptHelper.test_extract_price_from_text ________________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x0000029265722950>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x0000029266FD8C30>\n\n    def test_extract_price_from_text(self, prompt_helper):\n        \"\"\"Test price extraction from text\"\"\"\n        # Test cases for price extraction\n        test_cases = [\n            (\"laptop d\\u01b0\\u1edbi 20 tri\\u1ec7u\", 20000000),\n            (\"\\u0111i\\u1ec7n tho\\u1ea1i t\\u1eeb 15 tri\\u1ec7u \\u0111\\u1ebfn 25 tri\\u1ec7u\", 15000000),\n            (\"gi\\xe1 kho\\u1ea3ng 30 tri\\u1ec7u\", 30000000),\n            (\"không có giá\", None),\n            (\"\", None)\n        ]\n    \n        for text, expected_price in test_cases:\n>           result = prompt_helper.extract_price_from_text(text)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'PromptHelper' object has no attribute 'extract_price_from_text'\n\ntests\\unit\\test_utils.py:253: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n________________ TestPromptHelper.test_format_vietnamese_text _________________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x0000029265722B50>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x0000029266FD9810>\n\n    def test_format_vietnamese_text(self, prompt_helper):\n        \"\"\"Test Vietnamese text formatting\"\"\"\n        # Test Vietnamese text handling\n        vietnamese_text = \"T\\xecm \\u0111i\\u1ec7n tho\\u1ea1i c\\xf3 m\\xe0n h\\xecnh \\u0111\\u1eb9p\"\n>       formatted = prompt_helper.format_vietnamese_text(vietnamese_text)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: 'PromptHelper' object has no attribute 'format_vietnamese_text'\n\ntests\\unit\\test_utils.py:263: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:08 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n__________________ TestPromptHelper.test_safe_format_prompt ___________________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x0000029264E8BF20>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x0000029266FD8D60>\n\n    def test_safe_format_prompt(self, prompt_helper):\n        \"\"\"Test safe prompt formatting\"\"\"\n>       with patch('src.utils.prompt_helper.prompt_manager') as mock_prompt_manager:\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ntests\\unit\\test_utils.py:272: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <unittest.mock._patch object at 0x00000292671E1550>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'src.utils.prompt_helper' from 'C:\\\\Users\\\\MinhTC\\\\Desktop\\\\Hackaton\\\\evlevate-dn-03\\\\Workshop_final\\\\src\\\\utils\\\\prompt_helper.py'> does not have the attribute 'prompt_manager'\n\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1467: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:09 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:09 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n______________ TestPromptHelper.test_safe_format_prompt_failure _______________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x000002926582C050>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x0000029266FD8E90>\n\n    def test_safe_format_prompt_failure(self, prompt_helper):\n        \"\"\"Test safe prompt formatting with failure\"\"\"\n>       with patch('src.utils.prompt_helper.prompt_manager') as mock_prompt_manager:\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ntests\\unit\\test_utils.py:287: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <unittest.mock._patch object at 0x00000292671E1E10>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'src.utils.prompt_helper' from 'C:\\\\Users\\\\MinhTC\\\\Desktop\\\\Hackaton\\\\evlevate-dn-03\\\\Workshop_final\\\\src\\\\utils\\\\prompt_helper.py'> does not have the attribute 'prompt_manager'\n\n..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py:1467: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:09 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:09 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n______________ TestPromptHelper.test_format_conversation_history ______________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x00000292657FB930>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x0000029266FD9220>\nsample_conversation_history = [{'content': 'Xin ch\\xe0o', 'role': 'user'}, {'content': 'Xin ch\\xe0o! T\\xf4i c\\xf3 th\\u1ec3 gi\\xfap g\\xec cho b\\u1ea1n?', 'role': 'assistant'}, {... 'T\\xecm laptop Dell', 'role': 'user'}, {'content': 'T\\xf4i \\u0111\\xe3 t\\xecm th\\u1ea5y m\\u1ed9t s\\u1ed1 laptop Dell ph\\xf9 h\\u1ee3p...', 'role': 'assistant'}]\n\n    def test_format_conversation_history(self, prompt_helper, sample_conversation_history):\n        \"\"\"Test conversation history formatting\"\"\"\n>       formatted = prompt_helper.format_conversation_history(sample_conversation_history)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: 'PromptHelper' object has no attribute 'format_conversation_history'\n\ntests\\unit\\test_utils.py:298: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:09 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:09 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n__________________ TestPromptHelper.test_format_tool_results __________________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x00000292657FBBD0>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x000002926581CE90>\n\n    def test_format_tool_results(self, prompt_helper):\n        \"\"\"Test tool results formatting\"\"\"\n        tool_results = {\n            \"search_results\": {\"products\": [{\"name\": \"Dell XPS 13\"}]},\n            \"comparison_results\": {\"comparison_table\": {\"Dell XPS 13\": {\"price\": 25000000}}}\n        }\n    \n>       formatted = prompt_helper.format_tool_results(tool_results)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE       AttributeError: 'PromptHelper' object has no attribute 'format_tool_results'\n\ntests\\unit\\test_utils.py:313: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:09 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:09 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n_______________ TestPromptHelper.test_validate_vietnamese_input _______________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x00000292657E8A10>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x0000029265A0AEA0>\n\n    def test_validate_vietnamese_input(self, prompt_helper):\n        \"\"\"Test Vietnamese input validation\"\"\"\n        # Test cases for Vietnamese validation\n        test_cases = [\n            (\"Tìm laptop Dell\", True),\n            (\"\\u0111i\\u1ec7n tho\\u1ea1i Samsung\", True),\n            (\"Hello World\", True),  # English should also be valid\n            (\"\", False),\n            (\"   \", False),\n            (\"123456\", True),  # Numbers should be valid\n            (\"!@#$%\", False)  # Only special characters should be invalid\n        ]\n    \n        for text, expected_valid in test_cases:\n>           result = prompt_helper.validate_vietnamese_input(text)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'PromptHelper' object has no attribute 'validate_vietnamese_input'\n\ntests\\unit\\test_utils.py:355: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:09 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:09 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n____________________ TestPromptHelper.test_normalize_query ____________________\n\nself = <tests.unit.test_utils.TestPromptHelper object at 0x00000292657CC940>\nprompt_helper = <src.utils.prompt_helper.PromptHelper object at 0x0000029265A09BA0>\n\n    def test_normalize_query(self, prompt_helper):\n        \"\"\"Test query normalization\"\"\"\n        # Test query normalization\n        test_cases = [\n            (\"  TÌM LAPTOP DELL  \", \"tìm laptop dell\"),\n            (\"\\u0110i\\u1ec7n Tho\\u1ea1i Samsung\", \"\\u0111i\\u1ec7n tho\\u1ea1i samsung\"),\n            (\"\", \"\"),\n            (\"Multiple   Spaces\", \"multiple spaces\")\n        ]\n    \n        for input_query, expected_output in test_cases:\n>           result = prompt_helper.normalize_query(input_query)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'PromptHelper' object has no attribute 'normalize_query'\n\ntests\\unit\\test_utils.py:369: AttributeError\n---------------------------- Captured stderr setup ----------------------------\n2025-08-23 13:12:09 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\\n2025-08-23 13:12:09 - ecommerce_ai_advisor.prompt_helper - INFO - \\u2705 Prompt helper initialized\n----------------------------- Captured log setup ------------------------------\nINFO     ecommerce_ai_advisor.prompt_helper:logger.py:79 \\u2705 Prompt helper initialized\n============================== warnings summary ===============================\ntests/unit/test_tools.py::TestToolManager::test_describe_tools\ntests/unit/test_tools.py::TestToolManager::test_describe_tools\ntests/unit/test_tools.py::TestToolManager::test_describe_tools\ntests/unit/test_tools.py::TestToolManager::test_describe_tools\n  C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\\src\\tools\\tool_manager.py:52: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n    \"schema\": tool.args_schema.schema() if tool.args_schema else None\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n- generated xml file: C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\\tests\\reports\\junit.xml -\n=============================== tests coverage ================================\n_______________ coverage: platform win32, python 3.13.6-final-0 _______________\n\nName                               Stmts   Miss  Cover   Missing\n----------------------------------------------------------------\nsrc\\__init__.py                       12      0   100%\nsrc\\agents\\__init__.py                 0      0   100%\nsrc\\agents\\langgraph_agent.py        704    250    64%   145-146, 157-159, 184-192, 196-210, 219-231, 235-292, 296-297, 307-308, 319-320, 352-354, 369-370, 382, 409, 414-418, 442, 449, 462-464, 485-487, 520-523, 533-534, 541-542, 585-588, 592, 594, 609-620, 627-629, 646, 670-673, 683-684, 691-692, 719, 725-728, 742-743, 746-749, 775-778, 788-789, 796-797, 804-806, 865, 870-872, 883, 911-914, 923, 945-948, 957, 974, 982, 988-992, 1008, 1040-1043, 1051-1055, 1080, 1085, 1089-1092, 1106, 1233-1235, 1261, 1267-1268, 1272-1273, 1275-1276, 1281-1282, 1294-1305, 1309, 1311, 1318-1320, 1344-1346, 1359, 1363, 1367-1375, 1381-1382\nsrc\\config\\__init__.py                 2      0   100%\nsrc\\config\\config.py                  45      7    84%   52, 84, 89, 94, 101-103\nsrc\\prompts\\__init__.py                2      0   100%\nsrc\\prompts\\prompt_manager.py        158     39    75%   131-133, 137-153, 157-167, 191-193, 234-252\nsrc\\services\\__init__.py               3      0   100%\nsrc\\services\\llm_service.py           44     12    73%   41-46, 56-58, 68-76, 92-94\nsrc\\services\\pinecone_service.py     162     71    56%   45-50, 60-62, 66-95, 101, 117, 135-170, 223-226, 229-232, 236, 250-288, 294\nsrc\\tools\\__init__.py                  5      0   100%\nsrc\\tools\\compare_tool.py            184     86    53%   38-58, 94-95, 103-116, 136-161, 184-185, 217-220, 224, 226, 235-241, 246, 252-267, 271, 291, 327, 333, 337-342, 373-375, 393, 398-400, 415\nsrc\\tools\\generation_tool.py         106     29    73%   112-113, 120, 128, 154-169, 218-220, 228-230, 237, 241, 247-249, 256, 258, 263-271, 287\nsrc\\tools\\recommend_tool.py          179     69    61%   71-72, 80-89, 103-117, 128-139, 146-169, 178-189, 196, 200-202, 218, 259, 263-266, 270, 274-279, 292, 294, 398, 400, 410\nsrc\\tools\\review_tool.py             114     52    54%   84, 107, 135-137, 179-181, 185-187, 194-208, 217-269, 281\nsrc\\tools\\search_tool.py              87     16    82%   74-83, 141, 148, 162, 177, 207, 229-231, 244\nsrc\\tools\\tool_manager.py             25      0   100%\nsrc\\ui\\__init__.py                     2      0   100%\nsrc\\ui\\app.py                        139    114    18%   31-34, 39, 60-66, 73-94, 103-110, 143-163, 168, 182-203, 213-230, 235-254, 260-276, 282-342, 346\nsrc\\utils\\__init__.py                  3      0   100%\nsrc\\utils\\logger.py                   62      2    97%   61-62\nsrc\\utils\\prompt_helper.py           247    189    23%   23-38, 43-57, 62-71, 76-98, 107-130, 137, 142-166, 174-235, 249-262, 266-284, 288, 300-317, 321-374, 398-412\n----------------------------------------------------------------\nTOTAL                               2285    936    59%\nCoverage HTML written to dir tests/reports/coverage_html\nCoverage XML written to file tests/reports/coverage.xml\n=========================== short test summary info ===========================\nFAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflows::test_complete_search_workflow\nFAILED tests/integration/test_end_to_end.py::TestServiceIntegration::test_tool_service_integration\nFAILED tests/integration/test_end_to_end.py::TestAgentToolIntegration::test_tool_error_handling_in_agent\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_create_graph_structure\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_classify_intent_with_llm_success\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_classify_intent_with_rules\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_get_reviews_node\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_route_after_intent_analysis\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_route_to_response_or_error\nFAILED tests/unit/test_agents.py::TestProductAdvisorLangGraphAgent::test_extract_search_params\nFAILED tests/unit/test_agents.py::TestAgentManager::test_get_langgraph_agent_manager\nFAILED tests/unit/test_config.py::TestConfig::test_config_validation_failure\nFAILED tests/unit/test_config.py::TestConfig::test_get_openai_config - Assert...\nFAILED tests/unit/test_config.py::TestConfig::test_empty_environment_variables\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_llm_service_initialization\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_custom_endpoint_initialization\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_get_langchain_llm_azure\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_get_langchain_llm_custom\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_classify_intent_success\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_classify_intent_failure\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_generate_response_success\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_generate_response_failure\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_extract_parameters_success\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_extract_parameters_invalid_json\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_health_check_success\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_health_check_failure\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_format_prompt_for_intent\nFAILED tests/unit/test_llm_service.py::TestLLMService::test_format_prompt_for_generation\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_create_embedding_failure\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_upsert_products_success\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_upsert_products_failure\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_search_products_failure\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_get_index_stats_failure\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_health_check_success\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_health_check_failure\nFAILED tests/unit/test_pinecone_service.py::TestPineconeService::test_prepare_product_for_indexing\nFAILED tests/unit/test_prompts.py::TestPromptType::test_prompt_type_enum_values\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_prompt_manager_initialization\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_intent_classification\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_search_system\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_compare_system\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_recommend_system\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_review_system\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_base_system\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_search\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_compare\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_recommend\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_review\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_generation_direct\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_error_handling\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_get_prompt_greeting_response\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_prompt_templates_have_required_placeholders\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_prompt_templates_are_vietnamese_friendly\nFAILED tests/unit/test_prompts.py::TestPromptManager::test_all_prompt_types_have_prompts\nFAILED tests/unit/test_tools.py::TestSearchTool::test_search_tool_initialization\nFAILED tests/unit/test_tools.py::TestCompareTool::test_compare_tool_initialization\nFAILED tests/unit/test_tools.py::TestRecommendTool::test_recommend_tool_initialization\nFAILED tests/unit/test_tools.py::TestReviewTool::test_review_tool_initialization\nFAILED tests/unit/test_tools.py::TestGenerationTool::test_generation_tool_initialization\nFAILED tests/unit/test_tools.py::TestGenerationTool::test_generation_tool_success\nFAILED tests/unit/test_tools.py::TestGenerationTool::test_generation_tool_llm_failure\nFAILED tests/unit/test_tools.py::TestToolIntegration::test_tools_return_json_strings\nFAILED tests/unit/test_tools.py::TestToolIntegration::test_tool_manager_contains_all_tools\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_clean_text - Attribut...\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_truncate_text - Attri...\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_extract_keywords - At...\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_format_price - Attrib...\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_format_product_list\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_format_comparison_table\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_extract_price_from_text\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_format_vietnamese_text\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_safe_format_prompt - ...\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_safe_format_prompt_failure\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_format_conversation_history\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_format_tool_results\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_validate_vietnamese_input\nFAILED tests/unit/test_utils.py::TestPromptHelper::test_normalize_query - Att...\n================= 77 failed, 87 passed, 4 warnings in 22.24s ==================\n",
      "stderr": "",
      "returncode": 1
    },
    "smoke": {
      "status": "FAILED",
      "duration": 4.613690376281738,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.13.6, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\MinhTC\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\ncachedir: .pytest_cache\nrootdir: C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, langsmith-0.4.13, asyncio-1.1.0, cov-6.2.1, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 164 items / 164 deselected / 0 selected\n\n=========================== 164 deselected in 2.90s ===========================\n",
      "stderr": "",
      "returncode": 5
    },
    "vietnamese": {
      "status": "FAILED",
      "duration": 4.958965063095093,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.13.6, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\MinhTC\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\ncachedir: .pytest_cache\nrootdir: C:\\Users\\MinhTC\\Desktop\\Hackaton\\evlevate-dn-03\\Workshop_final\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, langsmith-0.4.13, asyncio-1.1.0, cov-6.2.1, mock-3.14.1\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 164 items / 164 deselected / 0 selected\n\n=========================== 164 deselected in 3.04s ===========================\n",
      "stderr": "",
      "returncode": 5
    }
  }
}