# ğŸ¤– LangGraph Agent Documentation

## TÃ i liá»‡u chi tiáº¿t vá» E-commerce AI Product Advisor Agent

---

## ğŸ“‹ Má»¥c lá»¥c

1. [Tá»•ng quan](#tá»•ng-quan)
2. [Kiáº¿n trÃºc há»‡ thá»‘ng](#kiáº¿n-trÃºc-há»‡-thá»‘ng)
3. [CÃ¡c thÃ nh pháº§n chÃ­nh](#cÃ¡c-thÃ nh-pháº§n-chÃ­nh)
4. [Luá»“ng xá»­ lÃ½](#luá»“ng-xá»­-lÃ½)
5. [Quáº£n lÃ½ bá»™ nhá»›](#quáº£n-lÃ½-bá»™-nhá»›)
6. [TÃ­nh nÄƒng Ä‘áº·c biá»‡t](#tÃ­nh-nÄƒng-Ä‘áº·c-biá»‡t)
7. [API vÃ  cÃ¡ch sá»­ dá»¥ng](#api-vÃ -cÃ¡ch-sá»­-dá»¥ng)
8. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Tá»•ng quan

**LangGraph Agent** lÃ  má»™t AI Agent thÃ´ng minh Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng framework LangGraph Ä‘á»ƒ tÆ° váº¥n sáº£n pháº©m Ä‘iá»‡n tá»­. Agent cÃ³ kháº£ nÄƒng:

- ğŸ” **TÃ¬m kiáº¿m sáº£n pháº©m** thÃ´ng minh theo yÃªu cáº§u ngÆ°á»i dÃ¹ng
- âš–ï¸ **So sÃ¡nh sáº£n pháº©m** chi tiáº¿t vá»›i nhiá»u tiÃªu chÃ­
- ğŸ’¡ **Gá»£i Ã½ sáº£n pháº©m** phÃ¹ há»£p dá»±a trÃªn nhu cáº§u
- ğŸ“ **Xem Ä‘Ã¡nh giÃ¡** tá»« ngÆ°á»i dÃ¹ng thá»±c táº¿
- ğŸ§  **Nhá»› ngá»¯ cáº£nh** giá»¯a cÃ¡c láº§n há»™i thoáº¡i
- ğŸ”„ **Hiá»ƒu tham chiáº¿u** tá»« cuá»™c trÃ² chuyá»‡n trÆ°á»›c

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

### SÆ¡ Ä‘á»“ luá»“ng xá»­ lÃ½

```mermaid
graph TD
    A[User Input] --> B[Analyze Intent]
    B --> C{Intent Type}
    C -->|greeting| D[Handle Greeting]
    C -->|search| E[Search Products]
    C -->|compare| F[Compare Products]
    C -->|recommend| G[Recommend Products]
    C -->|review| H[Get Reviews]
    C -->|direct| I[Generate Response]
    C -->|error| J[Handle Error]
    
    E --> I
    F --> I
    G --> I
    H --> I
    
    I --> K[Final Response]
    D --> K
    J --> K
    
    style A fill:#e1f5fe
    style K fill:#c8e6c9
    style C fill:#fff3e0
```

### Kiáº¿n trÃºc thÃ nh pháº§n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            LangGraph Agent              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Agent State â”‚  â”‚  Memory Saver   â”‚   â”‚
â”‚  â”‚             â”‚  â”‚  (LangGraph)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Intent      â”‚  â”‚ Context         â”‚   â”‚
â”‚  â”‚ Analysis    â”‚  â”‚ Detection       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Tool        â”‚  â”‚ Response        â”‚   â”‚
â”‚  â”‚ Execution   â”‚  â”‚ Generation      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© CÃ¡c thÃ nh pháº§n chÃ­nh

### 1. AgentState (Tráº¡ng thÃ¡i Agent)

```python
class AgentState(TypedDict):
    """Tráº¡ng thÃ¡i Ä‘áº§y Ä‘á»§ cá»§a Agent trong má»™t phiÃªn há»™i thoáº¡i"""
    
    # Core fields
    messages: Annotated[List[BaseMessage], add_messages]
    user_input: str
    session_id: Optional[str]
    current_step: str
    intent: str
    
    # Tool results
    search_results: Optional[Dict[str, Any]]
    comparison_results: Optional[Dict[str, Any]]
    recommendation_results: Optional[Dict[str, Any]]
    review_results: Optional[Dict[str, Any]]
    
    # Memory & context
    conversation_history: List[Dict[str, str]]
    previous_products: Optional[List[str]]
    context_references: Optional[Dict[str, Any]]
    
    # Metadata
    tools_used: List[str]
    reasoning_steps: List[Dict[str, Any]]
    final_response: Optional[str]
    error_count: int
```

**Chá»©c nÄƒng**: LÆ°u trá»¯ toÃ n bá»™ tráº¡ng thÃ¡i cá»§a cuá»™c há»™i thoáº¡i, bao gá»“m káº¿t quáº£ tá»« cÃ¡c tools vÃ  ngá»¯ cáº£nh tá»« cÃ¡c láº§n chat trÆ°á»›c.

### 2. LangGraph Workflow

```python
def _create_graph(self) -> StateGraph:
    workflow = StateGraph(AgentState)
    
    # CÃ¡c node xá»­ lÃ½
    workflow.add_node("analyze_intent", self._analyze_intent)
    workflow.add_node("handle_greeting", self._handle_greeting)
    workflow.add_node("search_products", self._search_products)
    workflow.add_node("compare_products", self._compare_products)
    workflow.add_node("recommend_products", self._recommend_products)
    workflow.add_node("get_reviews", self._get_reviews)
    workflow.add_node("generate_response", self._generate_response)
    workflow.add_node("handle_error", self._handle_error)
    
    # Äá»‹nh tuyáº¿n cÃ³ Ä‘iá»u kiá»‡n
    workflow.add_conditional_edges(
        "analyze_intent",
        self._route_intent,
        {
            "greeting": "handle_greeting",
            "search": "search_products",
            "compare": "compare_products",
            "recommend": "recommend_products",
            "review": "get_reviews",
            "direct": "generate_response",
            "error": "handle_error"
        }
    )
    
    return workflow.compile(checkpointer=self.memory_saver)
```

---

## ğŸ”„ Luá»“ng xá»­ lÃ½

### BÆ°á»›c 1: PhÃ¢n tÃ­ch Ã½ Ä‘á»‹nh (Intent Analysis)

#### A. Nháº­n biáº¿t ngá»¯ cáº£nh (Context Detection)

```python
def _detect_context_references(self, user_input: str, state: AgentState):
    """PhÃ¡t hiá»‡n tham chiáº¿u Ä‘áº¿n cuá»™c há»™i thoáº¡i trÆ°á»›c"""
    
    # Patterns so sÃ¡nh
    comparison_patterns = [
        "so sÃ¡nh", "compare", "khÃ¡c nhau", "vs", "versus",
        "2 sáº£n pháº©m", "hai sáº£n pháº©m", "cáº£ hai", "chÃºng"
    ]
    
    # Patterns review
    review_patterns = [
        "review", "Ä‘Ã¡nh giÃ¡", "nháº­n xÃ©t", "Ã½ kiáº¿n",
        "cÃ³ tá»‘t khÃ´ng", "cÃ³ Ä‘Ã¡ng mua"
    ]
    
    # Kiá»ƒm tra vÃ  tráº£ vá» intent vá»›i context
    if any(pattern in user_input.lower() for pattern in comparison_patterns):
        if previous_products and len(previous_products) >= 2:
            return {
                "intent": "compare",
                "products": previous_products[:2],
                "reason": "Tham chiáº¿u so sÃ¡nh tá»« sáº£n pháº©m trÆ°á»›c"
            }
```

**VÃ­ dá»¥ thá»±c táº¿**:
- Láº§n 1: "TÃ¬m laptop Dell" â†’ Agent tÃ¬m vÃ  lÆ°u danh sÃ¡ch laptop Dell
- Láº§n 2: "So sÃ¡nh chÃºng" â†’ Agent hiá»ƒu "chÃºng" = laptop Dell vá»«a tÃ¬m

#### B. PhÃ¢n loáº¡i Ã½ Ä‘á»‹nh báº±ng LLM

```python
def _classify_intent_with_llm(self, user_input: str) -> str:
    """Sá»­ dá»¥ng LLM Ä‘á»ƒ phÃ¢n loáº¡i Ã½ Ä‘á»‹nh thÃ´ng minh"""
    
    prompt_template = prompt_manager.get_prompt(PromptType.INTENT_CLASSIFICATION)
    intent_prompt = prompt_template.format(user_input=user_input)
    
    response = self.llm.invoke([HumanMessage(content=intent_prompt)])
    intent = response.content.strip().lower()
    
    # Validate intent
    valid_intents = ["greeting", "search", "compare", "recommend", "review", "direct"]
    return intent if intent in valid_intents else None
```

#### C. Fallback Rules-based

```python
def _classify_intent_with_rules(self, user_input: str) -> str:
    """PhÆ°Æ¡ng phÃ¡p dá»± phÃ²ng dá»±a trÃªn rules"""
    
    if any(word in user_input for word in ["xin chÃ o", "hello", "hi"]):
        return "greeting"
    elif any(word in user_input for word in ["so sÃ¡nh", "compare", "vs"]):
        return "compare"
    elif any(word in user_input for word in ["gá»£i Ã½", "recommend", "tÆ° váº¥n"]):
        return "recommend"
    elif any(word in user_input for word in ["tÃ¬m", "search", "laptop", "smartphone"]):
        return "search"
    else:
        return "direct"
```

### BÆ°á»›c 2: Thá»±c thi cÃ´ng cá»¥ (Tool Execution)

#### A. TÃ¬m kiáº¿m sáº£n pháº©m (Search Products)

```python
def _search_products(self, state: AgentState) -> AgentState:
    # 1. TrÃ­ch xuáº¥t tham sá»‘ tÃ¬m kiáº¿m báº±ng LLM
    search_params = self._extract_search_params(state["user_input"])
    
    # 2. Gá»i search tool
    search_input = json.dumps(search_params, ensure_ascii=False)
    result = search_tool.run(search_input)
    
    # 3. LÆ°u káº¿t quáº£ vÃ  reasoning
    state["search_results"] = result
    state["reasoning_steps"].append({
        "action": "search_products",
        "thought": f"TÃ¬m kiáº¿m vá»›i params: {search_params}",
        "observation": result
    })
```

**TrÃ­ch xuáº¥t tham sá»‘ thÃ´ng minh**:

```python
def _extract_search_params(self, user_input: str) -> Dict[str, Any]:
    """LLM trÃ­ch xuáº¥t tham sá»‘ tá»« ngÃ´n ngá»¯ tá»± nhiÃªn"""
    
    # Input: "TÃ¬m laptop Dell dÆ°á»›i 20 triá»‡u cho sinh viÃªn"
    # Output: {
    #     "query": "laptop Dell sinh viÃªn",
    #     "metadata": {
    #         "category": "laptop",
    #         "brand": "dell", 
    #         "price_max": 20000000,
    #         "usage_purpose": "study",
    #         "max_results": 3
    #     }
    # }
```

#### B. So sÃ¡nh sáº£n pháº©m (Compare Products)

```python
def _compare_products(self, state: AgentState) -> AgentState:
    # 1. Kiá»ƒm tra context products trÆ°á»›c
    if state.get("context_products"):
        compare_params = {
            "product_names": state["context_products"],
            "comparison_aspects": ["giÃ¡", "hiá»‡u nÄƒng", "thiáº¿t káº¿"]
        }
    else:
        # 2. TrÃ­ch xuáº¥t tá»« user input
        compare_params = self._extract_compare_params(state["user_input"])
    
    # 3. Thá»±c thi comparison tool
    result = compare_tool.run(json.dumps(compare_params))
```

#### C. Gá»£i Ã½ sáº£n pháº©m (Recommend Products)

```python
def _recommend_products(self, state: AgentState) -> AgentState:
    # TrÃ­ch xuáº¥t nhu cáº§u vÃ  ngÃ¢n sÃ¡ch
    recommend_params = self._extract_recommend_params(state["user_input"])
    
    # Input: "Gá»£i Ã½ laptop gaming dÆ°á»›i 30 triá»‡u"
    # Extracted: {
    #     "user_needs": "laptop gaming",
    #     "metadata": {
    #         "category": "laptop",
    #         "budget_max": 30000000,
    #         "usage_purpose": "gaming",
    #         "priority_features": ["performance", "graphics"]
    #     }
    # }
```

### BÆ°á»›c 3: Táº¡o pháº£n há»“i (Response Generation)

```python
def _generate_response(self, state: AgentState) -> AgentState:
    # 1. Thu tháº­p context tá»« táº¥t cáº£ tools
    context_parts = []
    if state.get("search_results"):
        context_parts.append(f"Search: {state['search_results']}")
    if state.get("comparison_results"):
        context_parts.append(f"Compare: {state['comparison_results']}")
    
    # 2. Táº¡o input cho RAG tool
    rag_input = {
        "user_query": state["user_input"],
        "intent": state["intent"],
        "context": "\n".join(context_parts),
        "conversation_history": conversation_history_text,
        "tools_used": state["tools_used"]
    }
    
    # 3. Generate natural response
    result = generation_tool.run(rag_input)
    state["final_response"] = result["response"]
```

---

## ğŸ§  Quáº£n lÃ½ bá»™ nhá»›

### Native LangGraph Memory

```python
class ProductAdvisorLangGraphAgent:
    def __init__(self):
        # LangGraph native memory management
        self.memory_saver = MemorySaver()
        self.graph = self._create_graph()
    
    def _create_graph(self) -> StateGraph:
        workflow = StateGraph(AgentState)
        # ... add nodes ...
        
        # Compile vá»›i memory checkpointer
        return workflow.compile(checkpointer=self.memory_saver)
```

### LÆ°u trá»¯ ngá»¯ cáº£nh há»™i thoáº¡i

```python
def _get_conversation_history(self, session_id: str) -> Dict[str, Any]:
    """Láº¥y lá»‹ch sá»­ há»™i thoáº¡i tá»« LangGraph checkpoints"""
    
    thread_config = {"configurable": {"thread_id": session_id}}
    checkpoints = list(self.graph.get_state_history(config=thread_config))
    
    # TrÃ­ch xuáº¥t previous_products cho context reference
    previous_products = self._extract_product_names_from_results(latest_state)
    
    return {
        "conversation_history": conversation_list,
        "previous_products": previous_products,
        "context_references": context_refs
    }
```

### TrÃ­ch xuáº¥t sáº£n pháº©m cho ngá»¯ cáº£nh

```python
def _extract_product_names_from_results(self, state: Dict[str, Any]) -> List[str]:
    """TrÃ­ch xuáº¥t tÃªn sáº£n pháº©m tá»« káº¿t quáº£ cÃ¡c tool"""
    
    product_names = []
    
    # Tá»« search results
    if state.get("search_results"):
        search_data = json.loads(state["search_results"])
        if search_data.get("success") and "products" in search_data:
            for product in search_data["products"]:
                product_names.append(product.get("name", ""))
    
    # Tá»« recommendation results  
    if state.get("recommendation_results"):
        # Similar extraction logic...
    
    return list(set(product_names))  # Remove duplicates
```

---

## âœ¨ TÃ­nh nÄƒng Ä‘áº·c biá»‡t

### 1. ReAct-style Reasoning

Agent ghi láº¡i quÃ¡ trÃ¬nh suy nghÄ© nhÆ° con ngÆ°á»i:

```python
reasoning_step = {
    "step": 1,
    "action": "search_products",
    "thought": "NgÆ°á»i dÃ¹ng muá»‘n tÃ¬m laptop Dell dÆ°á»›i 20 triá»‡u cho sinh viÃªn",
    "action_input": {"category": "laptop", "brand": "dell", "price_max": 20000000},
    "observation": "TÃ¬m tháº¥y 3 sáº£n pháº©m: Dell Inspiron 15 3000, Dell Vostro 3400, Dell Latitude 3420"
}
```

### 2. Intelligent Parameter Extraction

Sá»­ dá»¥ng LLM vá»›i prompt templates Ä‘á»ƒ trÃ­ch xuáº¥t thÃ´ng tin:

```python
# Input: "TÃ¬m smartphone Samsung cÃ³ camera tá»‘t dÆ°á»›i 15 triá»‡u"
# LLM extracts:
{
    "category": "smartphone",
    "brand": "samsung", 
    "price_max": 15000000,
    "priority_features": ["camera"],
    "max_results": 3
}
```

### 3. Context-Aware Conversation

```python
# Conversation flow:
# User: "TÃ¬m laptop Dell"
# Agent: [TÃ¬m vÃ  hiá»ƒn thá»‹ 3 laptop Dell] + lÆ°u vÃ o previous_products

# User: "So sÃ¡nh chÃºng"  
# Agent: Nháº­n biáº¿t "chÃºng" = 3 laptop Dell â†’ Tá»± Ä‘á»™ng so sÃ¡nh

# User: "CÃ³ gÃ¬ tá»‘t hÆ¡n?"
# Agent: Hiá»ƒu ngá»¯ cáº£nh â†’ Gá»£i Ã½ laptop khÃ¡c tÆ°Æ¡ng tá»±
```

### 4. Multi-layered Error Handling

```python
# Layer 1: LLM extraction
try:
    params = self._extract_search_params_with_llm(user_input)
except:
    # Layer 2: Rule-based fallback
    params = self._fallback_search_params(user_input)

# Layer 3: Error node
workflow.add_node("handle_error", self._handle_error)
```

### 5. Adaptive Response Generation

```python
def _get_error_response(self, error: str) -> str:
    """Smart error responses based on error type"""
    
    if "setup_required" in error:
        return """âŒ **CÆ¡ sá»Ÿ dá»¯ liá»‡u chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p**
        
ğŸ”§ **CÃ¡ch kháº¯c phá»¥c:**
1. Cháº¡y: `python scripts/insert_sample_data.py`
2. Táº¡o Pinecone index 'ecommerce-products'
        
ğŸ’¡ Sau Ä‘Ã³ thá»­ láº¡i cÃ¢u há»i!"""
    else:
        return f"Xin lá»—i, cÃ³ lá»—i: {error}. Báº¡n thá»­ láº¡i Ä‘Æ°á»£c khÃ´ng?"
```

---

## ğŸ”§ API vÃ  cÃ¡ch sá»­ dá»¥ng

### Khá»Ÿi táº¡o Agent

```python
from src.agents.langgraph_agent import get_langgraph_agent_manager

# Get agent manager
agent_manager = get_langgraph_agent_manager()
agent = agent_manager.get_agent()
```

### Chat vá»›i Agent

```python
# Chat Ä‘Æ¡n giáº£n
response = agent.chat("TÃ¬m laptop Dell dÆ°á»›i 20 triá»‡u")

# Chat vá»›i session management
session_id = "user123"
response = agent.chat("TÃ¬m laptop Dell", session_id=session_id)

# Chat tiáº¿p theo vá»›i context
response2 = agent.chat("So sÃ¡nh chÃºng", session_id=session_id)
```

### Response Format

```python
{
    "response": "TÃ´i tÃ¬m tháº¥y 3 laptop Dell phÃ¹ há»£p...",
    "tools_used": ["search_products", "answer_with_context"],
    "reasoning_steps": [
        {
            "step": 1,
            "action": "search_products", 
            "thought": "TÃ¬m laptop Dell vá»›i giÃ¡ dÆ°á»›i 20 triá»‡u",
            "observation": "TÃ¬m tháº¥y 3 sáº£n pháº©m phÃ¹ há»£p"
        }
    ],
    "session_id": "user123",
    "success": True,
    "intent": "search",
    "context_info": {
        "has_previous_context": False,
        "previous_products": [],
        "context_references_used": False
    }
}
```

### Quáº£n lÃ½ Session

```python
# Clear specific session
agent_manager.clear_session("user123")

# Clear all sessions  
agent_manager.clear_all_sessions()

# Get active sessions
sessions = agent_manager.get_active_sessions()
```

---

## ğŸ” Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

#### 1. Database Not Setup

```
âŒ Lá»—i: setup_required hoáº·c NOT_FOUND
ğŸ”§ Giáº£i phÃ¡p: 
   python scripts/insert_sample_data.py
   Kiá»ƒm tra Pinecone index Ä‘Ã£ táº¡o chÆ°a
```

#### 2. LLM Intent Classification Failed

```python
# Agent tá»± Ä‘á»™ng fallback sang rule-based
def _classify_intent_with_rules(self, user_input: str) -> str:
    # Backup classification logic
```

#### 3. Tool Execution Failed

```python
# Error handling trong má»—i tool node
except Exception as e:
    state["search_results"] = {"error": str(e), "success": False}
    state["error_count"] += 1
```

#### 4. Memory Issues

```python
# Reset memory náº¿u cáº§n
agent.clear_memory(session_id)

# Hoáº·c táº¡o agent má»›i
agent_manager = LangGraphAgentManager()
```

### Debug Tips

```python
# 1. Kiá»ƒm tra reasoning steps
print(response["reasoning_steps"])

# 2. Xem tools Ä‘Æ°á»£c sá»­ dá»¥ng
print(response["tools_used"])

# 3. Kiá»ƒm tra context info
print(response["context_info"])

# 4. Debug state transitions
# ThÃªm logging trong cÃ¡c node methods
```

---

## ğŸ“Š Performance & Metrics

### Thá»‘ng kÃª sá»­ dá»¥ng

```python
# Tracking trong AgentState
{
    "tools_used": ["search_products", "answer_with_context"],
    "iteration_count": 1,
    "error_count": 0,
    "reasoning_steps": [...]  # Detailed execution trace
}
```

### Memory Usage

```python
# LangGraph tá»± Ä‘á»™ng quáº£n lÃ½ memory
# Conversation history Ä‘Æ°á»£c giá»›i háº¡n (last 5 conversations)
if len(state["conversation_history"]) > 5:
    state["conversation_history"] = state["conversation_history"][-5:]
```

---

## ğŸš€ Má»Ÿ rá»™ng vÃ  tÃ¹y chá»‰nh

### ThÃªm Intent má»›i

```python
# 1. ThÃªm vÃ o valid_intents
valid_intents = ["greeting", "search", "compare", "recommend", "review", "direct", "new_intent"]

# 2. Táº¡o node xá»­ lÃ½
workflow.add_node("handle_new_intent", self._handle_new_intent)

# 3. ThÃªm routing
workflow.add_conditional_edges(
    "analyze_intent",
    self._route_intent,
    {
        # ... existing routes ...
        "new_intent": "handle_new_intent"
    }
)
```

### ThÃªm Tool má»›i

```python
# 1. Táº¡o tool trong tool_manager
def _handle_new_functionality(self, state: AgentState) -> AgentState:
    new_tool = self.tool_manager.get_tool("new_tool")
    result = new_tool.run(input_data)
    state["new_results"] = result
    return state
```

### Custom Prompt Templates

```python
# ThÃªm prompt má»›i trong prompt_manager
class PromptType(Enum):
    # ... existing types ...
    NEW_EXTRACTION = "new_extraction"

# Sá»­ dá»¥ng
prompt_template = prompt_manager.get_prompt(PromptType.NEW_EXTRACTION)
```

---

## ğŸ“ Káº¿t luáº­n

LangGraph Agent lÃ  má»™t implementation tinh vi cá»§a conversational AI vá»›i:

âœ… **Æ¯u Ä‘iá»ƒm**:
- Modular architecture dá»… má»Ÿ rá»™ng
- Native memory management vá»›i LangGraph
- Context-aware conversations  
- Intelligent parameter extraction
- Robust error handling
- ReAct-style reasoning

âš ï¸ **LÆ°u Ã½**:
- Cáº§n thiáº¿t láº­p database trÆ°á»›c khi sá»­ dá»¥ng
- LLM API keys pháº£i Ä‘Æ°á»£c cáº¥u hÃ¬nh Ä‘Ãºng
- Memory Ä‘Æ°á»£c quáº£n lÃ½ tá»± Ä‘á»™ng bá»Ÿi LangGraph

ğŸ”® **HÆ°á»›ng phÃ¡t triá»ƒn**:
- ThÃªm more sophisticated context understanding
- Multi-modal input support (images, voice)
- Advanced personalization
- Real-time learning from user feedback

---

*TÃ i liá»‡u nÃ y Ä‘Æ°á»£c táº¡o vÃ o ngÃ y 22/08/2025 cho phiÃªn báº£n LangGraph Agent v1.0*
