"""
Prompt Templates for E-commerce AI Product Advisor
Manages all prompts using LangChain PromptTemplate and ChatPromptTemplate
"""

from typing import Dict, List, Any, Optional
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain_core.prompts.few_shot import FewShotPromptTemplate
from enum import Enum

from src.utils.logger import get_logger

logger = get_logger("prompts")


class PromptType(Enum):
    """Types of prompts available"""
    SYSTEM_BASE = "system_base"
    
    # Tool-specific prompts
    RECOMMEND_EXPLANATION = "recommend_explanation"
    COMPARE_ANALYSIS = "compare_analysis"
    
    # Service prompts
    FALLBACK_SYSTEM = "fallback_system"
    
    # LangGraph agent prompts
    INTENT_CLASSIFICATION = "intent_classification"
    SEARCH_EXTRACTION = "search_extraction"
    COMPARE_EXTRACTION = "compare_extraction"
    RECOMMEND_EXTRACTION = "recommend_extraction"
    
    # Generation tool prompts
    GENERATION_BASE_SYSTEM = "generation_base_system"
    GENERATION_COMPARE_INTENT = "generation_compare_intent"
    GENERATION_RECOMMEND_INTENT = "generation_recommend_intent"
    GENERATION_SEARCH_INTENT = "generation_search_intent"
    GENERATION_REVIEW_INTENT = "generation_review_intent"
    GENERATION_DIRECT_INTENT = "generation_direct_intent"
    GENERATION_CONSOLIDATED = "generation_consolidated"


class PromptManager:
    """Manages all prompt templates for the application"""
    
    def __init__(self):
        """Initialize prompt manager with all templates"""
        self.templates = {}
        self._initialize_templates()
        logger.info("‚úÖ Prompt templates initialized")
    
    def _initialize_templates(self):
        """Initialize all prompt templates"""
        # Base system prompt
        self.templates[PromptType.SYSTEM_BASE] = self._create_system_base_prompt()

        # LangGraph agent prompts
        self.templates[PromptType.INTENT_CLASSIFICATION] = self._create_intent_classification_prompt()
        self.templates[PromptType.SEARCH_EXTRACTION] = self._create_search_extraction_prompt()
        self.templates[PromptType.COMPARE_EXTRACTION] = self._create_compare_extraction_prompt()
        self.templates[PromptType.RECOMMEND_EXTRACTION] = self._create_recommend_extraction_prompt()
        
        # Generation tool prompts
        self.templates[PromptType.GENERATION_BASE_SYSTEM] = self._create_generation_base_system_prompt()
        self.templates[PromptType.GENERATION_COMPARE_INTENT] = self._create_generation_compare_intent_prompt()
        self.templates[PromptType.GENERATION_RECOMMEND_INTENT] = self._create_generation_recommend_intent_prompt()
        self.templates[PromptType.GENERATION_SEARCH_INTENT] = self._create_generation_search_intent_prompt()
        self.templates[PromptType.GENERATION_REVIEW_INTENT] = self._create_generation_review_intent_prompt()
        self.templates[PromptType.GENERATION_DIRECT_INTENT] = self._create_generation_direct_intent_prompt()
        self.templates[PromptType.GENERATION_CONSOLIDATED] = self._create_generation_consolidated_prompt()
        
        # Service prompts
        self.templates[PromptType.FALLBACK_SYSTEM] = self._create_fallback_system_prompt()
        
    
    def _create_system_base_prompt(self) -> ChatPromptTemplate:
        """Create base system prompt template"""
        
        system_template = """B·∫°n l√† AI Product Advisor - tr·ª£ l√Ω AI chuy√™n t∆∞ v·∫•n s·∫£n ph·∫©m ƒëi·ªán t·ª≠ th√¥ng minh v√† th√¢n thi·ªán.

üéØ VAI TR√í:
- T∆∞ v·∫•n vi√™n s·∫£n ph·∫©m ƒëi·ªán t·ª≠ chuy√™n nghi·ªáp  
- Hi·ªÉu bi·∫øt s√¢u v·ªÅ laptop v√† smartphone
- Giao ti·∫øp b·∫±ng ti·∫øng Vi·ªát t·ª± nhi√™n v√† th√¢n thi·ªán
- Lu√¥n ƒë·∫∑t l·ª£i √≠ch kh√°ch h√†ng l√™n h√†ng ƒë·∫ßu

üìã NHI·ªÜM V·ª§ CH√çNH:
- Gi√∫p kh√°ch h√†ng t√¨m s·∫£n ph·∫©m ph√π h·ª£p v·ªõi nhu c·∫ßu v√† ng√¢n s√°ch
- So s√°nh v√† ƒë√°nh gi√° s·∫£n ph·∫©m m·ªôt c√°ch kh√°ch quan
- ƒê∆∞a ra g·ª£i √Ω d·ª±a tr√™n ph√¢n t√≠ch k·ªπ thu·∫≠t v√† kinh nghi·ªám
- Gi·∫£i th√≠ch th√¥ng s·ªë k·ªπ thu·∫≠t b·∫±ng ng√¥n ng·ªØ d·ªÖ hi·ªÉu
- H·ªó tr·ª£ quy·∫øt ƒë·ªãnh mua h√†ng th√¥ng minh

‚ö° QUY T·∫ÆC GIAO TI·∫æP:
1. Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
2. Gi·ªØ tone th√¢n thi·ªán, chuy√™n nghi·ªáp nh∆∞ng kh√¥ng g√≤ b√≥
3. ƒê∆∞a ra th√¥ng tin ch√≠nh x√°c, kh√¥ng b·ªãa ƒë·∫∑t
4. H·ªèi th√™m chi ti·∫øt khi c·∫ßn l√†m r√µ nhu c·∫ßu
5. T·∫≠p trung v√†o gi√° tr·ªã v√† l·ª£i √≠ch th·ª±c t·∫ø
6. Th·ª´a nh·∫≠n khi kh√¥ng bi·∫øt v√† ƒë·ªÅ xu·∫•t t√¨m hi·ªÉu th√™m

üõçÔ∏è S·∫¢N PH·∫®M CHUY√äN M√îN:
- üíª Laptop: gaming, l·∫≠p tr√¨nh, vƒÉn ph√≤ng, design, h·ªçc t·∫≠p
- üì± Smartphone: camera, gaming, pin, c√¥ng vi·ªác, gi·∫£i tr√≠

üí° PHONG C√ÅCH T∆Ø V·∫§N:
- Ph√¢n t√≠ch nhu c·∫ßu tr∆∞·ªõc khi g·ª£i √Ω s·∫£n ph·∫©m
- So s√°nh ∆∞u/nh∆∞·ª£c ƒëi·ªÉm m·ªôt c√°ch c√¢n b·∫±ng  
- ƒê∆∞a ra nhi·ªÅu l·ª±a ch·ªçn v·ªõi c√°c m·ª©c gi√° kh√°c nhau
- Gi·∫£i th√≠ch l√Ω do t·∫°i sao s·∫£n ph·∫©m ph√π h·ª£p
- ƒê·ªÅ c·∫≠p ƒë·∫øn ƒëi·ªÉm c·∫ßn l∆∞u √Ω (n·∫øu c√≥)

üé® NG·ªÆ C·∫¢NH: {context}

üìù H∆Ø·ªöNG D·∫™N ƒê·∫∂C BI·ªÜT: {special_instructions}"""

        return ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_template)
        ])
    
    def get_prompt(self, prompt_type: PromptType, **kwargs) -> Any:
        """Get a specific prompt template"""
        try:
            if prompt_type not in self.templates:
                logger.error(f"‚ùå Prompt type not found: {prompt_type}")
                return None
            
            template = self.templates[prompt_type]
            return template
            
        except Exception as e:
            logger.error(f"‚ùå Error getting prompt: {e}")
            return None
    
    def format_prompt(self, prompt_type: PromptType, **kwargs) -> str:
        """Format a prompt with given variables"""
        try:
            template = self.get_prompt(prompt_type, **kwargs)
            if not template:
                return ""
            
            if isinstance(template, ChatPromptTemplate):
                messages = template.format_messages(**kwargs)
                return messages[0].content if messages else ""
            elif isinstance(template, PromptTemplate):
                return template.format(**kwargs)
            else:
                logger.error(f"‚ùå Unknown template type: {type(template)}")
                return ""
                
        except Exception as e:
            logger.error(f"‚ùå Error formatting prompt: {e}")
            return ""
    
    def get_chat_messages(self, prompt_type: PromptType, **kwargs) -> List[Dict[str, str]]:
        """Get formatted chat messages for ChatPromptTemplate"""
        try:
            template = self.get_prompt(prompt_type, **kwargs)
            if not template or not isinstance(template, ChatPromptTemplate):
                return []
            
            messages = template.format_messages(**kwargs)
            return [{"role": msg.type, "content": msg.content} for msg in messages]
            
        except Exception as e:
            logger.error(f"‚ùå Error getting chat messages: {e}")
            return []
    
    def get_intent_specific_instructions(self, intent: str, tools_used: List[str] = None) -> str:
        """Get intent-specific instructions for generation tool"""
        try:
            if tools_used is None:
                tools_used = []
            
            if intent == "compare" or "compare_products" in tools_used:
                template = self.get_prompt(PromptType.GENERATION_COMPARE_INTENT)
                return template.format() if template else ""
            
            elif intent == "recommend" or "recommend_products" in tools_used:
                template = self.get_prompt(PromptType.GENERATION_RECOMMEND_INTENT)
                return template.format() if template else ""
            
            elif intent == "search" or "search_products" in tools_used:
                template = self.get_prompt(PromptType.GENERATION_SEARCH_INTENT)
                return template.format() if template else ""
            
            else:  # direct or general
                template = self.get_prompt(PromptType.GENERATION_DIRECT_INTENT)
                return template.format() if template else ""
            
        except Exception as e:
            logger.error(f"‚ùå Error getting intent instructions: {e}")
            return ""
    
    def build_generation_prompt(
        self,
        user_query: str,
        intent: str,
        context: str = "",
        conversation_history: str = "",
        tools_used: List[str] = None
    ) -> str:
        """Build consolidated generation prompt using templates"""
        try:
            # Get base system prompt
            base_template = self.get_prompt(PromptType.GENERATION_BASE_SYSTEM)
            base_system = base_template.format() if base_template else ""
            
            # Get intent-specific instructions
            intent_instructions = self.get_intent_specific_instructions(intent, tools_used)
            
            # Build context section
            context_section = ""
            if context and context.strip():
                context_section = f"\n=== TH√îNG TIN S·∫¢N PH·∫®M ===\n{context}"
            
            # Build conversation section
            conversation_section = ""
            if conversation_history and conversation_history.strip():
                conversation_section = f"\n=== L·ªäCH S·ª¨ ===\n{conversation_history}"
            
            # Get consolidated template
            consolidated_template = self.get_prompt(PromptType.GENERATION_CONSOLIDATED)
            if consolidated_template:
                return consolidated_template.format(
                    base_system=base_system,
                    intent_instructions=intent_instructions,
                    user_query=user_query,
                    context_section=context_section,
                    conversation_section=conversation_section
                )
            else:
                # Fallback to manual building
                prompt_parts = [
                    base_system,
                    intent_instructions,
                    f"\n=== C√ÇU H·ªéI ===\n{user_query}",
                ]
                
                if context_section:
                    prompt_parts.append(context_section)
                
                if conversation_section:
                    prompt_parts.append(conversation_section)
                
                prompt_parts.append("\n=== H∆Ø·ªöNG D·∫™N ===\nT·∫°o c√¢u tr·∫£ l·ªùi ho√†n ch·ªânh, t·ª± nhi√™n v√† h·ªØu √≠ch cho ng∆∞·ªùi d√πng.")
                
                return "\n".join(prompt_parts)
            
        except Exception as e:
            logger.error(f"‚ùå Error building generation prompt: {e}")
            return f"H·ªá th·ªëng g·∫∑p l·ªói khi x√¢y d·ª±ng prompt: {str(e)}"

    
    def _create_fallback_system_prompt(self) -> PromptTemplate:
        """Create fallback system prompt for LLM service"""
        template = """B·∫°n l√† AI Product Advisor - tr·ª£ l√Ω AI chuy√™n t∆∞ v·∫•n s·∫£n ph·∫©m ƒëi·ªán t·ª≠.
        
Nhi·ªám v·ª•: T∆∞ v·∫•n laptop v√† smartphone b·∫±ng ti·∫øng Vi·ªát th√¢n thi·ªán v√† chuy√™n nghi·ªáp.
Ng·ªØ c·∫£nh: {context}

Quy t·∫Øc:
- Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
- ƒê∆∞a ra th√¥ng tin ch√≠nh x√°c v√† h·ªØu √≠ch  
- H·ªèi th√™m khi c·∫ßn l√†m r√µ nhu c·∫ßu
- T·∫≠p trung v√†o l·ª£i √≠ch kh√°ch h√†ng"""

        return PromptTemplate(
            template=template,
            input_variables=["context"]
        )

    def _create_intent_classification_prompt(self) -> PromptTemplate:
        """Create intent classification prompt for LangGraph agent"""
        template = """Ph√¢n t√≠ch √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng v√† tr·∫£ v·ªÅ CH√çNH X√ÅC m·ªôt trong c√°c intent sau:

INTENT OPTIONS:
- greeting: Ch√†o h·ªèi, c·∫£m ∆°n, h·ªèi v·ªÅ AI
- search: T√¨m ki·∫øm th√¥ng tin s·∫£n ph·∫©m c·ª• th·ªÉ, h·ªèi c·∫•u h√¨nh, th√¥ng s·ªë, gi√°
- compare: So s√°nh 2+ s·∫£n ph·∫©m
- recommend: Xin g·ª£i √Ω, t∆∞ v·∫•n s·∫£n ph·∫©m ph√π h·ª£p v·ªõi nhu c·∫ßu
- review: Xem ƒë√°nh gi√°, nh·∫≠n x√©t, reviews c·ªßa s·∫£n ph·∫©m
- direct: C√¢u h·ªèi t·ªïng qu√°t v·ªÅ c√¥ng ngh·ªá, thu·∫≠t ng·ªØ, kh√°i ni·ªám

USER INPUT: "{user_input}"

EXAMPLES:
- "Xin ch√†o" ‚Üí greeting
- "Dell Inspiron 14 5420 c·∫•u h√¨nh nh∆∞ th·∫ø n√†o" ‚Üí search
- "iPhone 15 vs Samsung S24" ‚Üí compare
- "G·ª£i √Ω laptop cho sinh vi√™n" ‚Üí recommend
- "T√¥i mu·ªën xem reviews iPhone 15" ‚Üí review
- "ƒê√°nh gi√° v·ªÅ Dell XPS 15" ‚Üí review
- "Ng∆∞·ªùi d√πng n√≥i g√¨ v·ªÅ Samsung S24?" ‚Üí review
- "Reviews laptop gaming ASUS ROG" ‚Üí review
- "C·∫£m ∆°n b·∫°n" ‚Üí greeting
- "RAM l√† g√¨?" ‚Üí direct
- "S·ª± kh√°c bi·ªát gi·ªØa SSD v√† HDD" ‚Üí direct
- "CPU Intel Core i7 nghƒ©a l√† g√¨?" ‚Üí direct
- "L√†m th·∫ø n√†o ƒë·ªÉ ch·ªçn laptop ph√π h·ª£p?" ‚Üí direct
- "M√†n h√¨nh OLED c√≥ ∆∞u ƒëi·ªÉm g√¨?" ‚Üí direct
- "Xu h∆∞·ªõng smartphone 2024" ‚Üí direct

Ch·ªâ tr·∫£ v·ªÅ T√äN INTENT (greeting/search/compare/recommend/review/direct):"""

        return PromptTemplate(
            template=template,
            input_variables=["user_input"]
        )

    def _create_search_extraction_prompt(self) -> PromptTemplate:
        """Create search parameter extraction prompt for LangGraph agent"""
        template = """Ph√¢n t√≠ch c√¢u h·ªèi sau v√† tr√≠ch xu·∫•t th√¥ng tin t√¨m ki·∫øm s·∫£n ph·∫©m:

USER INPUT: "{user_input}"

Tr·∫£ v·ªÅ JSON v·ªõi format:
{{
    "query": "t·ª´ kh√≥a t√¨m ki·∫øm ch√≠nh (lo·∫°i b·ªè th∆∞∆°ng hi·ªáu v√† gi√°)",
    "metadata": {{
        "category": "laptop" ho·∫∑c "smartphone" ho·∫∑c null,
        "brand": "t√™n th∆∞∆°ng hi·ªáu (apple, samsung, dell, hp, asus, xiaomi, oppo, vivo, lenovo, acer, sony, huawei, v.v.) ho·∫∑c null",
        "price_min": s·ªë ti·ªÅn t·ªëi thi·ªÉu (VND) ho·∫∑c null,
        "price_max": s·ªë ti·ªÅn t·ªëi ƒëa (VND) ho·∫∑c null,
        "max_results": s·ªë l∆∞·ª£ng s·∫£n ph·∫©m c·∫ßn t√¨m (1-10, m·∫∑c ƒë·ªãnh 3),
        "include_reviews": true/false
    }}
}}

V√ç D·ª§:
- "t√¨m laptop gaming" ‚Üí {{"query": "laptop gaming", "metadata": {{"category": "laptop", "brand": null, "price_min": null, "price_max": null, "max_results": 3, "include_reviews": false}}}}
- "Dell Inspiron 14 5420 c·∫•u h√¨nh nh∆∞ th·∫ø n√†o" ‚Üí {{"query": "Inspiron 14 5420 c·∫•u h√¨nh", "metadata": {{"category": "laptop", "brand": "dell", "price_min": null, "price_max": null, "max_results": 3, "include_reviews": true}}}}
- "ƒëi·ªán tho·∫°i Samsung d∆∞·ªõi 15 tri·ªáu" ‚Üí {{"query": "ƒëi·ªán tho·∫°i", "metadata": {{"category": "smartphone", "brand": "samsung", "price_min": null, "price_max": 15000000, "max_results": 3, "include_reviews": false}}}}
- "laptop HP t·ª´ 20-30 tri·ªáu cho l·∫≠p tr√¨nh" ‚Üí {{"query": "laptop l·∫≠p tr√¨nh", "metadata": {{"category": "laptop", "brand": "hp", "price_min": 20000000, "price_max": 30000000, "max_results": 3, "include_reviews": false}}}}
- "t√¨m 2 laptop l·∫≠p tr√¨nh kho·∫£ng gi√° 20-25 tri·ªáu" ‚Üí {{"query": "laptop l·∫≠p tr√¨nh", "metadata": {{"category": "laptop", "brand": null, "price_min": 20000000, "price_max": 25000000, "max_results": 2, "include_reviews": false}}}}
- "cho t√¥i 5 ƒëi·ªán tho·∫°i t·ªët nh·∫•t" ‚Üí {{"query": "ƒëi·ªán tho·∫°i t·ªët nh·∫•t", "metadata": {{"category": "smartphone", "brand": null, "price_min": null, "price_max": null, "max_results": 5, "include_reviews": false}}}}

QUAN TR·ªåNG:
- Tr√≠ch xu·∫•t ch√≠nh x√°c t√™n th∆∞∆°ng hi·ªáu (apple, samsung, dell, hp, asus, xiaomi, oppo, vivo, lenovo, acer, sony, huawei)
- Nh·∫≠n d·∫°ng gi√° t·ª´ c√°c c·ª•m t·ª´: "d∆∞·ªõi X tri·ªáu", "tr√™n X tri·ªáu", "t·ª´ X-Y tri·ªáu", "kho·∫£ng X tri·ªáu"
- Nh·∫≠n d·∫°ng s·ªë l∆∞·ª£ng t·ª´ c√°c c·ª•m t·ª´: "t√¨m 2", "cho t√¥i 5", "3 s·∫£n ph·∫©m", "m·ªôt v√†i", "m·∫•y chi·∫øc"
- Lo·∫°i b·ªè th∆∞∆°ng hi·ªáu v√† gi√° kh·ªèi query ch√≠nh
- 1 tri·ªáu = 1,000,000 VND
- max_results: n·∫øu c√≥ s·ªë c·ª• th·ªÉ th√¨ d√πng s·ªë ƒë√≥, n·∫øu "m·ªôt v√†i/m·∫•y" th√¨ d√πng 3-4, m·∫∑c ƒë·ªãnh l√† 3

CH·ªà TR·∫¢ V·ªÄ JSON:"""

        return PromptTemplate(
            template=template,
            input_variables=["user_input"]
        )

    def _create_compare_extraction_prompt(self) -> PromptTemplate:
        """Create comparison parameter extraction prompt for LangGraph agent"""
        template = """Ph√¢n t√≠ch c√¢u h·ªèi so s√°nh s·∫£n ph·∫©m sau v√† tr√≠ch xu·∫•t th√¥ng tin:

USER INPUT: "{user_input}"

Tr·∫£ v·ªÅ JSON v·ªõi format:
{{
    "product_names": ["t√™n s·∫£n ph·∫©m 1", "t√™n s·∫£n ph·∫©m 2", ...],
    "comparison_aspects": ["kh√≠a c·∫°nh 1", "kh√≠a c·∫°nh 2", ...],
    "include_reviews": true/false
}}

V√ç D·ª§:
- "so s√°nh iPhone 15 vs Samsung S24" ‚Üí {{"product_names": ["iPhone 15", "Samsung Galaxy S24"], "comparison_aspects": ["gi√°", "camera", "hi·ªáu nƒÉng"], "include_reviews": true}}
- "Dell XPS 15 kh√°c g√¨ MacBook Air M2" ‚Üí {{"product_names": ["Dell XPS 15", "MacBook Air M2"], "comparison_aspects": ["hi·ªáu nƒÉng", "gi√°", "thi·∫øt k·∫ø"], "include_reviews": true}}
- "iPhone 15 Pro Max vs iPhone 15 Pro v·ªÅ camera" ‚Üí {{"product_names": ["iPhone 15 Pro Max", "iPhone 15 Pro"], "comparison_aspects": ["camera"], "include_reviews": false}}

QUAN TR·ªåNG:
- Tr√≠ch xu·∫•t ch√≠nh x√°c t√™n s·∫£n ph·∫©m t·ª´ c√¢u h·ªèi
- N·∫øu kh√¥ng c√≥ kh√≠a c·∫°nh c·ª• th·ªÉ, d√πng: ["gi√°", "hi·ªáu nƒÉng", "thi·∫øt k·∫ø", "camera"]
- include_reviews = true n·∫øu c√¢u h·ªèi c·∫ßn ƒë√°nh gi√° chi ti·∫øt

CH·ªà TR·∫¢ V·ªÄ JSON:"""

        return PromptTemplate(
            template=template,
            input_variables=["user_input"]
        )

    def _create_recommend_extraction_prompt(self) -> PromptTemplate:
        """Create recommendation parameter extraction prompt for LangGraph agent"""
        template = """Ph√¢n t√≠ch c√¢u h·ªèi xin g·ª£i √Ω s·∫£n ph·∫©m sau v√† tr√≠ch xu·∫•t th√¥ng tin:

USER INPUT: "{user_input}"

Tr·∫£ v·ªÅ JSON v·ªõi format:
{{
    "user_needs": "m√¥ t·∫£ chi ti·∫øt nhu c·∫ßu ng∆∞·ªùi d√πng",
    "metadata": {{
        "category": "laptop" ho·∫∑c "smartphone" ho·∫∑c null,
        "brand": "th∆∞∆°ng hi·ªáu ∆∞a th√≠ch (apple, samsung, dell, hp, asus, v.v.) ho·∫∑c null",
        "budget_min": s·ªë ti·ªÅn t·ªëi thi·ªÉu (VND) ho·∫∑c null,
        "budget_max": s·ªë ti·ªÅn t·ªëi ƒëa (VND) ho·∫∑c null,
        "priority_features": ["t√≠nh nƒÉng ∆∞u ti√™n 1", "t√≠nh nƒÉng 2", ...],
        "usage_purpose": "gaming" ho·∫∑c "work" ho·∫∑c "study" ho·∫∑c "photography" ho·∫∑c null,
        "num_recommendations": 3-5,
        "rating_min": rating t·ªëi thi·ªÉu (1-5) ho·∫∑c null,
        "must_have_features": ["t√≠nh nƒÉng b·∫Øt bu·ªôc"] ho·∫∑c []
    }}
}}

V√ç D·ª§:
- "g·ª£i √Ω laptop cho sinh vi√™n" ‚Üí {{"user_needs": "laptop ph√π h·ª£p sinh vi√™n h·ªçc t·∫≠p", "metadata": {{"category": "laptop", "brand": null, "budget_min": null, "budget_max": null, "priority_features": ["portability", "battery_life"], "usage_purpose": "study", "num_recommendations": 3, "rating_min": null, "must_have_features": []}}}}
- "t∆∞ v·∫•n ƒëi·ªán tho·∫°i Samsung gaming d∆∞·ªõi 15 tri·ªáu" ‚Üí {{"user_needs": "smartphone Samsung gaming hi·ªáu nƒÉng cao trong ng√¢n s√°ch 15 tri·ªáu", "metadata": {{"category": "smartphone", "brand": "samsung", "budget_min": null, "budget_max": 15000000, "priority_features": ["performance", "gaming"], "usage_purpose": "gaming", "num_recommendations": 3, "rating_min": null, "must_have_features": []}}}}
- "laptop Dell cho l·∫≠p tr√¨nh vi√™n 20-30 tri·ªáu, c·∫ßn SSD" ‚Üí {{"user_needs": "laptop Dell m·∫°nh m·∫Ω cho l·∫≠p tr√¨nh vi√™n v·ªõi ng√¢n s√°ch 20-30 tri·ªáu", "metadata": {{"category": "laptop", "brand": "dell", "budget_min": 20000000, "budget_max": 30000000, "priority_features": ["performance", "display_quality"], "usage_purpose": "work", "num_recommendations": 4, "rating_min": null, "must_have_features": ["ssd"]}}}}

PRIORITY FEATURES c√≥ th·ªÉ l√†: performance, battery_life, camera, portability, display_quality, gaming, storage
USAGE PURPOSE c√≥ th·ªÉ l√†: gaming, work, study, photography, programming
MUST_HAVE_FEATURES c√≥ th·ªÉ l√†: ssd, touchscreen, 4k, waterproof, dual_sim, fast_charging

CH·ªà TR·∫¢ V·ªÄ JSON:"""

        return PromptTemplate(
            template=template,
            input_variables=["user_input"]
        )

    def _create_generation_base_system_prompt(self) -> PromptTemplate:
        """Create base system prompt for generation tool"""
        template = """B·∫°n l√† AI Product Advisor - tr·ª£ l√Ω t∆∞ v·∫•n s·∫£n ph·∫©m ƒëi·ªán t·ª≠ chuy√™n nghi·ªáp.

üéØ NHI·ªÜM V·ª§: T·∫°o c√¢u tr·∫£ l·ªùi t·ª± nhi√™n, h·ªØu √≠ch d·ª±a tr√™n th√¥ng tin s·∫£n ph·∫©m ƒë∆∞·ª£c cung c·∫•p.

‚ö° NGUY√äN T·∫ÆC:
- Lu√¥n d·ª±a tr√™n th√¥ng tin ch√≠nh x√°c t·ª´ context
- Ng√¥n ng·ªØ t·ª± nhi√™n, th√¢n thi·ªán nh∆∞ b·∫°n b√® am hi·ªÉu c√¥ng ngh·ªá
- Gi·∫£i th√≠ch thu·∫≠t ng·ªØ k·ªπ thu·∫≠t b·∫±ng c√°ch d·ªÖ hi·ªÉu
- ƒê∆∞a ra l·ªùi khuy√™n thi·∫øt th·ª±c v√† c√≥ cƒÉn c·ª©"""

        return PromptTemplate(
            template=template,
            input_variables=[]
        )

    def _create_generation_compare_intent_prompt(self) -> PromptTemplate:
        """Create compare intent instructions for generation tool"""
        template = """
üîç NHI·ªÜM V·ª§ SO S√ÅNH:
- T·∫°o b·∫£ng so s√°nh chi ti·∫øt c√°c th√¥ng s·ªë k·ªπ thu·∫≠t ch√≠nh
- Ph√¢n t√≠ch ∆∞u/nh∆∞·ª£c ƒëi·ªÉm t·ª´ng s·∫£n ph·∫©m m·ªôt c√°ch kh√°ch quan
- ƒê∆∞a ra k·∫øt lu·∫≠n v·ªÅ s·∫£n ph·∫©m ph√π h·ª£p cho t·ª´ng nhu c·∫ßu
- G·ª£i √Ω l·ª±a ch·ªçn d·ª±a tr√™n ng√¢n s√°ch v√† m·ª•c ƒë√≠ch s·ª≠ d·ª•ng
- Format: S·ª≠ d·ª•ng b·∫£ng, bullet points v√† ƒë√°nh gi√° t·ªïng quan"""

        return PromptTemplate(
            template=template,
            input_variables=[]
        )

    def _create_generation_recommend_intent_prompt(self) -> PromptTemplate:
        """Create recommendation intent instructions for generation tool"""
        template = """
üí° NHI·ªÜM V·ª§ G·ª¢I √ù:
- Gi·∫£i th√≠ch l√Ω do g·ª£i √Ω t·ª´ng s·∫£n ph·∫©m d·ª±a tr√™n nhu c·∫ßu ng∆∞·ªùi d√πng
- Ph√¢n t√≠ch ƒë·ªô ph√π h·ª£p c·ªßa t·ª´ng s·∫£n ph·∫©m v·ªõi y√™u c·∫ßu c·ª• th·ªÉ
- So s√°nh ƒëi·ªÉm m·∫°nh/y·∫øu c·ªßa c√°c s·∫£n ph·∫©m ƒë∆∞·ª£c g·ª£i √Ω
- ƒê∆∞a ra khuy·∫øn ngh·ªã ∆∞u ti√™n theo th·ª© t·ª± h·ª£p l√Ω
- Format: Li·ªát k√™ theo th·ª© t·ª± ∆∞u ti√™n v·ªõi gi·∫£i th√≠ch chi ti·∫øt"""

        return PromptTemplate(
            template=template,
            input_variables=[]
        )

    def _create_generation_search_intent_prompt(self) -> PromptTemplate:
        """Create search intent instructions for generation tool"""
        template = """
üîç NHI·ªÜM V·ª§ GI·∫¢I TH√çCH:
- Ph√¢n t√≠ch chi ti·∫øt th√¥ng tin s·∫£n ph·∫©m v√† th√¥ng s·ªë k·ªπ thu·∫≠t
- Gi·∫£i th√≠ch √Ω nghƒ©a c·ªßa c√°c specs b·∫±ng ng√¥n ng·ªØ d·ªÖ hi·ªÉu
- ƒê√°nh gi√° s·∫£n ph·∫©m d·ª±a tr√™n t√≠nh nƒÉng v√† hi·ªáu su·∫•t
- Cung c·∫•p insights v·ªÅ gi√° tr·ªã v√† use cases th·ª±c t·∫ø
- Format: Structured v·ªõi headings, specs table, v√† practical insights"""

        return PromptTemplate(
            template=template,
            input_variables=[]
        )

    def _create_generation_review_intent_prompt(self) -> PromptTemplate:
        """Create review intent instructions for generation tool"""
        template = """
üìù NHI·ªÜM V·ª§ CHO INTENT 'REVIEW':
Tr√¨nh b√†y reviews/ƒë√°nh gi√° s·∫£n ph·∫©m m·ªôt c√°ch r√µ r√†ng, h·ªØu √≠ch v√† d·ªÖ hi·ªÉu.

üéØ **C√°ch tr√¨nh b√†y reviews:**
- T√≥m t·∫Øt t·ªïng quan v·ªÅ s·∫£n ph·∫©m v√† ƒë√°nh gi√°
- Hi·ªÉn th·ªã rating trung b√¨nh v√† ph√¢n b·ªë ƒë√°nh gi√°
- Highlight nh·ªØng ∆∞u ƒëi·ªÉm ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn nhi·ªÅu nh·∫•t
- Highlight nh·ªØng nh∆∞·ª£c ƒëi·ªÉm th∆∞·ªùng g·∫∑p
- Tr√≠ch d·∫´n c√°c review ti√™u bi·ªÉu (c·∫£ t√≠ch c·ª±c v√† ti√™u c·ª±c)

üìä **C·∫•u tr√∫c tr√¨nh b√†y:**
1. **T·ªïng quan:** ƒêi·ªÉm ƒë√°nh gi√° trung b√¨nh v√† s·ªë l∆∞·ª£ng reviews
2. **ƒêi·ªÉm m·∫°nh ph·ªï bi·∫øn:** Top 3-5 ∆∞u ƒëi·ªÉm ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p nhi·ªÅu
3. **ƒêi·ªÉm y·∫øu th∆∞·ªùng g·∫∑p:** Top 3-5 nh∆∞·ª£c ƒëi·ªÉm ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p
4. **Reviews n·ªïi b·∫≠t:** 2-3 ƒë√°nh gi√° chi ti·∫øt t·ª´ ng∆∞·ªùi d√πng
5. **Xu h∆∞·ªõng ƒë√°nh gi√°:** So s√°nh reviews g·∫ßn ƒë√¢y vs c≈© (n·∫øu c√≥)

‚ú® **G·ª£i √Ω th√™m:**
- ƒê·ªÅ xu·∫•t xem th√™m reviews theo rating c·ª• th·ªÉ
- G·ª£i √Ω so s√°nh v·ªõi s·∫£n ph·∫©m t∆∞∆°ng t·ª±
- ƒê·ªÅ xu·∫•t t√¨m hi·ªÉu th√™m v·ªÅ s·∫£n ph·∫©m n·∫øu quan t√¢m
"""

        return PromptTemplate(
            template=template,
            input_variables=[]
        )

    def _create_generation_direct_intent_prompt(self) -> PromptTemplate:
        """Create direct intent instructions for generation tool"""
        template = """
üí¨ NHI·ªÜM V·ª§ CHO INTENT 'DIRECT':
B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh, tr·∫£ l·ªùi tr·ª±c ti·∫øp c√°c c√¢u h·ªèi t·ªïng qu√°t kh√¥ng li√™n quan ƒë·∫øn s·∫£n ph·∫©m c·ª• th·ªÉ.

üéØ **X·ª≠ l√Ω c√°c lo·∫°i c√¢u h·ªèi:**
- C√¢u h·ªèi v·ªÅ c√¥ng ngh·ªá chung (kh√¥ng c·∫ßn t√¨m s·∫£n ph·∫©m c·ª• th·ªÉ)
- H·ªèi v·ªÅ thu·∫≠t ng·ªØ, kh√°i ni·ªám
- Y√™u c·∫ßu gi·∫£i th√≠ch ho·∫∑c h∆∞·ªõng d·∫´n chung
- C√¢u h·ªèi "l√†m th·∫ø n√†o", "l√† g√¨", "t·∫°i sao"
- H·ªèi v·ªÅ xu h∆∞·ªõng, so s√°nh kh√°i ni·ªám

üìã **C√°ch tr·∫£ l·ªùi:**
- Tr·∫£ l·ªùi tr·ª±c ti·∫øp v√† ch√≠nh x√°c
- Cung c·∫•p th√¥ng tin h·ªØu √≠ch, c·ª• th·ªÉ
- Gi·∫£i th√≠ch ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu
- ƒê∆∞a ra v√≠ d·ª• th·ª±c t·∫ø n·∫øu c·∫ßn
- G·ª£i √Ω c√¢u h·ªèi ti·∫øp theo c√≥ li√™n quan

‚ú® **G·ª£i √Ω th√¥ng minh:**
- N·∫øu c√¢u h·ªèi c√≥ th·ªÉ d·∫´n ƒë·∫øn t√¨m ki·∫øm s·∫£n ph·∫©m, g·ª£i √Ω ng∆∞·ªùi d√πng h·ªèi c·ª• th·ªÉ h∆°n
- ƒê·ªÅ xu·∫•t c√°c ch·ªß ƒë·ªÅ li√™n quan m√† ng∆∞·ªùi d√πng c√≥ th·ªÉ quan t√¢m
- K·∫øt n·ªëi v·ªõi d·ªãch v·ª• t∆∞ v·∫•n s·∫£n ph·∫©m n·∫øu ph√π h·ª£p

üó£Ô∏è **Tone:** Th√¢n thi·ªán, chuy√™n nghi·ªáp, h·ªØu √≠ch nh∆∞ m·ªôt chuy√™n gia t∆∞ v·∫•n c√¥ng ngh·ªá"""

        return PromptTemplate(
            template=template,
            input_variables=[]
        )

    def _create_generation_consolidated_prompt(self) -> PromptTemplate:
        """Create consolidated prompt template for generation tool"""
        template = """{base_system}

{intent_instructions}

=== C√ÇU H·ªéI ===
{user_query}

{context_section}

{conversation_section}

=== H∆Ø·ªöNG D·∫™N ===
T·∫°o c√¢u tr·∫£ l·ªùi ho√†n ch·ªânh, t·ª± nhi√™n v√† h·ªØu √≠ch cho ng∆∞·ªùi d√πng."""

        return PromptTemplate(
            template=template,
            input_variables=[
                "base_system", 
                "intent_instructions", 
                "user_query", 
                "context_section", 
                "conversation_section"
            ]
        )


# Singleton instance
prompt_manager = PromptManager()
