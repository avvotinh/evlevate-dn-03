# ü§ñ Agent Testing - Detailed Test Cases

## üìã Overview
This document contains comprehensive test cases for both ReAct Agent and LangGraph Agent implementations in the E-commerce AI Product Advisor Chatbot.

## üéØ Test Scope
- **LangGraph Agent**: Primary agent with state management and graph workflows
- **ReAct Agent**: Legacy agent for comparison and fallback
- **Agent State Management**: Memory persistence and context handling
- **Intent Classification**: Understanding user requests and routing
- **Tool Orchestration**: Proper tool selection and execution

---

## üß™ Test Cases

### TC-AGENT-001: LangGraph Agent Initialization
**Priority**: High  
**Category**: Functional  

**Description**: Verify LangGraph agent initializes correctly with all components

**Prerequisites**:
- Environment variables configured
- Dependencies installed
- Sample data loaded in Pinecone

**Test Steps**:
1. Import LangGraph agent module
2. Initialize agent manager
3. Get agent instance
4. Verify agent state structure
5. Check tool manager integration

**Expected Results**:
- Agent initializes without errors
- All tools are loaded (search, compare, recommend, review)
- State graph is properly constructed
- Memory saver is configured
- Session management is ready

**Validation Criteria**:
```python
assert agent is not None
assert len(agent.tool_manager.get_all_tools()) == 4
assert agent.memory_saver is not None
assert agent.graph is not None
```

---

### TC-AGENT-002: Basic Chat Functionality
**Priority**: High  
**Category**: Functional  

**Description**: Test basic chat interaction with simple queries

**Test Data**:
- Input: "Xin ch√†o"
- Input: "T√¨m laptop Dell"
- Input: "C·∫£m ∆°n"

**Test Steps**:
1. Start new chat session
2. Send greeting message
3. Send product search request
4. Send closing message
5. Verify responses are appropriate

**Expected Results**:
- Greeting response is welcoming and informative
- Product search triggers search tool
- Closing response is polite
- All responses are in Vietnamese
- Response time < 8 seconds

**Pass Criteria**:
- All responses are contextually appropriate
- No errors or exceptions
- Proper Vietnamese language usage

---

### TC-AGENT-003: Intent Classification Accuracy
**Priority**: High  
**Category**: Functional  

**Description**: Verify agent correctly identifies user intents

**Test Data**:
```python
test_intents = [
    ("T√¨m laptop gaming", "search"),
    ("So s√°nh iPhone 15 v√† Samsung S24", "compare"),
    ("G·ª£i √Ω ƒëi·ªán tho·∫°i d∆∞·ªõi 10 tri·ªáu", "recommend"),
    ("ƒê√°nh gi√° MacBook Air M2", "review"),
    ("C·∫£m ∆°n b·∫°n", "general"),
    ("Laptop n√†o t·ªët nh·∫•t?", "recommend")
]
```

**Test Steps**:
1. For each test case:
   - Send user input to agent
   - Capture intent classification result
   - Verify correct intent is identified
   - Check appropriate tool is selected

**Expected Results**:
- Intent classification accuracy > 90%
- Correct tools are invoked for each intent
- Ambiguous intents trigger clarification

**Validation**:
```python
for input_text, expected_intent in test_intents:
    result = agent.chat(input_text)
    assert result["intent"] == expected_intent
```

---

### TC-AGENT-004: Multi-turn Conversation Context
**Priority**: High  
**Category**: Functional  

**Description**: Test conversation context preservation across multiple turns

**Test Scenario**:
```
Turn 1: "T√¨m laptop Dell d∆∞·ªõi 20 tri·ªáu"
Turn 2: "C√≥ nh·ªØng model n√†o?"
Turn 3: "So s√°nh 2 model ƒë·∫ßu ti√™n"
Turn 4: "Model n√†o t·ªët h∆°n cho l·∫≠p tr√¨nh?"
```

**Test Steps**:
1. Start new session with session_id
2. Execute conversation turns sequentially
3. Verify context is maintained
4. Check reference resolution ("2 model ƒë·∫ßu ti√™n")
5. Validate personalized recommendations

**Expected Results**:
- Each turn builds on previous context
- References are resolved correctly
- Recommendations become more specific
- Session state persists between turns

**Context Validation**:
- Previous search results are referenced
- Product names are resolved from context
- User preferences are accumulated

---

### TC-AGENT-005: Session Memory Persistence
**Priority**: High  
**Category**: Functional  

**Description**: Verify session memory persists across application restarts

**Test Steps**:
1. Start conversation with session_id="test_session"
2. Perform product search
3. Save session state
4. Restart agent/application
5. Continue conversation with same session_id
6. Reference previous search results

**Expected Results**:
- Session state is restored correctly
- Previous conversation history is available
- Context references work across restarts
- No data loss occurs

**Validation**:
```python
# Before restart
result1 = agent.chat("T√¨m laptop Dell", session_id="test_session")

# After restart
agent = get_new_agent_instance()
result2 = agent.chat("So s√°nh ch√∫ng", session_id="test_session")
assert "Dell" in result2["response"]  # Context preserved
```

---

### TC-AGENT-006: Error Handling and Recovery
**Priority**: High  
**Category**: Error Handling  

**Description**: Test agent behavior when tools fail or return errors

**Test Scenarios**:
1. Pinecone service unavailable
2. LLM service timeout
3. Invalid tool parameters
4. Empty search results
5. Malformed user input

**Test Steps**:
1. Mock service failures
2. Send requests that trigger each error
3. Verify graceful error handling
4. Check fallback mechanisms
5. Validate error messages are user-friendly

**Expected Results**:
- No application crashes
- User-friendly error messages in Vietnamese
- Fallback suggestions provided
- Agent continues functioning after errors
- Error count is tracked in state

---

### TC-AGENT-007: Tool Selection Logic
**Priority**: Medium  
**Category**: Functional  

**Description**: Verify agent selects appropriate tools based on user input

**Test Cases**:
```python
tool_selection_tests = [
    ("T√¨m laptop HP", ["search_tool"]),
    ("So s√°nh iPhone v√† Samsung", ["search_tool", "compare_tool"]),
    ("G·ª£i √Ω ƒëi·ªán tho·∫°i t·ªët", ["recommend_tool"]),
    ("ƒê√°nh gi√° MacBook", ["search_tool", "review_tool"]),
    ("Laptop n√†o ph√π h·ª£p v·ªõi t√¥i?", ["recommend_tool"])
]
```

**Test Steps**:
1. For each test case, send input to agent
2. Monitor tool execution sequence
3. Verify correct tools are called
4. Check tool parameters are extracted correctly
5. Validate tool results are used appropriately

**Expected Results**:
- Correct tools selected for each query type
- Tools called in logical sequence
- Parameters extracted accurately
- Results integrated properly

---

### TC-AGENT-008: Performance Benchmarking
**Priority**: Medium  
**Category**: Performance  

**Description**: Measure agent response times for different query types

**Test Scenarios**:
- Simple search: "T√¨m laptop Dell"
- Complex comparison: "So s√°nh 3 laptop gaming t·ªët nh·∫•t"
- Recommendation: "G·ª£i √Ω ƒëi·ªán tho·∫°i ph√π h·ª£p v·ªõi sinh vi√™n"
- Multi-tool query: "T√¨m v√† so s√°nh iPhone m·ªõi nh·∫•t"

**Performance Targets**:
- Simple queries: < 5 seconds
- Complex queries: < 8 seconds
- Multi-tool queries: < 10 seconds
- Memory usage: < 500MB per session

**Measurement Points**:
- Total response time
- Individual tool execution time
- LLM API call duration
- Database query time
- Memory consumption

---

### TC-AGENT-009: Concurrent Session Handling
**Priority**: Medium  
**Category**: Performance  

**Description**: Test agent handling multiple concurrent sessions

**Test Setup**:
- 5 concurrent sessions
- Different conversation flows per session
- Mixed query types
- Session isolation verification

**Test Steps**:
1. Start 5 parallel sessions
2. Execute different conversations simultaneously
3. Verify session isolation
4. Check memory usage scaling
5. Validate response quality consistency

**Expected Results**:
- Sessions don't interfere with each other
- Response quality maintained across all sessions
- Memory usage scales linearly
- No session data leakage

---

### TC-AGENT-010: Vietnamese Language Handling
**Priority**: High  
**Category**: Functional  

**Description**: Verify proper Vietnamese language processing

**Test Cases**:
- Diacritics: "T√¨m ƒëi·ªán tho·∫°i c√≥ m√†n h√¨nh ƒë·∫πp"
- Colloquial: "Cho t√¥i xem laptop x·ªãn x√≤"
- Technical terms: "Laptop c√≥ CPU Intel Core i7"
- Mixed language: "T√¨m iPhone 15 Pro Max"

**Validation Points**:
- Correct intent understanding
- Proper parameter extraction
- Vietnamese response generation
- Technical term recognition
- Cultural context awareness

**Expected Results**:
- 90%+ accuracy in Vietnamese understanding
- Responses maintain Vietnamese language
- Technical terms handled correctly
- Cultural nuances respected

---

## üìä Test Execution Matrix

| Test Case | Priority | Automation | Status | Notes |
|-----------|----------|------------|--------|-------|
| TC-AGENT-001 | High | Yes | ‚è≥ Pending | Core functionality |
| TC-AGENT-002 | High | Yes | ‚è≥ Pending | Basic chat flow |
| TC-AGENT-003 | High | Yes | ‚è≥ Pending | Intent accuracy critical |
| TC-AGENT-004 | High | Partial | ‚è≥ Pending | Manual validation needed |
| TC-AGENT-005 | High | Yes | ‚è≥ Pending | Memory persistence |
| TC-AGENT-006 | High | Yes | ‚è≥ Pending | Error scenarios |
| TC-AGENT-007 | Medium | Yes | ‚è≥ Pending | Tool selection logic |
| TC-AGENT-008 | Medium | Yes | ‚è≥ Pending | Performance benchmarks |
| TC-AGENT-009 | Medium | Yes | ‚è≥ Pending | Concurrency testing |
| TC-AGENT-010 | High | Partial | ‚è≥ Pending | Language validation |

## üîß Test Automation Framework

### Unit Test Structure
```python
import pytest
from src.agents.langgraph_agent import get_agent_manager

class TestLangGraphAgent:
    @pytest.fixture
    def agent(self):
        return get_agent_manager().get_agent()
    
    def test_agent_initialization(self, agent):
        assert agent is not None
        # Additional assertions...
    
    def test_basic_chat(self, agent):
        response = agent.chat("Xin ch√†o")
        assert response["success"] is True
        # Additional validations...
```

### Integration Test Setup
```python
@pytest.mark.integration
class TestAgentIntegration:
    def test_multi_turn_conversation(self):
        # Multi-turn conversation test
        pass
    
    def test_session_persistence(self):
        # Session memory test
        pass
```

---

**Next**: Continue with tool-specific test cases in `test_cases_tools.md`
